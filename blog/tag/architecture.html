<!DOCTYPE html><html lang="en"><head><meta name="viewport" content="width=device-width"/><meta name="description" content="Starter kit for NextJS with Nx"/><meta charSet="utf8"/><title>architecture posts - idmontie&#x27;s Portfolio</title><meta name="keywords" content="architecture"/><meta name="next-head-count" content="5"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous"/><script>
                        try {
                            const storage = window && window.localStorage;
                            if (
                                storage.getItem("color-theme") === "dark" ||
                                (!("color-theme" in storage) &&
                                    window.matchMedia("(prefers-color-scheme: dark)").matches)
                            ) {
                                document.documentElement.classList.add("dark");
                            } else {
                                document.documentElement.classList.remove("dark");
                            }
                        } catch (e) {
                            console.error(e);
                        }
                        </script><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/db049c4a03aeb399.css" as="style"/><link rel="stylesheet" href="/_next/static/css/db049c4a03aeb399.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-f5a48affa2e5582e.js" defer=""></script><script src="/_next/static/chunks/framework-dfd14d7ce6600b03.js" defer=""></script><script src="/_next/static/chunks/main-3412f4325dfb32ac.js" defer=""></script><script src="/_next/static/chunks/pages/_app-13772235da247b91.js" defer=""></script><script src="/_next/static/chunks/2e6ef0e3-e0509ad90a52e50d.js" defer=""></script><script src="/_next/static/chunks/956-48ab0a0aeefeb947.js" defer=""></script><script src="/_next/static/chunks/pages/blog/tag/%5Btag%5D-04bece64926e977e.js" defer=""></script><script src="/_next/static/dqZvGnb3PuxFZXpxasXNF/_buildManifest.js" defer=""></script><script src="/_next/static/dqZvGnb3PuxFZXpxasXNF/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700&family=Open+Sans:wght@300;400;700&display=swap">@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRpXA.woff) format('woff')}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5OeA.woff) format('woff')}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNpXA.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsiH0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjZ0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsg-1y4k.woff) format('woff')}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZVcf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZXMf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZV8f6hPvhPUWH.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZVsf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZWMf6hPvhPQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-cSZMdeX3rsHo.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-eCZMdeX3rsHo.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-cyZMdeX3rsHo.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-ciZMdeX3rsHo.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-fCZMdeX3rg.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZVcf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZXMf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZV8f6hPvhPUWH.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZVsf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZWMf6hPvhPQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0307-0308,U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0307-0308,U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0307-0308,U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body class="leading-base bg-white text-lg antialiased dark:bg-gray-900 dark:text-white"><div id="__next"><nav class="flex items-center p-3"><div class="flex-1 space-x-4"><a class="" href="/">Home</a><a class="" href="/blog">Blog</a><a class="" href="/blog/tag">Tags</a><a class="" href="/portfolio">Portfolio</a></div><div class="flex flex-1 justify-end"><label for="toggle" class="relative flex w-fit cursor-pointer items-center">üåë<input type="checkbox" id="toggle" class="sr-only"/><div class="
                        relative
                        h-6
                        w-11
                        rounded-full
                        border-2
                    
                        after:absolute
                        after:h-5
                        after:w-5
                        after:rounded-full
                        after:border
                        after:border-gray-300
                        after:bg-white
                        after:shadow-sm
                        after:transition
                     
                            border-gray-200
                            bg-gray-200
                            dark:border-gray-700
                            dark:bg-gray-700
                        "></div>‚òÄÔ∏è</label></div></nav><div class="relative overflow-hidden pb-4"><div class="mx-auto flex w-full max-w-screen-lg flex-col items-center"><main class="app max-w-full"><div><div class="px-4"><header><h1 class="my-8 text-center text-3xl font-bold dark:text-white md:text-5xl"><span class="capitalize">architecture</span> posts</h1></header><div class="space-y-6"><div class="flex-1 overflow-visible rounded-lg bg-white shadow-lg dark:bg-gray-800"><div class="p-8 md:px-16"><a href="/blog/post/2023-12-08-the-breaking-point"><h2 class="text-2xl font-bold">The Breaking Point - Understanding the performance of your systems</h2></a><div class="py-2 text-sm"></div><div class="prose dark:prose-dark py-4"><div><div><p>Every system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn‚Äôt magically infinite. It‚Äôs a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.</p></div></div></div><div class="pt-2"><a href="/blog/post/2023-12-08-the-breaking-point">Continue reading<span class="ml-2">‚Üí</span></a></div></div></div><div class="flex-1 overflow-visible rounded-lg bg-white shadow-lg dark:bg-gray-800"><div class="p-8 md:px-16"><a href="/blog/post/2023-08-06-data-on-the-wire"><h2 class="text-2xl font-bold">Data on the Wire</h2></a><div class="py-2 text-sm"></div><div class="prose dark:prose-dark py-4"><div><div><p>Back when <a href="https://www.meteor.com/">Meteor</a> was in vogue, they popularized the concept of ‚ÄúData on the wire‚Äù. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.</p></div></div></div><div class="pt-2"><a href="/blog/post/2023-08-06-data-on-the-wire">Continue reading<span class="ml-2">‚Üí</span></a></div></div></div><div class="flex-1 overflow-visible rounded-lg bg-white shadow-lg dark:bg-gray-800"><div class="p-8 md:px-16"><a href="/blog/post/2023-07-21-backend-frontend"><h2 class="text-2xl font-bold">Backend for Frontend</h2></a><div class="py-2 text-sm"></div><div class="prose dark:prose-dark py-4"><div><div><p>The Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:</p></div></div></div><div class="pt-2"><a href="/blog/post/2023-07-21-backend-frontend">Continue reading<span class="ml-2">‚Üí</span></a></div></div></div></div></div></div></main></div></div><footer class="width-full border-top bg-gray-light my-4 mx-auto max-w-[1200px] p-4"><div class="mb-6 flex justify-center"></div><div class="flex-justify-between flex px-3 text-gray-700 dark:text-gray-300"><div class="flex flex-1 flex-row items-center gap-6"><div class="flex flex-row items-center gap-2"><a href="https://github.com/idmontie" target="_blank" rel="noopener noreferrer" type="button" class="m-1 h-9 w-9 rounded-full border-2 border-white uppercase leading-normal text-white transition duration-150 ease-in-out hover:bg-black hover:bg-opacity-5"><svg xmlns="http://www.w3.org/2000/svg" class="mx-auto h-full w-4" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg></a><a href="https://dev.to/idmontie" target="_blank" rel="noopener noreferrer" type="button" class="m-1 h-9 w-9 rounded-full border-2 border-white uppercase leading-normal text-white transition duration-150 ease-in-out hover:bg-black hover:bg-opacity-5"><svg xmlns="http://www.w3.org/2000/svg" class="mx-auto h-full w-4" viewBox="100 100 312 312" fill="currentColor"><path d="M140.47 203.94h-17.44v104.47h17.45c10.155-.545 17.358-8.669 17.47-17.41v-69.65c-.696-10.364-7.796-17.272-17.48-17.41zm45.73 87.25c0 18.81-11.61 47.31-48.36 47.25h-46.4V172.98h47.38c35.44 0 47.36 28.46 47.37 47.28zm100.68-88.66H233.6v38.42h32.57v29.57H233.6v38.41h53.29v29.57h-62.18c-11.16.29-20.44-8.53-20.72-19.69V193.7c-.27-11.15 8.56-20.41 19.71-20.69h63.19zm103.64 115.29c-13.2 30.75-36.85 24.63-47.44 0l-38.53-144.8h32.57l29.71 113.72 29.57-113.72h32.58z"></path></svg></a><a href="https://medium.com/@ivanmontiel" target="_blank" rel="noopener noreferrer" type="button" class="m-1 h-9 w-9 rounded-full border-2 border-white uppercase leading-normal text-white transition duration-150 ease-in-out hover:bg-black hover:bg-opacity-5"><svg xmlns="http://www.w3.org/2000/svg" class="mx-auto h-full w-4" viewBox="0 -55 256 256" version="1.1" preserveAspectRatio="xMidYMid"><g><path d="M72.2009141,1.42108547e-14 C112.076502,1.42108547e-14 144.399375,32.5485469 144.399375,72.6964154 C144.399375,112.844284 112.074049,145.390378 72.2009141,145.390378 C32.327779,145.390378 0,112.844284 0,72.6964154 C0,32.5485469 32.325326,1.42108547e-14 72.2009141,1.42108547e-14 Z M187.500628,4.25836743 C207.438422,4.25836743 223.601085,34.8960455 223.601085,72.6964154 L223.603538,72.6964154 C223.603538,110.486973 207.440875,141.134463 187.503081,141.134463 C167.565287,141.134463 151.402624,110.486973 151.402624,72.6964154 C151.402624,34.9058574 167.562834,4.25836743 187.500628,4.25836743 Z M243.303393,11.3867175 C250.314,11.3867175 256,38.835526 256,72.6964154 C256,106.547493 250.316453,134.006113 243.303393,134.006113 C236.290333,134.006113 230.609239,106.554852 230.609239,72.6964154 C230.609239,38.837979 236.292786,11.3867175 243.303393,11.3867175 Z" fill="currentColor"></path></g></svg></a></div><div>|</div><div><a href="/rss.xml" target="_blank" rel="noopener noreferrer">RSS Feed</a></div></div><div class="flex self-end"><button>Back to top</button></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"headTitle":"architecture posts - idmontie's Portfolio","headKeywords":"architecture","tag":"architecture","posts":[{"slug":"2023-12-08-the-breaking-point","date":"2023-12-08","title":"The Breaking Point - Understanding the performance of your systems","frontmatter":{"title":"The Breaking Point - Understanding the performance of your systems","tags":["architecture","scaling"]},"contentRaw":"\nEvery system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn‚Äôt magically infinite. It‚Äôs a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.\n\n![The Breaking Point](/media/2023-12-08-the-breaking-point/splash.png)\n\n## The Myth of Scaling\n\nSoftware engineering often has an optimistic mindset that scaling a service is easy: we just let the more instances of the service be deployed, and viola, perfect scaling! But the reality is a bit more complex. Instances don't always fire up instantly, services can fail unexpectedly, and not every component can scale indefinitely.\n\nThat‚Äôs why it‚Äôs important to understand the limitations of our services. Knowing where the system might buckle under pressure allows us to devise strategies to prevent these breaking points from turning into disasters.\n\nFor example, we may have a public API service with set auto-scaling rules. When the service is hit with many requests, the service spawns additional instances to handle the workload. This ends up working well in most cases, but in the real-world, the service ends up getting hit with huge bursts of requests from downstream users, rather than a steady increase of traffic. When this happens, we scale the service instances up, but now the database gets hit with too many writes and fails over, since the database was originally designed as a read heavy use-case. Of course this is a contrived example, but similar edge-cases commonly appear in complex architectures.\n\nWithout understanding the full system and the constraints of each part, it can be difficult to successfully scale.\n\n## Understanding Server Limitations\n\nA good starting point for finding your system‚Äôs breaking point is to see how it fares on a single machine. Profile the memory usage when under load, and use load testing to determine how many simultaneous requests the service can handle before performance degrades. To make sense of it all, set some benchmarks:\n\n1. Determine what it means for performance to degrade. In some systems, you may have SLAs for some percentage of requests to complete within a given response time. Other systems may have more leniency.\n2. Use readily available tools to bombard your service with requests and observe the results. For web API services, there are plenty of open source tools that can sustain issuing millions of requests a second and reporting results.\n3. Run the tests multiple times and throw out any outliers in the results. From the rest, understand the peak memory usage, peak disk usage, and peak CPU usage of the service.\n\nOnce you have the information from these types of load tests, it becomes easy to identify indicators that a service will begin to degrade. For some services it is CPU usage that will increase more than the other resources. For some services, memory can get exhausted first.\n\nThe load testing will also be a good indicator of how many requests a single instance of your service can handle before falling over.\n\n## Scaling Strategies\n\nWhen dealing with monolithic services or hefty microservices, you may find from load testing that just vertically scaling the service by adding more hardware is more cost efficient than replicating the instance.\n\nFore smaller service that use less memory and CPU footprint, it may make more sense to horizontally scale the service with many additional smaller servers being deployed.\n\nCloud services like AWS, Azure, and GCP help enable either decision. With AWS, there are many different instance types to get the right size for your specific service deployment. With the right size picked out, auto-scaling becomes a more budget-friendly option, as you're only spinning up instances that meet your specific resource requirements.\n\nCloud providers additionally have ways to detect when to auto-scale an instance based on resource usage, making load testing very informative to tune these values.\n\n## Conclusion\n\nScaling isn‚Äôt a one-size-fits-all solution. It‚Äôs about understanding the unique limitations and potential of your system. Through careful analysis, load testing, and a bit of strategic thinking, you can develop a scaling strategy that not only meets your performance needs but also keeps an eye on the cost of your system. Whether it‚Äôs beefing up your hardware or multiplying smaller instances, the key lies in making informed, tailored decisions for your system's specific demands and quirks.\n","contentHTML":"\u003cp\u003eEvery system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn‚Äôt magically infinite. It‚Äôs a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"The Breaking Point\" src=\"/media/2023-12-08-the-breaking-point/splash.png\" style=\"max-height:500px;margin:auto;text-align:center\"/\u003e\u003c/p\u003e\n\u003ch2\u003eThe Myth of Scaling\u003c/h2\u003e\n\u003cp\u003eSoftware engineering often has an optimistic mindset that scaling a service is easy: we just let the more instances of the service be deployed, and viola, perfect scaling! But the reality is a bit more complex. Instances don\u0026#x27;t always fire up instantly, services can fail unexpectedly, and not every component can scale indefinitely.\u003c/p\u003e\n\u003cp\u003eThat‚Äôs why it‚Äôs important to understand the limitations of our services. Knowing where the system might buckle under pressure allows us to devise strategies to prevent these breaking points from turning into disasters.\u003c/p\u003e\n\u003cp\u003eFor example, we may have a public API service with set auto-scaling rules. When the service is hit with many requests, the service spawns additional instances to handle the workload. This ends up working well in most cases, but in the real-world, the service ends up getting hit with huge bursts of requests from downstream users, rather than a steady increase of traffic. When this happens, we scale the service instances up, but now the database gets hit with too many writes and fails over, since the database was originally designed as a read heavy use-case. Of course this is a contrived example, but similar edge-cases commonly appear in complex architectures.\u003c/p\u003e\n\u003cp\u003eWithout understanding the full system and the constraints of each part, it can be difficult to successfully scale.\u003c/p\u003e\n\u003ch2\u003eUnderstanding Server Limitations\u003c/h2\u003e\n\u003cp\u003eA good starting point for finding your system‚Äôs breaking point is to see how it fares on a single machine. Profile the memory usage when under load, and use load testing to determine how many simultaneous requests the service can handle before performance degrades. To make sense of it all, set some benchmarks:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDetermine what it means for performance to degrade. In some systems, you may have SLAs for some percentage of requests to complete within a given response time. Other systems may have more leniency.\u003c/li\u003e\n\u003cli\u003eUse readily available tools to bombard your service with requests and observe the results. For web API services, there are plenty of open source tools that can sustain issuing millions of requests a second and reporting results.\u003c/li\u003e\n\u003cli\u003eRun the tests multiple times and throw out any outliers in the results. From the rest, understand the peak memory usage, peak disk usage, and peak CPU usage of the service.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eOnce you have the information from these types of load tests, it becomes easy to identify indicators that a service will begin to degrade. For some services it is CPU usage that will increase more than the other resources. For some services, memory can get exhausted first.\u003c/p\u003e\n\u003cp\u003eThe load testing will also be a good indicator of how many requests a single instance of your service can handle before falling over.\u003c/p\u003e\n\u003ch2\u003eScaling Strategies\u003c/h2\u003e\n\u003cp\u003eWhen dealing with monolithic services or hefty microservices, you may find from load testing that just vertically scaling the service by adding more hardware is more cost efficient than replicating the instance.\u003c/p\u003e\n\u003cp\u003eFore smaller service that use less memory and CPU footprint, it may make more sense to horizontally scale the service with many additional smaller servers being deployed.\u003c/p\u003e\n\u003cp\u003eCloud services like AWS, Azure, and GCP help enable either decision. With AWS, there are many different instance types to get the right size for your specific service deployment. With the right size picked out, auto-scaling becomes a more budget-friendly option, as you\u0026#x27;re only spinning up instances that meet your specific resource requirements.\u003c/p\u003e\n\u003cp\u003eCloud providers additionally have ways to detect when to auto-scale an instance based on resource usage, making load testing very informative to tune these values.\u003c/p\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eScaling isn‚Äôt a one-size-fits-all solution. It‚Äôs about understanding the unique limitations and potential of your system. Through careful analysis, load testing, and a bit of strategic thinking, you can develop a scaling strategy that not only meets your performance needs but also keeps an eye on the cost of your system. Whether it‚Äôs beefing up your hardware or multiplying smaller instances, the key lies in making informed, tailored decisions for your system\u0026#x27;s specific demands and quirks.\u003c/p\u003e","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    h2: \"h2\",\n    img: \"img\",\n    li: \"li\",\n    ol: \"ol\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Every system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn‚Äôt magically infinite. It‚Äôs a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-12-08-the-breaking-point/splash.png\",\n        alt: \"The Breaking Point\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"The Myth of Scaling\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Software engineering often has an optimistic mindset that scaling a service is easy: we just let the more instances of the service be deployed, and viola, perfect scaling! But the reality is a bit more complex. Instances don't always fire up instantly, services can fail unexpectedly, and not every component can scale indefinitely.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That‚Äôs why it‚Äôs important to understand the limitations of our services. Knowing where the system might buckle under pressure allows us to devise strategies to prevent these breaking points from turning into disasters.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For example, we may have a public API service with set auto-scaling rules. When the service is hit with many requests, the service spawns additional instances to handle the workload. This ends up working well in most cases, but in the real-world, the service ends up getting hit with huge bursts of requests from downstream users, rather than a steady increase of traffic. When this happens, we scale the service instances up, but now the database gets hit with too many writes and fails over, since the database was originally designed as a read heavy use-case. Of course this is a contrived example, but similar edge-cases commonly appear in complex architectures.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Without understanding the full system and the constraints of each part, it can be difficult to successfully scale.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Understanding Server Limitations\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A good starting point for finding your system‚Äôs breaking point is to see how it fares on a single machine. Profile the memory usage when under load, and use load testing to determine how many simultaneous requests the service can handle before performance degrades. To make sense of it all, set some benchmarks:\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Determine what it means for performance to degrade. In some systems, you may have SLAs for some percentage of requests to complete within a given response time. Other systems may have more leniency.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Use readily available tools to bombard your service with requests and observe the results. For web API services, there are plenty of open source tools that can sustain issuing millions of requests a second and reporting results.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Run the tests multiple times and throw out any outliers in the results. From the rest, understand the peak memory usage, peak disk usage, and peak CPU usage of the service.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Once you have the information from these types of load tests, it becomes easy to identify indicators that a service will begin to degrade. For some services it is CPU usage that will increase more than the other resources. For some services, memory can get exhausted first.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The load testing will also be a good indicator of how many requests a single instance of your service can handle before falling over.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Scaling Strategies\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When dealing with monolithic services or hefty microservices, you may find from load testing that just vertically scaling the service by adding more hardware is more cost efficient than replicating the instance.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Fore smaller service that use less memory and CPU footprint, it may make more sense to horizontally scale the service with many additional smaller servers being deployed.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Cloud services like AWS, Azure, and GCP help enable either decision. With AWS, there are many different instance types to get the right size for your specific service deployment. With the right size picked out, auto-scaling becomes a more budget-friendly option, as you're only spinning up instances that meet your specific resource requirements.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Cloud providers additionally have ways to detect when to auto-scale an instance based on resource usage, making load testing very informative to tune these values.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Conclusion\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Scaling isn‚Äôt a one-size-fits-all solution. It‚Äôs about understanding the unique limitations and potential of your system. Through careful analysis, load testing, and a bit of strategic thinking, you can develop a scaling strategy that not only meets your performance needs but also keeps an eye on the cost of your system. Whether it‚Äôs beefing up your hardware or multiplying smaller instances, the key lies in making informed, tailored decisions for your system's specific demands and quirks.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nEvery system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn‚Äôt magically infinite. It‚Äôs a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.","excerptHTML":"\u003cp\u003eEvery system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn‚Äôt magically infinite. It‚Äôs a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.\u003c/p\u003e","excerptCode":"\"use strict\";\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    p: \"p\",\n    ...props.components\n  };\n  return _jsx(_components.p, {\n    children: \"Every system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn‚Äôt magically infinite. It‚Äôs a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["architecture","scaling"]},{"slug":"2023-08-06-data-on-the-wire","date":"2023-08-06","title":"Data on the Wire","frontmatter":{"title":"Data on the Wire","tags":["architecture"]},"contentRaw":"\nBack when [Meteor](https://www.meteor.com/) was in vogue, they popularized the concept of ‚ÄúData on the wire‚Äù. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.\n\n\u003e Data on the wire refers mostly to the way that Meteor forms a websocket connection to the server on page load and then transfers the data needed over that connection.\n\u003e\n\u003e The websocket is a live connection and as the data changes, the updates are automatically pushed over the wire and the client updates in real time. (Similar to how many people can edit the same document simultaneously in Google Docs and see each others changes in real time)\n\u003e\n\n- [coagmano on Stackoverflow](https://stackoverflow.com/questions/48512242/in-meteor-what-does-data-on-the-wire-mean)\n\nThis idea was pretty interesting: a UI could always be considered up to date even if another client created a new row in the database. This is because Meteor would listen to the changelog of the MongoDB it was connected to, and then if a client was subscribed to the dataset that change belonged it, Meteor would push that change over the connected websocket.\n\nData on the wire enabled clients to stay up-to-date with any changes and create an amazing experience for users who would see changes instantly. For developers, this was also a huge win for prototyping applications.\n\nBut the problem with data on the wire is that the client can subscribe to a dataset with additional MongoDB filters, but the server now needs to keep track of what clients are subscribed to what subset of data.\n\nIf we start with a dataset `A`, and a user creates a new item `i`, then we know that if a user is subscribed to dataset `A`, we can just send the changes for `i` via a websocket.\n\n```mermaid\nsequenceDiagram\n    Client-\u003e\u003eServer: Subscribe to dataset A\n    MongoDB--\u003e\u003eServer: New item i was inserted into A\n    Server--\u003e\u003eClient: Push new item i via websocket\n```\n\nBut if we want to start scaling our servers up, then we must broadcast any change to dataset `A` to every service, and then each service must check if any websocket is subscribed to `A`:\n\n```mermaid\ngraph LR\n  MongoDB --\u003e Server1\n  Client --\u003e Server2\n  MongoDB --\u003e Server2\n  MongoDB --\u003e Server3 \n```\n\n(Technically, each server would either read from the MongoDB change stream, or have a service push an event to them that is listening to the change stream)\n\nNow, each Service needs to additionally check if the item `i` meets any additional filter criteria that each subscriber may have for dataset `A`.\n\nAs datasets grow and filters become more computationally expensive, this can cause a lot of processing and memory burden for each Server.\n\nThis is such a problem that it is even called out in the Meteor documentation: **Scaling Updates**.\n\n\u003e As previously mentioned, Meteor uses MongoDB‚Äôs Oplog to identify which changes to apply to which publication. Each change to the database is processed by every Meteor server, so frequent changes can result in high CPU usage across the board. At the same time, your database will come under higher load as all your servers keep fetching data from the oplog.\n\u003e\n\nI‚Äôve just thought about this recently since I had a conversation about keeping UI‚Äôs up-to-date with realtime data based on subscribing to that dataset via a websocket and it sounded eerily familiar to problems I have seen in the past.\n\nIn fact, similarly, I‚Äôve seen trouble with GraphQL Subscriptions having similar issues, since each server node now needs to identify when to push data back to a subscriber:\n\n\u003e GraphQL Subscriptions (GQLS) are a mechanism which allow clients to subscribe to changes in a piece of data from the server, and get notified whenever that data changes.\n\u003e\n\n[The relay spec](https://relay.dev/docs/v13.0.0/guided-tour/updating-data/graphql-subscriptions/) makes no mention of how a server might do this though. There is a handy tutorial by LogRocket on implementing a NodeJS server to handle subscriptions though: [GraphQL Subscriptions with NodeJS and Express](https://blog.logrocket.com/graphql-subscriptions-nodejs-express/).\n\nBut if you look at the diagrams, they seem awfully familiar‚Ä¶\n","contentHTML":"\u003cp\u003eBack when \u003ca href=\"https://www.meteor.com/\"\u003eMeteor\u003c/a\u003e was in vogue, they popularized the concept of ‚ÄúData on the wire‚Äù. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.\u003c/p\u003e\n\u003cblockquote class=\"border-l-4 border-gray-300 pl-4\"\u003e\n\u003cp\u003eData on the wire refers mostly to the way that Meteor forms a websocket connection to the server on page load and then transfers the data needed over that connection.\u003c/p\u003e\n\u003cp\u003eThe websocket is a live connection and as the data changes, the updates are automatically pushed over the wire and the client updates in real time. (Similar to how many people can edit the same document simultaneously in Google Docs and see each others changes in real time)\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://stackoverflow.com/questions/48512242/in-meteor-what-does-data-on-the-wire-mean\"\u003ecoagmano on Stackoverflow\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis idea was pretty interesting: a UI could always be considered up to date even if another client created a new row in the database. This is because Meteor would listen to the changelog of the MongoDB it was connected to, and then if a client was subscribed to the dataset that change belonged it, Meteor would push that change over the connected websocket.\u003c/p\u003e\n\u003cp\u003eData on the wire enabled clients to stay up-to-date with any changes and create an amazing experience for users who would see changes instantly. For developers, this was also a huge win for prototyping applications.\u003c/p\u003e\n\u003cp\u003eBut the problem with data on the wire is that the client can subscribe to a dataset with additional MongoDB filters, but the server now needs to keep track of what clients are subscribed to what subset of data.\u003c/p\u003e\n\u003cp\u003eIf we start with a dataset \u003ccode\u003eA\u003c/code\u003e, and a user creates a new item \u003ccode\u003ei\u003c/code\u003e, then we know that if a user is subscribed to dataset \u003ccode\u003eA\u003c/code\u003e, we can just send the changes for \u003ccode\u003ei\u003c/code\u003e via a websocket.\u003c/p\u003e\n\u003cmermaid chart=\"sequenceDiagram\n    Client-\u0026gt;\u0026gt;Server: Subscribe to dataset A\n    MongoDB--\u0026gt;\u0026gt;Server: New item i was inserted into A\n    Server--\u0026gt;\u0026gt;Client: Push new item i via websocket\"\u003e\u003c/mermaid\u003e\n\u003cp\u003eBut if we want to start scaling our servers up, then we must broadcast any change to dataset \u003ccode\u003eA\u003c/code\u003e to every service, and then each service must check if any websocket is subscribed to \u003ccode\u003eA\u003c/code\u003e:\u003c/p\u003e\n\u003cmermaid chart=\"graph LR\n  MongoDB --\u0026gt; Server1\n  Client --\u0026gt; Server2\n  MongoDB --\u0026gt; Server2\n  MongoDB --\u0026gt; Server3 \"\u003e\u003c/mermaid\u003e\n\u003cp\u003e(Technically, each server would either read from the MongoDB change stream, or have a service push an event to them that is listening to the change stream)\u003c/p\u003e\n\u003cp\u003eNow, each Service needs to additionally check if the item \u003ccode\u003ei\u003c/code\u003e meets any additional filter criteria that each subscriber may have for dataset \u003ccode\u003eA\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eAs datasets grow and filters become more computationally expensive, this can cause a lot of processing and memory burden for each Server.\u003c/p\u003e\n\u003cp\u003eThis is such a problem that it is even called out in the Meteor documentation: \u003cstrong\u003eScaling Updates\u003c/strong\u003e.\u003c/p\u003e\n\u003cblockquote class=\"border-l-4 border-gray-300 pl-4\"\u003e\n\u003cp\u003eAs previously mentioned, Meteor uses MongoDB‚Äôs Oplog to identify which changes to apply to which publication. Each change to the database is processed by every Meteor server, so frequent changes can result in high CPU usage across the board. At the same time, your database will come under higher load as all your servers keep fetching data from the oplog.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eI‚Äôve just thought about this recently since I had a conversation about keeping UI‚Äôs up-to-date with realtime data based on subscribing to that dataset via a websocket and it sounded eerily familiar to problems I have seen in the past.\u003c/p\u003e\n\u003cp\u003eIn fact, similarly, I‚Äôve seen trouble with GraphQL Subscriptions having similar issues, since each server node now needs to identify when to push data back to a subscriber:\u003c/p\u003e\n\u003cblockquote class=\"border-l-4 border-gray-300 pl-4\"\u003e\n\u003cp\u003eGraphQL Subscriptions (GQLS) are a mechanism which allow clients to subscribe to changes in a piece of data from the server, and get notified whenever that data changes.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://relay.dev/docs/v13.0.0/guided-tour/updating-data/graphql-subscriptions/\"\u003eThe relay spec\u003c/a\u003e makes no mention of how a server might do this though. There is a handy tutorial by LogRocket on implementing a NodeJS server to handle subscriptions though: \u003ca href=\"https://blog.logrocket.com/graphql-subscriptions-nodejs-express/\"\u003eGraphQL Subscriptions with NodeJS and Express\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eBut if you look at the diagrams, they seem awfully familiar‚Ä¶\u003c/p\u003e","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    blockquote: \"blockquote\",\n    code: \"code\",\n    li: \"li\",\n    mermaid: \"mermaid\",\n    p: \"p\",\n    strong: \"strong\",\n    ul: \"ul\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"Back when \", _jsx(_components.a, {\n        href: \"https://www.meteor.com/\",\n        children: \"Meteor\"\n      }), \" was in vogue, they popularized the concept of ‚ÄúData on the wire‚Äù. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.\"]\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"Data on the wire refers mostly to the way that Meteor forms a websocket connection to the server on page load and then transfers the data needed over that connection.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The websocket is a live connection and as the data changes, the updates are automatically pushed over the wire and the client updates in real time. (Similar to how many people can edit the same document simultaneously in Google Docs and see each others changes in real time)\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://stackoverflow.com/questions/48512242/in-meteor-what-does-data-on-the-wire-mean\",\n          children: \"coagmano on Stackoverflow\"\n        })\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This idea was pretty interesting: a UI could always be considered up to date even if another client created a new row in the database. This is because Meteor would listen to the changelog of the MongoDB it was connected to, and then if a client was subscribed to the dataset that change belonged it, Meteor would push that change over the connected websocket.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Data on the wire enabled clients to stay up-to-date with any changes and create an amazing experience for users who would see changes instantly. For developers, this was also a huge win for prototyping applications.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But the problem with data on the wire is that the client can subscribe to a dataset with additional MongoDB filters, but the server now needs to keep track of what clients are subscribed to what subset of data.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"If we start with a dataset \", _jsx(_components.code, {\n        children: \"A\"\n      }), \", and a user creates a new item \", _jsx(_components.code, {\n        children: \"i\"\n      }), \", then we know that if a user is subscribed to dataset \", _jsx(_components.code, {\n        children: \"A\"\n      }), \", we can just send the changes for \", _jsx(_components.code, {\n        children: \"i\"\n      }), \" via a websocket.\"]\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"sequenceDiagram\\n    Client-\u003e\u003eServer: Subscribe to dataset A\\n    MongoDB--\u003e\u003eServer: New item i was inserted into A\\n    Server--\u003e\u003eClient: Push new item i via websocket\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"But if we want to start scaling our servers up, then we must broadcast any change to dataset \", _jsx(_components.code, {\n        children: \"A\"\n      }), \" to every service, and then each service must check if any websocket is subscribed to \", _jsx(_components.code, {\n        children: \"A\"\n      }), \":\"]\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph LR\\n  MongoDB --\u003e Server1\\n  Client --\u003e Server2\\n  MongoDB --\u003e Server2\\n  MongoDB --\u003e Server3 \"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"(Technically, each server would either read from the MongoDB change stream, or have a service push an event to them that is listening to the change stream)\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now, each Service needs to additionally check if the item \", _jsx(_components.code, {\n        children: \"i\"\n      }), \" meets any additional filter criteria that each subscriber may have for dataset \", _jsx(_components.code, {\n        children: \"A\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"As datasets grow and filters become more computationally expensive, this can cause a lot of processing and memory burden for each Server.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This is such a problem that it is even called out in the Meteor documentation: \", _jsx(_components.strong, {\n        children: \"Scaling Updates\"\n      }), \".\"]\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"As previously mentioned, Meteor uses MongoDB‚Äôs Oplog to identify which changes to apply to which publication. Each change to the database is processed by every Meteor server, so frequent changes can result in high CPU usage across the board. At the same time, your database will come under higher load as all your servers keep fetching data from the oplog.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I‚Äôve just thought about this recently since I had a conversation about keeping UI‚Äôs up-to-date with realtime data based on subscribing to that dataset via a websocket and it sounded eerily familiar to problems I have seen in the past.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In fact, similarly, I‚Äôve seen trouble with GraphQL Subscriptions having similar issues, since each server node now needs to identify when to push data back to a subscriber:\"\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"GraphQL Subscriptions (GQLS) are a mechanism which allow clients to subscribe to changes in a piece of data from the server, and get notified whenever that data changes.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://relay.dev/docs/v13.0.0/guided-tour/updating-data/graphql-subscriptions/\",\n        children: \"The relay spec\"\n      }), \" makes no mention of how a server might do this though. There is a handy tutorial by LogRocket on implementing a NodeJS server to handle subscriptions though: \", _jsx(_components.a, {\n        href: \"https://blog.logrocket.com/graphql-subscriptions-nodejs-express/\",\n        children: \"GraphQL Subscriptions with NodeJS and Express\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But if you look at the diagrams, they seem awfully familiar‚Ä¶\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nBack when [Meteor](https://www.meteor.com/) was in vogue, they popularized the concept of ‚ÄúData on the wire‚Äù. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.","excerptHTML":"\u003cp\u003eBack when \u003ca href=\"https://www.meteor.com/\"\u003eMeteor\u003c/a\u003e was in vogue, they popularized the concept of ‚ÄúData on the wire‚Äù. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.\u003c/p\u003e","excerptCode":"\"use strict\";\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsxs(_components.p, {\n    children: [\"Back when \", _jsx(_components.a, {\n      href: \"https://www.meteor.com/\",\n      children: \"Meteor\"\n    }), \" was in vogue, they popularized the concept of ‚ÄúData on the wire‚Äù. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.\"]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["architecture"]},{"slug":"2023-07-21-backend-frontend","date":"2023-07-21","title":"Backend for Frontend","frontmatter":{"title":"Backend for Frontend","tags":["backend","frontend","architecture"]},"contentRaw":"\nThe Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:\n\n```mermaid\ngraph LR\n  SPA --\u003e Backend\n```\n\nSPAs also became popular because the codebase could be built into static assets that could be services.\n\nHowever, as complexity arises with the above architecture and the SPA starts to rely on more services, a thin proxy is typically introduced, like NGINX:\n\n```mermaid\ngraph LR\n  SPA --\u003e NGINX\n  NGINX --\u003e Service1\n  NGINX --\u003e Service2\n  NGINX --\u003e Service3\n```\n\nWhile proxies like NGINX can continue to be useful, using it as a proxy ends up putting a lot of routing and additional API handling logic on the client. The client now ends up also having to support, understand, and embed how to interact with the data rom all the downstream services. To simplify and create consistent contracts with the UI, we can create a proxy service: a Backend for the Frontend:\n\n```mermaid\ngraph LR\n  SPA --\u003e BEFFE\n  BEFFE --\u003e Service1\n  BEFFE --\u003e Service2\n  BEFFE --\u003e Service3\n```\n\nThe Backend for the Frontend ends up serving two purposes:\n\n- It acts as a proxy for all UI requests\n- It manages and massages the APIs of downstream services to be a consistent API for the UI.\n\nWhen building a UI, only a single service that acts like an API Gateway is required to understand and encode within the application.\n\nThe Backend for the Frontend model also allows engineers working on services to separate logic for the UI with the logic from an internal service. An internal service can rely on the Backend for the Frontend to handle things like Authentication, Authorization, Caching, and Rate-limits. These mechanisms may also be implemented as independent services, but the Backend for the Frontend can make multiple API calls per any API request from the UI.\n\n## Moving away from SPAs\n\nA newer development in the UI space is server side render the application. If we are already introducing additional complexity by having a Backend for the Frontend, then why not combine the UI code with the backend service and generate hydrated and cacheable pages via the server instead of using a SPA?\n\n```mermaid\ngraph LR\n  UIServer[\"UI Server\"] --\u003e Service1\n  UIServer --\u003e Service2\n UIServer --\u003e Service3\n```\n\nWith this design, we increase the complexity - the backend not has to be able to render the UI code. It must now render, hydrate, make requests to downstream APIs, and send those server-side rendered pages to the browser.\n\nBut this additional complexity enabled us to:\n\n- create truly authenticated and authorized routes ‚Äì the code for those routes isn‚Äôt even streamed to the browser, unlike a SPA.\n- near instant page loads ‚Äì¬†reducing the bundle size by just sending the JavaScript needed to run the page makes this possible. And since API calls are happening within the same network, this saves the user from additional loading spinners after the initial bundle has been loaded.\n\nThe general trend of having a Backend for the Frontend comes with additional complexity. It stems from the want to enhance the experience of the user, and probably from a subconscious desire to return to a simpler time:\n\n```mermaid\ngraph TD\n  Server\n```\n","contentHTML":"\u003cp\u003eThe Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:\u003c/p\u003e\n\u003cmermaid chart=\"graph LR\n  SPA --\u0026gt; Backend\"\u003e\u003c/mermaid\u003e\n\u003cp\u003eSPAs also became popular because the codebase could be built into static assets that could be services.\u003c/p\u003e\n\u003cp\u003eHowever, as complexity arises with the above architecture and the SPA starts to rely on more services, a thin proxy is typically introduced, like NGINX:\u003c/p\u003e\n\u003cmermaid chart=\"graph LR\n  SPA --\u0026gt; NGINX\n  NGINX --\u0026gt; Service1\n  NGINX --\u0026gt; Service2\n  NGINX --\u0026gt; Service3\"\u003e\u003c/mermaid\u003e\n\u003cp\u003eWhile proxies like NGINX can continue to be useful, using it as a proxy ends up putting a lot of routing and additional API handling logic on the client. The client now ends up also having to support, understand, and embed how to interact with the data rom all the downstream services. To simplify and create consistent contracts with the UI, we can create a proxy service: a Backend for the Frontend:\u003c/p\u003e\n\u003cmermaid chart=\"graph LR\n  SPA --\u0026gt; BEFFE\n  BEFFE --\u0026gt; Service1\n  BEFFE --\u0026gt; Service2\n  BEFFE --\u0026gt; Service3\"\u003e\u003c/mermaid\u003e\n\u003cp\u003eThe Backend for the Frontend ends up serving two purposes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIt acts as a proxy for all UI requests\u003c/li\u003e\n\u003cli\u003eIt manages and massages the APIs of downstream services to be a consistent API for the UI.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhen building a UI, only a single service that acts like an API Gateway is required to understand and encode within the application.\u003c/p\u003e\n\u003cp\u003eThe Backend for the Frontend model also allows engineers working on services to separate logic for the UI with the logic from an internal service. An internal service can rely on the Backend for the Frontend to handle things like Authentication, Authorization, Caching, and Rate-limits. These mechanisms may also be implemented as independent services, but the Backend for the Frontend can make multiple API calls per any API request from the UI.\u003c/p\u003e\n\u003ch2\u003eMoving away from SPAs\u003c/h2\u003e\n\u003cp\u003eA newer development in the UI space is server side render the application. If we are already introducing additional complexity by having a Backend for the Frontend, then why not combine the UI code with the backend service and generate hydrated and cacheable pages via the server instead of using a SPA?\u003c/p\u003e\n\u003cmermaid chart=\"graph LR\n  UIServer[\u0026quot;UI Server\u0026quot;] --\u0026gt; Service1\n  UIServer --\u0026gt; Service2\n UIServer --\u0026gt; Service3\"\u003e\u003c/mermaid\u003e\n\u003cp\u003eWith this design, we increase the complexity - the backend not has to be able to render the UI code. It must now render, hydrate, make requests to downstream APIs, and send those server-side rendered pages to the browser.\u003c/p\u003e\n\u003cp\u003eBut this additional complexity enabled us to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecreate truly authenticated and authorized routes ‚Äì the code for those routes isn‚Äôt even streamed to the browser, unlike a SPA.\u003c/li\u003e\n\u003cli\u003enear instant page loads ‚Äì¬†reducing the bundle size by just sending the JavaScript needed to run the page makes this possible. And since API calls are happening within the same network, this saves the user from additional loading spinners after the initial bundle has been loaded.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe general trend of having a Backend for the Frontend comes with additional complexity. It stems from the want to enhance the experience of the user, and probably from a subconscious desire to return to a simpler time:\u003c/p\u003e\n\u003cmermaid chart=\"graph TD\n  Server\"\u003e\u003c/mermaid\u003e","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    h2: \"h2\",\n    li: \"li\",\n    mermaid: \"mermaid\",\n    p: \"p\",\n    ul: \"ul\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"The Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:\"\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph LR\\n  SPA --\u003e Backend\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"SPAs also became popular because the codebase could be built into static assets that could be services.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"However, as complexity arises with the above architecture and the SPA starts to rely on more services, a thin proxy is typically introduced, like NGINX:\"\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph LR\\n  SPA --\u003e NGINX\\n  NGINX --\u003e Service1\\n  NGINX --\u003e Service2\\n  NGINX --\u003e Service3\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"While proxies like NGINX can continue to be useful, using it as a proxy ends up putting a lot of routing and additional API handling logic on the client. The client now ends up also having to support, understand, and embed how to interact with the data rom all the downstream services. To simplify and create consistent contracts with the UI, we can create a proxy service: a Backend for the Frontend:\"\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph LR\\n  SPA --\u003e BEFFE\\n  BEFFE --\u003e Service1\\n  BEFFE --\u003e Service2\\n  BEFFE --\u003e Service3\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The Backend for the Frontend ends up serving two purposes:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"It acts as a proxy for all UI requests\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"It manages and massages the APIs of downstream services to be a consistent API for the UI.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When building a UI, only a single service that acts like an API Gateway is required to understand and encode within the application.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The Backend for the Frontend model also allows engineers working on services to separate logic for the UI with the logic from an internal service. An internal service can rely on the Backend for the Frontend to handle things like Authentication, Authorization, Caching, and Rate-limits. These mechanisms may also be implemented as independent services, but the Backend for the Frontend can make multiple API calls per any API request from the UI.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Moving away from SPAs\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A newer development in the UI space is server side render the application. If we are already introducing additional complexity by having a Backend for the Frontend, then why not combine the UI code with the backend service and generate hydrated and cacheable pages via the server instead of using a SPA?\"\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph LR\\n  UIServer[\\\"UI Server\\\"] --\u003e Service1\\n  UIServer --\u003e Service2\\n UIServer --\u003e Service3\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With this design, we increase the complexity - the backend not has to be able to render the UI code. It must now render, hydrate, make requests to downstream APIs, and send those server-side rendered pages to the browser.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But this additional complexity enabled us to:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"create truly authenticated and authorized routes ‚Äì the code for those routes isn‚Äôt even streamed to the browser, unlike a SPA.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"near instant page loads ‚Äì¬†reducing the bundle size by just sending the JavaScript needed to run the page makes this possible. And since API calls are happening within the same network, this saves the user from additional loading spinners after the initial bundle has been loaded.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The general trend of having a Backend for the Frontend comes with additional complexity. It stems from the want to enhance the experience of the user, and probably from a subconscious desire to return to a simpler time:\"\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph TD\\n  Server\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nThe Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:","excerptHTML":"\u003cp\u003eThe Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:\u003c/p\u003e","excerptCode":"\"use strict\";\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    p: \"p\",\n    ...props.components\n  };\n  return _jsx(_components.p, {\n    children: \"The Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["backend","frontend","architecture"]}]},"__N_SSG":true},"page":"/blog/tag/[tag]","query":{"tag":"architecture"},"buildId":"dqZvGnb3PuxFZXpxasXNF","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>