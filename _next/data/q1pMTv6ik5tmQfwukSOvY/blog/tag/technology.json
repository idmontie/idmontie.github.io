{"pageProps":{"headTitle":"technology posts - idmontie's Portfolio","headKeywords":"technology","tag":"technology","posts":[{"slug":"2025-12-07-spreading-type-holes","date":"2025-12-07","title":"Forbidden Typescript: Spreading Type-holes","frontmatter":{"title":"Forbidden Typescript: Spreading Type-holes","tags":["technology","programming","react","typescript"]},"contentRaw":"\nI've discussed [full and partial objects before on this blog](/blog/post/2023-08-14-partial-objects), and in this article I'm going to investigate a common factory pattern\nin Typescript that can lead to type-holes.\nWhen writing tests or complex components, I'll often create prop factory utilities.\n\n<!--truncate-->\n\nFor tests, the goal is to create props with all the default values, except a few that may be\noveridden for a specific test case. The function signature typically looks like this:\n\n```jsx\nfunction makeFoo(partial?: Partial<Foo>): Foo;\n```\n\nThe expectation is that a software developer can call `makeFoo` and get a version of `Foo` that has all the defaults set to use in tests. Then, if the developer want to override a few fields to test an edge case, all they do is call `makeFoo({ fieldA: 'special-case })`.\n\nI’ve seen developers try to implement this a few ways, each with its pros and cons.\n\n### Spreading\n\nThe easiest way to implement this function is to just provide defaults and spread the partial:\n\n```jsx\ninterface Foo {\n  fieldA: string;\n  fieldB?: string;\n  fieldC?: boolean | null;\n}\n\nfunction makeFoo(partial?: Partial<Foo>): Foo {\n  return {\n\t  fieldA: 'test',\n    fieldB: 'example',\n    fieldC: false,\n    ...partial\n  };\n}\n```\n\nHere, we create a `Foo`  mock with overrides for the defaults, which are provided by `partial?: Partial<Foo>` . However, even though `fieldA` is required, we can see a type-hole with the default Typescript compilation settings:\n\n```jsx\nconst instance = makeFoo({ fieldA: undefined, fieldB: undefined, fieldC: undefined });\nconsole.log(instance.fieldA);\n\n// No type error, but this blows up\nconsole.log(instance.fieldA.toLowerCase());\n```\n\nWhen we spread, `undefined` actually overrides the default! But why were we allowed to provide `undefined` in the first place?\n\nIn Typescript, `Partial<Foo>`  keeps all the fields, but makes them optional. In the default compilation settings, an optional field can be set to `undefined`.\n\n[Typescript Playground Link](https://www.typescriptlang.org/play/?#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTIAOSQ9BkANOwpnGRcNBkQAB5wFk7yeQUcYuI08CS0EPkEBAB0PS5uwB7sOrr6COb0yKD0ikjIALzIVrb2DtgNaTRGZBBEIBBkyDohbGMgtOjyXSToTA5TYDMQXamUx-oA9O-IAHJYYACeThQ0Cg6CguRk6jAyDAAAtgLQZNcAO6I9ROXCnc6Xa63e6PZ5FChdMDoAAy6GR0HEcDaDhCxyAA)\n\nThere is a Typescript compilation flag to throw a type-error and keep our sanity: `exactOptionalPropertyTypes`. Enabling this flag makes Typescript show an error for `makeFoo({ fieldA: undefined, fieldB: undefined, fieldC: undefined });`. We can add the field to the call if it is set to a value.\n\n[Typescript Playground Link](https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=true#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTIAOSQ9BkANOwpnGRcNBkQAB5wFk7yeQUcYuI08CS0EPkEBAB0PS5uwB7sOrr6COb0yKD0ikjIALzIVrb2DtgNaTRGZBBEIBBkuevFmyDbu-uHqRInZ6D7yDohbGMgtOjyXSToTA5TYDMQLpXChPUbjd6Ar4-P4AoFFChdMDoAAy6AA7tBxHA2g4Qk8gA)\n\nBut this causes another problem: it is perfectly valid to create an initial instance of `Foo` without fieldB being set (and its value being `undefined`). But now our `makeFoo` object doesn’t allow us to pass `fieldB: undefined` anymore. Only when the interface explicitly defines fieldB as optional AND undefined does it allow us to so.\n\n[Typescript Playground Link](https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=true#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQTZAB9kAVxBkIREBDJsCRUmQDCfZACNMJCHBCjkIcSRJsAvrlwxJCMMHQGAtnADWEDOgAUABzhR7OBINAAV-QJIAHk8APgBKGk8cdigIMHEoAzwASCVOShoAckh6QoAadjyVLiKIAA84Jx9dcsqOFVUaeBJaCAqCAgA6Yb8A4CD2cwsrBEd6ZFB6fSRkAF5kF3dPL2x27hpJaVl5ZHM4tlmQWnRdQZJ0Ji9FsGWIQeVyCnOZuZu3+8ez1e73yFEGYHQABl0AB3aCqOC9Lxxc5AA)\n\nGenerally this pattern without the flag is fine for creating mock data, since any type-holes would only be scoped to tests and not real production code. But the question is: can we have `makeFoo` take a partial, return Foo without type-holes, and have allow `undefined` for partials?\n\n## Null-Coalescing Every Field\n\nAnother common implementation I have seen is to add nullish coalescing to every field:\n\n```jsx\ninterface Foo {\n  fieldA: string;\n  fieldB?: string;\n  fieldC?: boolean | null;\n}\n\nfunction makeFoo(partial?: Partial<Foo>): Foo {\n  return {\n\t  fieldA: partial?.fieldA ?? 'test',\n    fieldB: partial?.fieldB ?? 'example',\n    fieldC: partial?.fieldC ?? false,\n  };\n} \n```\n\nLet’s also turn off the `exactOptionalPropertyTypes` compilation flag for now.\n\nWe know every field will be set correctly, so there are no type-holes in `Foo`, however, we still have the problem where we cannot override a field to the `unset` value of `undefined` :\n\n[Typescript Playground Link](https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=false&ssl=13&ssc=2&pln=1&pc=1#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTILm7AHjwAdKmUyDw8yADkkPSlADTsKZxkXDSZfnkFXEUlpRAAHnAWTvLVtRxi4k2+2Z759eIdhB60EDUEOrr6COb0yKD0ikjIALzIVrb2DtgjaTRGZBBEIBBkVZcN1yC394-IOiFsGyC0dDyXIkdBMBw7MB7CDTMQUX64f6A4Gg8GQ6Gw7gIxGbIEw1EQgFQ4wwgoUXJgdAAGXQAHdoOI4IsHCEEUA)\n\nTurning on the `exactOptionalPropertyTypes` also doesn’t save us here since we didn’t have a type-issue anyway, but more of a logic issue. `makeFoo({ fieldB: undefined })` will still set `fieldB` to `example`.\n\n## Allowing bad inputs\n\nThis last approach takes the first and second approaches above and combines them using a `pickOrDefault` function. Here if any value is passed into the partial, we will return it, except when that value would be incorrect in the output type:\n\n```tsx\nfunction isValuePresent<T extends object>(obj: T, key: keyof T): boolean {\n    return key in obj;\n}\n\nfunction pickOrDefault<T extends object, K extends keyof T>(partial: T, key: K, fallbackValue: T[K]): T[K] {\n  if (key in partial) {\n    return partial[key];\n  }\n\n  return fallbackValue\n}\n\ninterface Foo {\n  fieldA: string;\n  fieldB?: string;\n  fieldC?: boolean | null;\n}\n\nfunction makeFoo(partial: Partial<Foo> = {}): Foo {\n  return {\n\t  fieldA: pickOrDefault(partial, 'fieldA', 'test') ?? 'test',\n    fieldB: pickOrDefault(partial, 'fieldB', 'example'),\n    fieldC: pickOrDefault(partial, 'fieldC', true),\n  };\n}\n\nconst instance = makeFoo({ fieldA: undefined, fieldB: undefined });\nconsole.log(instance.fieldA);\nconsole.log(instance.fieldB);\n\nconsole.log(instance.fieldA.toLowerCase());\n\n```\n\nFor each field, we prefer the input partial, except here the type mismatch for `fieldA` forced us to add the default value twice, once if the partial didn’t have a value, and once if the partial had `undefined` which isn’t allows in the final version of `type Foo`.\n\nWhile more verbose, this does eliminate the type holes the code!","contentHTML":"<p>I&#x27;ve discussed <a href=\"/blog/post/2023-08-14-partial-objects\">full and partial objects before on this blog</a>, and in this article I&#x27;m going to investigate a common factory pattern\nin Typescript that can lead to type-holes.\nWhen writing tests or complex components, I&#x27;ll often create prop factory utilities.</p>\n<p>For tests, the goal is to create props with all the default values, except a few that may be\noveridden for a specific test case. The function signature typically looks like this:</p>\n<div class=\"overflow-auto rounded-2xl bg-[#0e005d6d] p-4 font-mono text-sm dark:bg-[#0e005d6d] dark:text-gray-100\"><pre><code class=\"language-jsx\">function makeFoo(partial?: Partial&lt;Foo&gt;): Foo;\n</code></pre></div>\n<p>The expectation is that a software developer can call <code>makeFoo</code> and get a version of <code>Foo</code> that has all the defaults set to use in tests. Then, if the developer want to override a few fields to test an edge case, all they do is call <code>makeFoo({ fieldA: &#x27;special-case })</code>.</p>\n<p>I’ve seen developers try to implement this a few ways, each with its pros and cons.</p>\n<h3>Spreading</h3>\n<p>The easiest way to implement this function is to just provide defaults and spread the partial:</p>\n<div class=\"overflow-auto rounded-2xl bg-[#0e005d6d] p-4 font-mono text-sm dark:bg-[#0e005d6d] dark:text-gray-100\"><pre><code class=\"language-jsx\">interface Foo {\n  fieldA: string;\n  fieldB?: string;\n  fieldC?: boolean | null;\n}\n\nfunction makeFoo(partial?: Partial&lt;Foo&gt;): Foo {\n  return {\n\t  fieldA: &#x27;test&#x27;,\n    fieldB: &#x27;example&#x27;,\n    fieldC: false,\n    ...partial\n  };\n}\n</code></pre></div>\n<p>Here, we create a <code>Foo</code>  mock with overrides for the defaults, which are provided by <code>partial?: Partial&lt;Foo&gt;</code> . However, even though <code>fieldA</code> is required, we can see a type-hole with the default Typescript compilation settings:</p>\n<div class=\"overflow-auto rounded-2xl bg-[#0e005d6d] p-4 font-mono text-sm dark:bg-[#0e005d6d] dark:text-gray-100\"><pre><code class=\"language-jsx\">const instance = makeFoo({ fieldA: undefined, fieldB: undefined, fieldC: undefined });\nconsole.log(instance.fieldA);\n\n// No type error, but this blows up\nconsole.log(instance.fieldA.toLowerCase());\n</code></pre></div>\n<p>When we spread, <code>undefined</code> actually overrides the default! But why were we allowed to provide <code>undefined</code> in the first place?</p>\n<p>In Typescript, <code>Partial&lt;Foo&gt;</code>  keeps all the fields, but makes them optional. In the default compilation settings, an optional field can be set to <code>undefined</code>.</p>\n<p><a href=\"https://www.typescriptlang.org/play/?#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTIAOSQ9BkANOwpnGRcNBkQAB5wFk7yeQUcYuI08CS0EPkEBAB0PS5uwB7sOrr6COb0yKD0ikjIALzIVrb2DtgNaTRGZBBEIBBkyDohbGMgtOjyXSToTA5TYDMQXamUx-oA9O-IAHJYYACeThQ0Cg6CguRk6jAyDAAAtgLQZNcAO6I9ROXCnc6Xa63e6PZ5FChdMDoAAy6GR0HEcDaDhCxyAA\">Typescript Playground Link</a></p>\n<p>There is a Typescript compilation flag to throw a type-error and keep our sanity: <code>exactOptionalPropertyTypes</code>. Enabling this flag makes Typescript show an error for <code>makeFoo({ fieldA: undefined, fieldB: undefined, fieldC: undefined });</code>. We can add the field to the call if it is set to a value.</p>\n<p><a href=\"https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=true#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTIAOSQ9BkANOwpnGRcNBkQAB5wFk7yeQUcYuI08CS0EPkEBAB0PS5uwB7sOrr6COb0yKD0ikjIALzIVrb2DtgNaTRGZBBEIBBkuevFmyDbu-uHqRInZ6D7yDohbGMgtOjyXSToTA5TYDMQLpXChPUbjd6Ar4-P4AoFFChdMDoAAy6AA7tBxHA2g4Qk8gA\">Typescript Playground Link</a></p>\n<p>But this causes another problem: it is perfectly valid to create an initial instance of <code>Foo</code> without fieldB being set (and its value being <code>undefined</code>). But now our <code>makeFoo</code> object doesn’t allow us to pass <code>fieldB: undefined</code> anymore. Only when the interface explicitly defines fieldB as optional AND undefined does it allow us to so.</p>\n<p><a href=\"https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=true#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQTZAB9kAVxBkIREBDJsCRUmQDCfZACNMJCHBCjkIcSRJsAvrlwxJCMMHQGAtnADWEDOgAUABzhR7OBINAAV-QJIAHk8APgBKGk8cdigIMHEoAzwASCVOShoAckh6QoAadjyVLiKIAA84Jx9dcsqOFVUaeBJaCAqCAgA6Yb8A4CD2cwsrBEd6ZFB6fSRkAF5kF3dPL2x27hpJaVl5ZHM4tlmQWnRdQZJ0Ji9FsGWIQeVyCnOZuZu3+8ez1e73yFEGYHQABl0AB3aCqOC9Lxxc5AA\">Typescript Playground Link</a></p>\n<p>Generally this pattern without the flag is fine for creating mock data, since any type-holes would only be scoped to tests and not real production code. But the question is: can we have <code>makeFoo</code> take a partial, return Foo without type-holes, and have allow <code>undefined</code> for partials?</p>\n<h2>Null-Coalescing Every Field</h2>\n<p>Another common implementation I have seen is to add nullish coalescing to every field:</p>\n<div class=\"overflow-auto rounded-2xl bg-[#0e005d6d] p-4 font-mono text-sm dark:bg-[#0e005d6d] dark:text-gray-100\"><pre><code class=\"language-jsx\">interface Foo {\n  fieldA: string;\n  fieldB?: string;\n  fieldC?: boolean | null;\n}\n\nfunction makeFoo(partial?: Partial&lt;Foo&gt;): Foo {\n  return {\n\t  fieldA: partial?.fieldA ?? &#x27;test&#x27;,\n    fieldB: partial?.fieldB ?? &#x27;example&#x27;,\n    fieldC: partial?.fieldC ?? false,\n  };\n} \n</code></pre></div>\n<p>Let’s also turn off the <code>exactOptionalPropertyTypes</code> compilation flag for now.</p>\n<p>We know every field will be set correctly, so there are no type-holes in <code>Foo</code>, however, we still have the problem where we cannot override a field to the <code>unset</code> value of <code>undefined</code> :</p>\n<p><a href=\"https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=false&amp;ssl=13&amp;ssc=2&amp;pln=1&amp;pc=1#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTILm7AHjwAdKmUyDw8yADkkPSlADTsKZxkXDSZfnkFXEUlpRAAHnAWTvLVtRxi4k2+2Z759eIdhB60EDUEOrr6COb0yKD0ikjIALzIVrb2DtgjaTRGZBBEIBBkVZcN1yC394-IOiFsGyC0dDyXIkdBMBw7MB7CDTMQUX64f6A4Gg8GQ6Gw7gIxGbIEw1EQgFQ4wwgoUXJgdAAGXQAHdoOI4IsHCEEUA\">Typescript Playground Link</a></p>\n<p>Turning on the <code>exactOptionalPropertyTypes</code> also doesn’t save us here since we didn’t have a type-issue anyway, but more of a logic issue. <code>makeFoo({ fieldB: undefined })</code> will still set <code>fieldB</code> to <code>example</code>.</p>\n<h2>Allowing bad inputs</h2>\n<p>This last approach takes the first and second approaches above and combines them using a <code>pickOrDefault</code> function. Here if any value is passed into the partial, we will return it, except when that value would be incorrect in the output type:</p>\n<div class=\"overflow-auto rounded-2xl bg-[#0e005d6d] p-4 font-mono text-sm dark:bg-[#0e005d6d] dark:text-gray-100\"><pre><code class=\"language-tsx\">function isValuePresent&lt;T extends object&gt;(obj: T, key: keyof T): boolean {\n    return key in obj;\n}\n\nfunction pickOrDefault&lt;T extends object, K extends keyof T&gt;(partial: T, key: K, fallbackValue: T[K]): T[K] {\n  if (key in partial) {\n    return partial[key];\n  }\n\n  return fallbackValue\n}\n\ninterface Foo {\n  fieldA: string;\n  fieldB?: string;\n  fieldC?: boolean | null;\n}\n\nfunction makeFoo(partial: Partial&lt;Foo&gt; = {}): Foo {\n  return {\n\t  fieldA: pickOrDefault(partial, &#x27;fieldA&#x27;, &#x27;test&#x27;) ?? &#x27;test&#x27;,\n    fieldB: pickOrDefault(partial, &#x27;fieldB&#x27;, &#x27;example&#x27;),\n    fieldC: pickOrDefault(partial, &#x27;fieldC&#x27;, true),\n  };\n}\n\nconst instance = makeFoo({ fieldA: undefined, fieldB: undefined });\nconsole.log(instance.fieldA);\nconsole.log(instance.fieldB);\n\nconsole.log(instance.fieldA.toLowerCase());\n\n</code></pre></div>\n<p>For each field, we prefer the input partial, except here the type mismatch for <code>fieldA</code> forced us to add the default value twice, once if the partial didn’t have a value, and once if the partial had <code>undefined</code> which isn’t allows in the final version of <code>type Foo</code>.</p>\n<p>While more verbose, this does eliminate the type holes the code!</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    code: \"code\",\n    h2: \"h2\",\n    h3: \"h3\",\n    p: \"p\",\n    pre: \"pre\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"I've discussed \", _jsx(_components.a, {\n        href: \"/blog/post/2023-08-14-partial-objects\",\n        children: \"full and partial objects before on this blog\"\n      }), \", and in this article I'm going to investigate a common factory pattern\\nin Typescript that can lead to type-holes.\\nWhen writing tests or complex components, I'll often create prop factory utilities.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For tests, the goal is to create props with all the default values, except a few that may be\\noveridden for a specific test case. The function signature typically looks like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-jsx\",\n        children: \"function makeFoo(partial?: Partial<Foo>): Foo;\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The expectation is that a software developer can call \", _jsx(_components.code, {\n        children: \"makeFoo\"\n      }), \" and get a version of \", _jsx(_components.code, {\n        children: \"Foo\"\n      }), \" that has all the defaults set to use in tests. Then, if the developer want to override a few fields to test an edge case, all they do is call \", _jsx(_components.code, {\n        children: \"makeFoo({ fieldA: 'special-case })\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I’ve seen developers try to implement this a few ways, each with its pros and cons.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Spreading\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The easiest way to implement this function is to just provide defaults and spread the partial:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-jsx\",\n        children: \"interface Foo {\\n  fieldA: string;\\n  fieldB?: string;\\n  fieldC?: boolean | null;\\n}\\n\\nfunction makeFoo(partial?: Partial<Foo>): Foo {\\n  return {\\n\\t  fieldA: 'test',\\n    fieldB: 'example',\\n    fieldC: false,\\n    ...partial\\n  };\\n}\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Here, we create a \", _jsx(_components.code, {\n        children: \"Foo\"\n      }), \"  mock with overrides for the defaults, which are provided by \", _jsx(_components.code, {\n        children: \"partial?: Partial<Foo>\"\n      }), \" . However, even though \", _jsx(_components.code, {\n        children: \"fieldA\"\n      }), \" is required, we can see a type-hole with the default Typescript compilation settings:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-jsx\",\n        children: \"const instance = makeFoo({ fieldA: undefined, fieldB: undefined, fieldC: undefined });\\nconsole.log(instance.fieldA);\\n\\n// No type error, but this blows up\\nconsole.log(instance.fieldA.toLowerCase());\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"When we spread, \", _jsx(_components.code, {\n        children: \"undefined\"\n      }), \" actually overrides the default! But why were we allowed to provide \", _jsx(_components.code, {\n        children: \"undefined\"\n      }), \" in the first place?\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In Typescript, \", _jsx(_components.code, {\n        children: \"Partial<Foo>\"\n      }), \"  keeps all the fields, but makes them optional. In the default compilation settings, an optional field can be set to \", _jsx(_components.code, {\n        children: \"undefined\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.a, {\n        href: \"https://www.typescriptlang.org/play/?#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTIAOSQ9BkANOwpnGRcNBkQAB5wFk7yeQUcYuI08CS0EPkEBAB0PS5uwB7sOrr6COb0yKD0ikjIALzIVrb2DtgNaTRGZBBEIBBkyDohbGMgtOjyXSToTA5TYDMQXamUx-oA9O-IAHJYYACeThQ0Cg6CguRk6jAyDAAAtgLQZNcAO6I9ROXCnc6Xa63e6PZ5FChdMDoAAy6GR0HEcDaDhCxyAA\",\n        children: \"Typescript Playground Link\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"There is a Typescript compilation flag to throw a type-error and keep our sanity: \", _jsx(_components.code, {\n        children: \"exactOptionalPropertyTypes\"\n      }), \". Enabling this flag makes Typescript show an error for \", _jsx(_components.code, {\n        children: \"makeFoo({ fieldA: undefined, fieldB: undefined, fieldC: undefined });\"\n      }), \". We can add the field to the call if it is set to a value.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.a, {\n        href: \"https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=true#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTIAOSQ9BkANOwpnGRcNBkQAB5wFk7yeQUcYuI08CS0EPkEBAB0PS5uwB7sOrr6COb0yKD0ikjIALzIVrb2DtgNaTRGZBBEIBBkuevFmyDbu-uHqRInZ6D7yDohbGMgtOjyXSToTA5TYDMQLpXChPUbjd6Ar4-P4AoFFChdMDoAAy6AA7tBxHA2g4Qk8gA\",\n        children: \"Typescript Playground Link\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"But this causes another problem: it is perfectly valid to create an initial instance of \", _jsx(_components.code, {\n        children: \"Foo\"\n      }), \" without fieldB being set (and its value being \", _jsx(_components.code, {\n        children: \"undefined\"\n      }), \"). But now our \", _jsx(_components.code, {\n        children: \"makeFoo\"\n      }), \" object doesn’t allow us to pass \", _jsx(_components.code, {\n        children: \"fieldB: undefined\"\n      }), \" anymore. Only when the interface explicitly defines fieldB as optional AND undefined does it allow us to so.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.a, {\n        href: \"https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=true#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQTZAB9kAVxBkIREBDJsCRUmQDCfZACNMJCHBCjkIcSRJsAvrlwxJCMMHQGAtnADWEDOgAUABzhR7OBINAAV-QJIAHk8APgBKGk8cdigIMHEoAzwASCVOShoAckh6QoAadjyVLiKIAA84Jx9dcsqOFVUaeBJaCAqCAgA6Yb8A4CD2cwsrBEd6ZFB6fSRkAF5kF3dPL2x27hpJaVl5ZHM4tlmQWnRdQZJ0Ji9FsGWIQeVyCnOZuZu3+8ez1e73yFEGYHQABl0AB3aCqOC9Lxxc5AA\",\n        children: \"Typescript Playground Link\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Generally this pattern without the flag is fine for creating mock data, since any type-holes would only be scoped to tests and not real production code. But the question is: can we have \", _jsx(_components.code, {\n        children: \"makeFoo\"\n      }), \" take a partial, return Foo without type-holes, and have allow \", _jsx(_components.code, {\n        children: \"undefined\"\n      }), \" for partials?\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Null-Coalescing Every Field\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Another common implementation I have seen is to add nullish coalescing to every field:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-jsx\",\n        children: \"interface Foo {\\n  fieldA: string;\\n  fieldB?: string;\\n  fieldC?: boolean | null;\\n}\\n\\nfunction makeFoo(partial?: Partial<Foo>): Foo {\\n  return {\\n\\t  fieldA: partial?.fieldA ?? 'test',\\n    fieldB: partial?.fieldB ?? 'example',\\n    fieldC: partial?.fieldC ?? false,\\n  };\\n} \\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Let’s also turn off the \", _jsx(_components.code, {\n        children: \"exactOptionalPropertyTypes\"\n      }), \" compilation flag for now.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We know every field will be set correctly, so there are no type-holes in \", _jsx(_components.code, {\n        children: \"Foo\"\n      }), \", however, we still have the problem where we cannot override a field to the \", _jsx(_components.code, {\n        children: \"unset\"\n      }), \" value of \", _jsx(_components.code, {\n        children: \"undefined\"\n      }), \" :\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.a, {\n        href: \"https://www.typescriptlang.org/play/?exactOptionalPropertyTypes=false&ssl=13&ssc=2&pln=1&pc=1#code/JYOwLgpgTgZghgYwgAgGIHt3IN4ChnIzAQA2AJgIIBcyAzmFKAOYDc+hx5AQgPw32MQrdkVJkAwn2QAjTCQhwQyAD7IQAVxIk2AX1y4Y6kAjDB0SgLZwA1hAzoAFAAc4UU3BJSACq-ckAPPYAfACUNPY47FAQYOpQSngAkASi5NTILm7AHjwAdKmUyDw8yADkkPSlADTsKZxkXDSZfnkFXEUlpRAAHnAWTvLVtRxi4k2+2Z759eIdhB60EDUEOrr6COb0yKD0ikjIALzIVrb2DtgjaTRGZBBEIBBkVZcN1yC394-IOiFsGyC0dDyXIkdBMBw7MB7CDTMQUX64f6A4Gg8GQ6Gw7gIxGbIEw1EQgFQ4wwgoUXJgdAAGXQAHdoOI4IsHCEEUA\",\n        children: \"Typescript Playground Link\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Turning on the \", _jsx(_components.code, {\n        children: \"exactOptionalPropertyTypes\"\n      }), \" also doesn’t save us here since we didn’t have a type-issue anyway, but more of a logic issue. \", _jsx(_components.code, {\n        children: \"makeFoo({ fieldB: undefined })\"\n      }), \" will still set \", _jsx(_components.code, {\n        children: \"fieldB\"\n      }), \" to \", _jsx(_components.code, {\n        children: \"example\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Allowing bad inputs\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This last approach takes the first and second approaches above and combines them using a \", _jsx(_components.code, {\n        children: \"pickOrDefault\"\n      }), \" function. Here if any value is passed into the partial, we will return it, except when that value would be incorrect in the output type:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-tsx\",\n        children: \"function isValuePresent<T extends object>(obj: T, key: keyof T): boolean {\\n    return key in obj;\\n}\\n\\nfunction pickOrDefault<T extends object, K extends keyof T>(partial: T, key: K, fallbackValue: T[K]): T[K] {\\n  if (key in partial) {\\n    return partial[key];\\n  }\\n\\n  return fallbackValue\\n}\\n\\ninterface Foo {\\n  fieldA: string;\\n  fieldB?: string;\\n  fieldC?: boolean | null;\\n}\\n\\nfunction makeFoo(partial: Partial<Foo> = {}): Foo {\\n  return {\\n\\t  fieldA: pickOrDefault(partial, 'fieldA', 'test') ?? 'test',\\n    fieldB: pickOrDefault(partial, 'fieldB', 'example'),\\n    fieldC: pickOrDefault(partial, 'fieldC', true),\\n  };\\n}\\n\\nconst instance = makeFoo({ fieldA: undefined, fieldB: undefined });\\nconsole.log(instance.fieldA);\\nconsole.log(instance.fieldB);\\n\\nconsole.log(instance.fieldA.toLowerCase());\\n\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"For each field, we prefer the input partial, except here the type mismatch for \", _jsx(_components.code, {\n        children: \"fieldA\"\n      }), \" forced us to add the default value twice, once if the partial didn’t have a value, and once if the partial had \", _jsx(_components.code, {\n        children: \"undefined\"\n      }), \" which isn’t allows in the final version of \", _jsx(_components.code, {\n        children: \"type Foo\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"While more verbose, this does eliminate the type holes the code!\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nI've discussed [full and partial objects before on this blog](/blog/post/2023-08-14-partial-objects), and in this article I'm going to investigate a common factory pattern\nin Typescript that can lead to type-holes.\nWhen writing tests or complex components, I'll often create prop factory utilities.\n\n","excerptHTML":"<p>I&#x27;ve discussed <a href=\"/blog/post/2023-08-14-partial-objects\">full and partial objects before on this blog</a>, and in this article I&#x27;m going to investigate a common factory pattern\nin Typescript that can lead to type-holes.\nWhen writing tests or complex components, I&#x27;ll often create prop factory utilities.</p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsxs(_components.p, {\n    children: [\"I've discussed \", _jsx(_components.a, {\n      href: \"/blog/post/2023-08-14-partial-objects\",\n      children: \"full and partial objects before on this blog\"\n    }), \", and in this article I'm going to investigate a common factory pattern\\nin Typescript that can lead to type-holes.\\nWhen writing tests or complex components, I'll often create prop factory utilities.\"]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["technology","programming","react","typescript"]},{"slug":"2025-06-16-gpus-best-buy-queues","date":"2025-06-16","title":"GPUs and Best Buy Queues","frontmatter":{"title":"GPUs and Best Buy Queues","tags":["technology","gpus"],"image":"do-something.jpg"},"contentRaw":"\nAt the height of the GPU craze, around 2021, when everyone was holed up in their homes due to COVID, the 30 series of Nvidia GPUs was extremely difficult to purchase. The scarcity was due to a few factors: the COVID pandemic had disrupted supply chains across the world, Taiwan was experiencing a severe drought that was impacting chip production, and cryptocurrency, especially ETH, was gaining value, making mining it was the latest GPU series incredibly lucrative.\n\n<!--truncate-->\n\nSince the supply was low and demand was high, this created two types of markets: one was the second hand market for GPUs where an \\$800 GPU could go for \\$3500 in cash when sold to someone mining cryptocurrency. Because of the massive mark up, buying and selling software to automate the process of buying GPUs when they \"dropped\" on a site was also growing as a market. These were called \"bots\" in the community, where customers trying to get a single GPU for their gaming PC were competing against hundreds of not thousands of bots flooding websites when they dropped. Common sites like Nvidia, AMD, Best Buy, and Zotac would get flooded with millions of requests when they added GPU stock the site.\n\nTo combat this, different market places tried different techniques to verify that humans were the ones trying to access the site. But due to time constraints, these never seemed to be properly implemented.\n\nZotac added a Cloudflare verification to their site that would try to verify that a user was real. The setting they used though attempted to not disrupt real users, but only issue a challenge to visitors it deemed \"bots\". A puppeteer script could easily bypass this by first visiting other sites that used cloud flare (but didn't issue challenges) and then visiting the Zotac site. A fresh puppeteer instance would be issued a challenge, but one that visited other sites before would not.\n\nThere were other tricks people used to help them attempt to secure GPUs. My favorite was adding a Zotac TShirt to your cart before a drop so that you could input all of your shipping and payment information. Then when a drop was detected, you'd simply issue the add to cart API call, and then the checkout API call. This would bypass the checkout walkthrough. When the website was flooded with millions of API calls, you only needed two API calls to succeed, rather than 10 or more.\n\n![Do something zotac](/media/2025-06-16-gpus-best-buy-queues/do-something.jpg)\n\nAutomating this way worked so well that a puppeteer script that I wrote was able to add 4 GPUs to one cart, send me a Pushbullet notification to wake me up in the middle of the night, and I just had to click one last step to verify the checkout manually since I didn't trust a script with actually making card payments on my behalf.\n\nZotac did finally learn from this and finally upped the Cloudflare bot check to issue a challenge to all users during the rest of the 30 series release. They also released a new site that made it harder to track when GPU stock was released.\n\nBest Buy must have had many complaints about the terrible system they had. Any GPU stock they had would almost immediately be gone by the time s human would show up to try to purchase one. At the time, they had a graphql-like API that allowed anyone to request with any frequency the in-stock status of any number of skus on their system. If you used puppeteer to visit the site, grab the cookies, and then issue an API request to this API, you could consistently check the status of all GPU skus every 5 or so seconds for the entire day. No rate limits, no other form of authentication other than public cookies.\n\nSo that explained how bots were able to detect GPUs so quickly and with no form of bot checking or challenge system, once the GPU was in someone's cart, it was very easy to checkout since the Best Buy site would continue to work even when flooded with requests.\n\nTo mitigate this, some poor group of developers was tasked with creating a queue system. I'm guessing the time crunch was real because when I went to investigate how this queue worked, it was entirely determined by the user cookie that was issued.\n\nHere's how the queue worked for the end user: the user would get a notification from their favorite discord server that there was a drop (since the graphql-like endpoint was still available). They would go to the page for the GPU they wanted to purchase and click \"add to cart\". The button would then change to a \"waiting in queue\" message and be disabled. There was no indication how long that queue would be. Then after some time, the button would change back to \"add to cart\". The user clicks it, and if there was still stock, the GPU would be added to cart. Then the user needed to quickly checkout before the stock ran out.\n\nI was really curious on the part where there was no indication of how long the queue was. When testing using a 5950 AMD CPU that still had stock, but had the queue system enabled, I determined that the wait time was effectively random. It didn't matter if you were the first one to click that button, it would just assign a random queue time to you before you could cart the item.\n\nI ran more tests. I recorded a small sample of wait times and they would vary from a minute to over an hour.\n\nI decided to investigate what code determined when the button changed back to \"add to cart\". No API calls were made while waiting in queue. Huh okay so the browser code already knows how long the queue time is.\n\nThe UI code on the Best Buy site is not just minified, but also mangled. This process will replace function names, introduce additional function calls to obfuscate what functions are doing, and generally makes it very difficult to debug. After tracing back what changed the button and the call stack, I was able to finally piece together how the queue time was determined.\n\nWhen a user visited the best buy site, they were issued a public cookie. It looked like a special UUID. The middle section of the UUID must have some special properties to meet some hash check value from what I could tell. The point is that I must have had some guaranteed randomness to it that gave the developers the idea to reuse this section to deterministically evaluate a queue time on both the browser and the server.\n\nI created a browser extension to test the hypothesis:\n\n1. Show the queue time for the current cookie on the page by injecting some HTML.\n2. Add a button to \"roll for a better queue time\". This would issue a request to get 20 new cookies, figure out which queue time was best, set the browser cookie to that cookies and display the new queue time.\n\nI tested with the 5950 CPU and saw my queue time go from 30 minutes to 1 minute. Success!\n\n![Queue times](/media/2025-06-16-gpus-best-buy-queues/queue-times.png)\n\nI had a close group of friends that I rolled this out to. The next Best Buy drop happened and we were all able to get the founders edition cards. Finally!\n\nThere was a popular bot net that effectively did the same thing. I don't know if they knew how to calculate the queue times, but they would spin up 20+ browsers with the best buy site and wait for the first one to have the add to cart button, and then give the purchaser of the bot net subscription the cookies for that session.\n\nTimes were dire and I thought this approach from best buy was garbage. It effectively made individuals - who might have stood a chance before - now have to wait some random amount of time against those with those who had hundreds of bots trying to get a good queue time.\n\nConveniently someone reached out to me to commission a chrome extension related to getting GPUs. They wanted to know what was possible and I told them I figured out the queue system times, and how an average person could get a better queue time. We released a branded version of my extension and some 10,000 people downloaded it.\n\nAnd then I waited for the next Best Buy drop.\n\n![A rare occurrence](/media/2025-06-16-gpus-best-buy-queues/a-rare-occurence.png)\n\nThe alert went out that there was stock.\n\n![extension](/media/2025-06-16-gpus-best-buy-queues/extension.png)\n\nAnd the website crashed 20 seconds into the drop.\n\nI was actually surprised since their site had done so well before. But I guess people rolling for new cookies 20 times in a second was enough to bring the site down momentarily.\n\nAfter that drop, Best Buy held off on GPU drops for over a month. When the next drop finally happened, they had changed the queue system slightly. The cookie was no longer the source for the queue time, and rolling for a new cookie did not give you a new queue time. Finally.\n\nYour queue position was still effectively random, but at least it could no longer be gamed by requesting new sessions. Nor could you know your queue time even if you did ask for new sessions.\n\nProps to Best Buy for continuing to experience with this too. Pokemon cards are the new drops and they force people to use the mobile app now to request a time in queue.\n","contentHTML":"<p>At the height of the GPU craze, around 2021, when everyone was holed up in their homes due to COVID, the 30 series of Nvidia GPUs was extremely difficult to purchase. The scarcity was due to a few factors: the COVID pandemic had disrupted supply chains across the world, Taiwan was experiencing a severe drought that was impacting chip production, and cryptocurrency, especially ETH, was gaining value, making mining it was the latest GPU series incredibly lucrative.</p>\n<p>Since the supply was low and demand was high, this created two types of markets: one was the second hand market for GPUs where an $800 GPU could go for $3500 in cash when sold to someone mining cryptocurrency. Because of the massive mark up, buying and selling software to automate the process of buying GPUs when they &quot;dropped&quot; on a site was also growing as a market. These were called &quot;bots&quot; in the community, where customers trying to get a single GPU for their gaming PC were competing against hundreds of not thousands of bots flooding websites when they dropped. Common sites like Nvidia, AMD, Best Buy, and Zotac would get flooded with millions of requests when they added GPU stock the site.</p>\n<p>To combat this, different market places tried different techniques to verify that humans were the ones trying to access the site. But due to time constraints, these never seemed to be properly implemented.</p>\n<p>Zotac added a Cloudflare verification to their site that would try to verify that a user was real. The setting they used though attempted to not disrupt real users, but only issue a challenge to visitors it deemed &quot;bots&quot;. A puppeteer script could easily bypass this by first visiting other sites that used cloud flare (but didn&#x27;t issue challenges) and then visiting the Zotac site. A fresh puppeteer instance would be issued a challenge, but one that visited other sites before would not.</p>\n<p>There were other tricks people used to help them attempt to secure GPUs. My favorite was adding a Zotac TShirt to your cart before a drop so that you could input all of your shipping and payment information. Then when a drop was detected, you&#x27;d simply issue the add to cart API call, and then the checkout API call. This would bypass the checkout walkthrough. When the website was flooded with millions of API calls, you only needed two API calls to succeed, rather than 10 or more.</p>\n<p><img alt=\"Do something zotac\" src=\"/media/2025-06-16-gpus-best-buy-queues/do-something.jpg\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p>Automating this way worked so well that a puppeteer script that I wrote was able to add 4 GPUs to one cart, send me a Pushbullet notification to wake me up in the middle of the night, and I just had to click one last step to verify the checkout manually since I didn&#x27;t trust a script with actually making card payments on my behalf.</p>\n<p>Zotac did finally learn from this and finally upped the Cloudflare bot check to issue a challenge to all users during the rest of the 30 series release. They also released a new site that made it harder to track when GPU stock was released.</p>\n<p>Best Buy must have had many complaints about the terrible system they had. Any GPU stock they had would almost immediately be gone by the time s human would show up to try to purchase one. At the time, they had a graphql-like API that allowed anyone to request with any frequency the in-stock status of any number of skus on their system. If you used puppeteer to visit the site, grab the cookies, and then issue an API request to this API, you could consistently check the status of all GPU skus every 5 or so seconds for the entire day. No rate limits, no other form of authentication other than public cookies.</p>\n<p>So that explained how bots were able to detect GPUs so quickly and with no form of bot checking or challenge system, once the GPU was in someone&#x27;s cart, it was very easy to checkout since the Best Buy site would continue to work even when flooded with requests.</p>\n<p>To mitigate this, some poor group of developers was tasked with creating a queue system. I&#x27;m guessing the time crunch was real because when I went to investigate how this queue worked, it was entirely determined by the user cookie that was issued.</p>\n<p>Here&#x27;s how the queue worked for the end user: the user would get a notification from their favorite discord server that there was a drop (since the graphql-like endpoint was still available). They would go to the page for the GPU they wanted to purchase and click &quot;add to cart&quot;. The button would then change to a &quot;waiting in queue&quot; message and be disabled. There was no indication how long that queue would be. Then after some time, the button would change back to &quot;add to cart&quot;. The user clicks it, and if there was still stock, the GPU would be added to cart. Then the user needed to quickly checkout before the stock ran out.</p>\n<p>I was really curious on the part where there was no indication of how long the queue was. When testing using a 5950 AMD CPU that still had stock, but had the queue system enabled, I determined that the wait time was effectively random. It didn&#x27;t matter if you were the first one to click that button, it would just assign a random queue time to you before you could cart the item.</p>\n<p>I ran more tests. I recorded a small sample of wait times and they would vary from a minute to over an hour.</p>\n<p>I decided to investigate what code determined when the button changed back to &quot;add to cart&quot;. No API calls were made while waiting in queue. Huh okay so the browser code already knows how long the queue time is.</p>\n<p>The UI code on the Best Buy site is not just minified, but also mangled. This process will replace function names, introduce additional function calls to obfuscate what functions are doing, and generally makes it very difficult to debug. After tracing back what changed the button and the call stack, I was able to finally piece together how the queue time was determined.</p>\n<p>When a user visited the best buy site, they were issued a public cookie. It looked like a special UUID. The middle section of the UUID must have some special properties to meet some hash check value from what I could tell. The point is that I must have had some guaranteed randomness to it that gave the developers the idea to reuse this section to deterministically evaluate a queue time on both the browser and the server.</p>\n<p>I created a browser extension to test the hypothesis:</p>\n<ol>\n<li>Show the queue time for the current cookie on the page by injecting some HTML.</li>\n<li>Add a button to &quot;roll for a better queue time&quot;. This would issue a request to get 20 new cookies, figure out which queue time was best, set the browser cookie to that cookies and display the new queue time.</li>\n</ol>\n<p>I tested with the 5950 CPU and saw my queue time go from 30 minutes to 1 minute. Success!</p>\n<p><img alt=\"Queue times\" src=\"/media/2025-06-16-gpus-best-buy-queues/queue-times.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p>I had a close group of friends that I rolled this out to. The next Best Buy drop happened and we were all able to get the founders edition cards. Finally!</p>\n<p>There was a popular bot net that effectively did the same thing. I don&#x27;t know if they knew how to calculate the queue times, but they would spin up 20+ browsers with the best buy site and wait for the first one to have the add to cart button, and then give the purchaser of the bot net subscription the cookies for that session.</p>\n<p>Times were dire and I thought this approach from best buy was garbage. It effectively made individuals - who might have stood a chance before - now have to wait some random amount of time against those with those who had hundreds of bots trying to get a good queue time.</p>\n<p>Conveniently someone reached out to me to commission a chrome extension related to getting GPUs. They wanted to know what was possible and I told them I figured out the queue system times, and how an average person could get a better queue time. We released a branded version of my extension and some 10,000 people downloaded it.</p>\n<p>And then I waited for the next Best Buy drop.</p>\n<p><img alt=\"A rare occurrence\" src=\"/media/2025-06-16-gpus-best-buy-queues/a-rare-occurence.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p>The alert went out that there was stock.</p>\n<p><img alt=\"extension\" src=\"/media/2025-06-16-gpus-best-buy-queues/extension.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p>And the website crashed 20 seconds into the drop.</p>\n<p>I was actually surprised since their site had done so well before. But I guess people rolling for new cookies 20 times in a second was enough to bring the site down momentarily.</p>\n<p>After that drop, Best Buy held off on GPU drops for over a month. When the next drop finally happened, they had changed the queue system slightly. The cookie was no longer the source for the queue time, and rolling for a new cookie did not give you a new queue time. Finally.</p>\n<p>Your queue position was still effectively random, but at least it could no longer be gamed by requesting new sessions. Nor could you know your queue time even if you did ask for new sessions.</p>\n<p>Props to Best Buy for continuing to experience with this too. Pokemon cards are the new drops and they force people to use the mobile app now to request a time in queue.</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    img: \"img\",\n    li: \"li\",\n    ol: \"ol\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"At the height of the GPU craze, around 2021, when everyone was holed up in their homes due to COVID, the 30 series of Nvidia GPUs was extremely difficult to purchase. The scarcity was due to a few factors: the COVID pandemic had disrupted supply chains across the world, Taiwan was experiencing a severe drought that was impacting chip production, and cryptocurrency, especially ETH, was gaining value, making mining it was the latest GPU series incredibly lucrative.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Since the supply was low and demand was high, this created two types of markets: one was the second hand market for GPUs where an $800 GPU could go for $3500 in cash when sold to someone mining cryptocurrency. Because of the massive mark up, buying and selling software to automate the process of buying GPUs when they \\\"dropped\\\" on a site was also growing as a market. These were called \\\"bots\\\" in the community, where customers trying to get a single GPU for their gaming PC were competing against hundreds of not thousands of bots flooding websites when they dropped. Common sites like Nvidia, AMD, Best Buy, and Zotac would get flooded with millions of requests when they added GPU stock the site.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To combat this, different market places tried different techniques to verify that humans were the ones trying to access the site. But due to time constraints, these never seemed to be properly implemented.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Zotac added a Cloudflare verification to their site that would try to verify that a user was real. The setting they used though attempted to not disrupt real users, but only issue a challenge to visitors it deemed \\\"bots\\\". A puppeteer script could easily bypass this by first visiting other sites that used cloud flare (but didn't issue challenges) and then visiting the Zotac site. A fresh puppeteer instance would be issued a challenge, but one that visited other sites before would not.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"There were other tricks people used to help them attempt to secure GPUs. My favorite was adding a Zotac TShirt to your cart before a drop so that you could input all of your shipping and payment information. Then when a drop was detected, you'd simply issue the add to cart API call, and then the checkout API call. This would bypass the checkout walkthrough. When the website was flooded with millions of API calls, you only needed two API calls to succeed, rather than 10 or more.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2025-06-16-gpus-best-buy-queues/do-something.jpg\",\n        alt: \"Do something zotac\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Automating this way worked so well that a puppeteer script that I wrote was able to add 4 GPUs to one cart, send me a Pushbullet notification to wake me up in the middle of the night, and I just had to click one last step to verify the checkout manually since I didn't trust a script with actually making card payments on my behalf.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Zotac did finally learn from this and finally upped the Cloudflare bot check to issue a challenge to all users during the rest of the 30 series release. They also released a new site that made it harder to track when GPU stock was released.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Best Buy must have had many complaints about the terrible system they had. Any GPU stock they had would almost immediately be gone by the time s human would show up to try to purchase one. At the time, they had a graphql-like API that allowed anyone to request with any frequency the in-stock status of any number of skus on their system. If you used puppeteer to visit the site, grab the cookies, and then issue an API request to this API, you could consistently check the status of all GPU skus every 5 or so seconds for the entire day. No rate limits, no other form of authentication other than public cookies.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So that explained how bots were able to detect GPUs so quickly and with no form of bot checking or challenge system, once the GPU was in someone's cart, it was very easy to checkout since the Best Buy site would continue to work even when flooded with requests.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To mitigate this, some poor group of developers was tasked with creating a queue system. I'm guessing the time crunch was real because when I went to investigate how this queue worked, it was entirely determined by the user cookie that was issued.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Here's how the queue worked for the end user: the user would get a notification from their favorite discord server that there was a drop (since the graphql-like endpoint was still available). They would go to the page for the GPU they wanted to purchase and click \\\"add to cart\\\". The button would then change to a \\\"waiting in queue\\\" message and be disabled. There was no indication how long that queue would be. Then after some time, the button would change back to \\\"add to cart\\\". The user clicks it, and if there was still stock, the GPU would be added to cart. Then the user needed to quickly checkout before the stock ran out.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I was really curious on the part where there was no indication of how long the queue was. When testing using a 5950 AMD CPU that still had stock, but had the queue system enabled, I determined that the wait time was effectively random. It didn't matter if you were the first one to click that button, it would just assign a random queue time to you before you could cart the item.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I ran more tests. I recorded a small sample of wait times and they would vary from a minute to over an hour.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I decided to investigate what code determined when the button changed back to \\\"add to cart\\\". No API calls were made while waiting in queue. Huh okay so the browser code already knows how long the queue time is.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The UI code on the Best Buy site is not just minified, but also mangled. This process will replace function names, introduce additional function calls to obfuscate what functions are doing, and generally makes it very difficult to debug. After tracing back what changed the button and the call stack, I was able to finally piece together how the queue time was determined.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When a user visited the best buy site, they were issued a public cookie. It looked like a special UUID. The middle section of the UUID must have some special properties to meet some hash check value from what I could tell. The point is that I must have had some guaranteed randomness to it that gave the developers the idea to reuse this section to deterministically evaluate a queue time on both the browser and the server.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I created a browser extension to test the hypothesis:\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Show the queue time for the current cookie on the page by injecting some HTML.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Add a button to \\\"roll for a better queue time\\\". This would issue a request to get 20 new cookies, figure out which queue time was best, set the browser cookie to that cookies and display the new queue time.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I tested with the 5950 CPU and saw my queue time go from 30 minutes to 1 minute. Success!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2025-06-16-gpus-best-buy-queues/queue-times.png\",\n        alt: \"Queue times\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I had a close group of friends that I rolled this out to. The next Best Buy drop happened and we were all able to get the founders edition cards. Finally!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"There was a popular bot net that effectively did the same thing. I don't know if they knew how to calculate the queue times, but they would spin up 20+ browsers with the best buy site and wait for the first one to have the add to cart button, and then give the purchaser of the bot net subscription the cookies for that session.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Times were dire and I thought this approach from best buy was garbage. It effectively made individuals - who might have stood a chance before - now have to wait some random amount of time against those with those who had hundreds of bots trying to get a good queue time.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Conveniently someone reached out to me to commission a chrome extension related to getting GPUs. They wanted to know what was possible and I told them I figured out the queue system times, and how an average person could get a better queue time. We released a branded version of my extension and some 10,000 people downloaded it.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And then I waited for the next Best Buy drop.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2025-06-16-gpus-best-buy-queues/a-rare-occurence.png\",\n        alt: \"A rare occurrence\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The alert went out that there was stock.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2025-06-16-gpus-best-buy-queues/extension.png\",\n        alt: \"extension\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And the website crashed 20 seconds into the drop.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I was actually surprised since their site had done so well before. But I guess people rolling for new cookies 20 times in a second was enough to bring the site down momentarily.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"After that drop, Best Buy held off on GPU drops for over a month. When the next drop finally happened, they had changed the queue system slightly. The cookie was no longer the source for the queue time, and rolling for a new cookie did not give you a new queue time. Finally.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Your queue position was still effectively random, but at least it could no longer be gamed by requesting new sessions. Nor could you know your queue time even if you did ask for new sessions.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Props to Best Buy for continuing to experience with this too. Pokemon cards are the new drops and they force people to use the mobile app now to request a time in queue.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nAt the height of the GPU craze, around 2021, when everyone was holed up in their homes due to COVID, the 30 series of Nvidia GPUs was extremely difficult to purchase. The scarcity was due to a few factors: the COVID pandemic had disrupted supply chains across the world, Taiwan was experiencing a severe drought that was impacting chip production, and cryptocurrency, especially ETH, was gaining value, making mining it was the latest GPU series incredibly lucrative.\n\n","excerptHTML":"<p>At the height of the GPU craze, around 2021, when everyone was holed up in their homes due to COVID, the 30 series of Nvidia GPUs was extremely difficult to purchase. The scarcity was due to a few factors: the COVID pandemic had disrupted supply chains across the world, Taiwan was experiencing a severe drought that was impacting chip production, and cryptocurrency, especially ETH, was gaining value, making mining it was the latest GPU series incredibly lucrative.</p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    p: \"p\",\n    ...props.components\n  };\n  return _jsx(_components.p, {\n    children: \"At the height of the GPU craze, around 2021, when everyone was holed up in their homes due to COVID, the 30 series of Nvidia GPUs was extremely difficult to purchase. The scarcity was due to a few factors: the COVID pandemic had disrupted supply chains across the world, Taiwan was experiencing a severe drought that was impacting chip production, and cryptocurrency, especially ETH, was gaining value, making mining it was the latest GPU series incredibly lucrative.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["technology","gpus"]}]},"__N_SSG":true}