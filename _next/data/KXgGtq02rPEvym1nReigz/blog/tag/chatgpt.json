{"pageProps":{"headTitle":"chatgpt posts - idmontie's Portfolio","headKeywords":"chatgpt","tag":"chatgpt","posts":[{"slug":"2023-07-23-chatgpt-coding-loop","date":"2023-07-23","title":"ChatGPT, Coding, and Language","frontmatter":{"title":"ChatGPT, Coding, and Language","tags":["chatgpt"]},"contentRaw":"\nI’ve been experimenting with ChatGPT, just like everyone else. But why has it become so popular? It truly is a revolutionary piece of technology. Is it The Next Big Thing? Will it really replace all of us?\n\nMy day to day is architecture and programming, and I’ve heard all sorts of things on Twitter:\n\n- That ChatGPT can build entire iOS applications\n- ChatGPT can write whole files of code\n- ChatGPT can find bugs in code when writing tests\n\nWhen I started by own company Clarity Hub, we had a focus on machine learning to help augment human intelligence. My thought at the time was that we could leverage machine learning to augment and supplement human intelligence. The focus wouldn't be to replace any person's job, but to make it streamlined and easier to accomplish that job. Our journey started with us serving customer success agents with suggested replies and contextual information, but we eventually pivoted to a Dovetail-like application to help product teams gather, annotate, and contextualize customer interviews.\n\nWe found that augmenting activity with machine learning was not only easier to do from a technology point of view, but empowered users, rather than make them feel like their job was being replaced.\n\nEven with the advent of ChatGPT, I still see this being the short term future of it's use.\n\n## False Starts\n\nI was curious how much ChatGPT could really do given all of its hype  \n\nI asked it to build an Asteroids game using PhaserJS. Don’t worry, this isn’t another article on “Look, I got ChatGPT to build a game!”\n\nI originally just asked ChatGPT to build an Asteroids game using PhaserJS. A very vague prompt, yes, but a great starting point to figure out the limitations of ChatGPT.\n\nThe response was basically, “No I can’t”:\n\n> As an AI language model, I'm not able to write and execute code in real-time. However, I can provide you with a detailed framework to get started with creating an Asteroids game in PhaserJS.\n\nThis was followed by instructions on how I could do it myself.\n\nThe next steps of course are to be more specific, asking ChatGPT to build the application to build specific functionality:\n\n> Add the code to let the player shoot asteroids. If the player gets hit by 3 asteroids, its game over\n\nMost interactions with ChatGPT seem to go like this:\n\n![Flowchart workflow](/media/2023-07-23-chatgpt-coding-loop/Flowchart_Template_1.jpg)\n\nThis flow eventually leads to either:\n\n- Not getting what you want.\n- Getting what you want across many different responses, and then you must manually coalesce all of the different responses together to form the result you want.\n\nOnce I like the set of responses that ChatGPT has given me, I’ll ask ChatGPT to summarize for me so that I can improve the prompt further:\n\n> Take everything we just talked about and give me a prompt to ask you in the future that encapsulates all of the requirements.\n\n## A More Natural Flow\n\nI’ve talked with ChatGPT on a variety of topics, but the majority of questions relate to coding. I actively use Github Copilot, which utilizes the ChatGPT engine in the backend. I’ve built [Sora by Capsule Cat](https://marketplace.visualstudio.com/items?itemName=CapsuleCat.sora-by-capsule-cat) to have ChatGPT generate entire coding files for me as well with project context. Even then, I still use the ChatGPT UI as well.\n\n![Flowchart line](/media/2023-07-23-chatgpt-coding-loop/Flowchart_Template_2.jpg)\n\nI find that the above flow leaves me less fatigued, and more productive - at least in the context of side-projects that I’ve used ChatGPT. Research shows that when we read code and attempt logic puzzles, we use a completely different part of our brain than when we use language [[link](https://hub.jhu.edu/2020/12/17/brain-activity-while-reading-code/)]. In the above chart, you can imagine that when we write prompts, we utilize some logical reasoning, but we lean heavily on language as we talk with ChatGPT. Then when we get a response, a completely different part of the brain kicks in to read and write code.\n\n## The Hard Part About Coding\n\nEventually this leads to “the hard part about coding” which anecdotally everyone will tell you that surprise, it isn’t the coding part. What is nice about ChatGPT though is that even though the hard part isn’t writing code, it does take time, thought, and energy.\n\nIf the hard part of coding isn’t coding, then what is it? The non-exhaustive list is that it’s teamwork, communication, debugging, and requirements gathering. Oversimplifying, it’s the writing prompts part of the chart.\n","contentHTML":"<p>I’ve been experimenting with ChatGPT, just like everyone else. But why has it become so popular? It truly is a revolutionary piece of technology. Is it The Next Big Thing? Will it really replace all of us?</p>\n<p>My day to day is architecture and programming, and I’ve heard all sorts of things on Twitter:</p>\n<ul>\n<li>That ChatGPT can build entire iOS applications</li>\n<li>ChatGPT can write whole files of code</li>\n<li>ChatGPT can find bugs in code when writing tests</li>\n</ul>\n<p>When I started by own company Clarity Hub, we had a focus on machine learning to help augment human intelligence. My thought at the time was that we could leverage machine learning to augment and supplement human intelligence. The focus wouldn&#x27;t be to replace any person&#x27;s job, but to make it streamlined and easier to accomplish that job. Our journey started with us serving customer success agents with suggested replies and contextual information, but we eventually pivoted to a Dovetail-like application to help product teams gather, annotate, and contextualize customer interviews.</p>\n<p>We found that augmenting activity with machine learning was not only easier to do from a technology point of view, but empowered users, rather than make them feel like their job was being replaced.</p>\n<p>Even with the advent of ChatGPT, I still see this being the short term future of it&#x27;s use.</p>\n<h2>False Starts</h2>\n<p>I was curious how much ChatGPT could really do given all of its hype</p>\n<p>I asked it to build an Asteroids game using PhaserJS. Don’t worry, this isn’t another article on “Look, I got ChatGPT to build a game!”</p>\n<p>I originally just asked ChatGPT to build an Asteroids game using PhaserJS. A very vague prompt, yes, but a great starting point to figure out the limitations of ChatGPT.</p>\n<p>The response was basically, “No I can’t”:</p>\n<blockquote class=\"border-l-4 border-gray-300 pl-4\">\n<p>As an AI language model, I&#x27;m not able to write and execute code in real-time. However, I can provide you with a detailed framework to get started with creating an Asteroids game in PhaserJS.</p>\n</blockquote>\n<p>This was followed by instructions on how I could do it myself.</p>\n<p>The next steps of course are to be more specific, asking ChatGPT to build the application to build specific functionality:</p>\n<blockquote class=\"border-l-4 border-gray-300 pl-4\">\n<p>Add the code to let the player shoot asteroids. If the player gets hit by 3 asteroids, its game over</p>\n</blockquote>\n<p>Most interactions with ChatGPT seem to go like this:</p>\n<p><img alt=\"Flowchart workflow\" src=\"/media/2023-07-23-chatgpt-coding-loop/Flowchart_Template_1.jpg\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p>This flow eventually leads to either:</p>\n<ul>\n<li>Not getting what you want.</li>\n<li>Getting what you want across many different responses, and then you must manually coalesce all of the different responses together to form the result you want.</li>\n</ul>\n<p>Once I like the set of responses that ChatGPT has given me, I’ll ask ChatGPT to summarize for me so that I can improve the prompt further:</p>\n<blockquote class=\"border-l-4 border-gray-300 pl-4\">\n<p>Take everything we just talked about and give me a prompt to ask you in the future that encapsulates all of the requirements.</p>\n</blockquote>\n<h2>A More Natural Flow</h2>\n<p>I’ve talked with ChatGPT on a variety of topics, but the majority of questions relate to coding. I actively use Github Copilot, which utilizes the ChatGPT engine in the backend. I’ve built <a href=\"https://marketplace.visualstudio.com/items?itemName=CapsuleCat.sora-by-capsule-cat\">Sora by Capsule Cat</a> to have ChatGPT generate entire coding files for me as well with project context. Even then, I still use the ChatGPT UI as well.</p>\n<p><img alt=\"Flowchart line\" src=\"/media/2023-07-23-chatgpt-coding-loop/Flowchart_Template_2.jpg\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p>I find that the above flow leaves me less fatigued, and more productive - at least in the context of side-projects that I’ve used ChatGPT. Research shows that when we read code and attempt logic puzzles, we use a completely different part of our brain than when we use language [<a href=\"https://hub.jhu.edu/2020/12/17/brain-activity-while-reading-code/\">link</a>]. In the above chart, you can imagine that when we write prompts, we utilize some logical reasoning, but we lean heavily on language as we talk with ChatGPT. Then when we get a response, a completely different part of the brain kicks in to read and write code.</p>\n<h2>The Hard Part About Coding</h2>\n<p>Eventually this leads to “the hard part about coding” which anecdotally everyone will tell you that surprise, it isn’t the coding part. What is nice about ChatGPT though is that even though the hard part isn’t writing code, it does take time, thought, and energy.</p>\n<p>If the hard part of coding isn’t coding, then what is it? The non-exhaustive list is that it’s teamwork, communication, debugging, and requirements gathering. Oversimplifying, it’s the writing prompts part of the chart.</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    blockquote: \"blockquote\",\n    h2: \"h2\",\n    img: \"img\",\n    li: \"li\",\n    p: \"p\",\n    ul: \"ul\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"I’ve been experimenting with ChatGPT, just like everyone else. But why has it become so popular? It truly is a revolutionary piece of technology. Is it The Next Big Thing? Will it really replace all of us?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"My day to day is architecture and programming, and I’ve heard all sorts of things on Twitter:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"That ChatGPT can build entire iOS applications\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"ChatGPT can write whole files of code\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"ChatGPT can find bugs in code when writing tests\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When I started by own company Clarity Hub, we had a focus on machine learning to help augment human intelligence. My thought at the time was that we could leverage machine learning to augment and supplement human intelligence. The focus wouldn't be to replace any person's job, but to make it streamlined and easier to accomplish that job. Our journey started with us serving customer success agents with suggested replies and contextual information, but we eventually pivoted to a Dovetail-like application to help product teams gather, annotate, and contextualize customer interviews.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We found that augmenting activity with machine learning was not only easier to do from a technology point of view, but empowered users, rather than make them feel like their job was being replaced.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Even with the advent of ChatGPT, I still see this being the short term future of it's use.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"False Starts\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I was curious how much ChatGPT could really do given all of its hype\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I asked it to build an Asteroids game using PhaserJS. Don’t worry, this isn’t another article on “Look, I got ChatGPT to build a game!”\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I originally just asked ChatGPT to build an Asteroids game using PhaserJS. A very vague prompt, yes, but a great starting point to figure out the limitations of ChatGPT.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The response was basically, “No I can’t”:\"\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"As an AI language model, I'm not able to write and execute code in real-time. However, I can provide you with a detailed framework to get started with creating an Asteroids game in PhaserJS.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This was followed by instructions on how I could do it myself.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The next steps of course are to be more specific, asking ChatGPT to build the application to build specific functionality:\"\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"Add the code to let the player shoot asteroids. If the player gets hit by 3 asteroids, its game over\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Most interactions with ChatGPT seem to go like this:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-07-23-chatgpt-coding-loop/Flowchart_Template_1.jpg\",\n        alt: \"Flowchart workflow\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This flow eventually leads to either:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Not getting what you want.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Getting what you want across many different responses, and then you must manually coalesce all of the different responses together to form the result you want.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Once I like the set of responses that ChatGPT has given me, I’ll ask ChatGPT to summarize for me so that I can improve the prompt further:\"\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"Take everything we just talked about and give me a prompt to ask you in the future that encapsulates all of the requirements.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"A More Natural Flow\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"I’ve talked with ChatGPT on a variety of topics, but the majority of questions relate to coding. I actively use Github Copilot, which utilizes the ChatGPT engine in the backend. I’ve built \", _jsx(_components.a, {\n        href: \"https://marketplace.visualstudio.com/items?itemName=CapsuleCat.sora-by-capsule-cat\",\n        children: \"Sora by Capsule Cat\"\n      }), \" to have ChatGPT generate entire coding files for me as well with project context. Even then, I still use the ChatGPT UI as well.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-07-23-chatgpt-coding-loop/Flowchart_Template_2.jpg\",\n        alt: \"Flowchart line\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"I find that the above flow leaves me less fatigued, and more productive - at least in the context of side-projects that I’ve used ChatGPT. Research shows that when we read code and attempt logic puzzles, we use a completely different part of our brain than when we use language [\", _jsx(_components.a, {\n        href: \"https://hub.jhu.edu/2020/12/17/brain-activity-while-reading-code/\",\n        children: \"link\"\n      }), \"]. In the above chart, you can imagine that when we write prompts, we utilize some logical reasoning, but we lean heavily on language as we talk with ChatGPT. Then when we get a response, a completely different part of the brain kicks in to read and write code.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"The Hard Part About Coding\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Eventually this leads to “the hard part about coding” which anecdotally everyone will tell you that surprise, it isn’t the coding part. What is nice about ChatGPT though is that even though the hard part isn’t writing code, it does take time, thought, and energy.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If the hard part of coding isn’t coding, then what is it? The non-exhaustive list is that it’s teamwork, communication, debugging, and requirements gathering. Oversimplifying, it’s the writing prompts part of the chart.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nI’ve been experimenting with ChatGPT, just like everyone else. But why has it become so popular? It truly is a revolutionary piece of technology. Is it The Next Big Thing? Will it really replace all of us?","excerptHTML":"<p>I’ve been experimenting with ChatGPT, just like everyone else. But why has it become so popular? It truly is a revolutionary piece of technology. Is it The Next Big Thing? Will it really replace all of us?</p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    p: \"p\",\n    ...props.components\n  };\n  return _jsx(_components.p, {\n    children: \"I’ve been experimenting with ChatGPT, just like everyone else. But why has it become so popular? It truly is a revolutionary piece of technology. Is it The Next Big Thing? Will it really replace all of us?\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["chatgpt"]},{"slug":"2023-01-24-chat-gpt-doesnt-understand","date":"2023-01-24","title":"ChatGPT Doesn't Understand","frontmatter":{"title":"ChatGPT Doesn't Understand","tags":["openai","chatgpt"]},"contentRaw":"\nLooks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether [ChatGPT can play 20 questions](https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff). The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.\n\nI attempted to do 20 questions with ChatGPT using a different prompt:\n\n*Me: I would like to play a game. It's called twenty questions. You will ask me one question at a time and I will answer it. The goal is for you guess the thing I am thinking about.*\n\n*ChatGPT: Sure, I'd be happy to play \"Twenty Questions\" with you. Please go ahead and think of something, and I will start asking my first question.*\n\n*Me: I am ready*\n\n*ChatGPT: Great, here is my first question: Is the thing you are thinking of an object?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object something that you can hold in your hand?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object something that you would typically find in a kitchen?*\n\n*Me: No*\n\n*ChatGPT: Is the object something that you would use for transportation?*\n\n*Me: No*\n\n*ChatGPT: Is the object something that you would use for entertainment or leisure?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object a musical instrument?*\n\n*Me: No*\n\n*ChatGPT: Is the object a type of game or puzzle?*\n\n*Me: No*\n\n*ChatGPT: Is the object a piece of technology such as a phone or computer?*\n\n*Me: No*\n\n*ChatGPT: Is the object a book or magazine?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object a novel or a collection of short stories?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object a specific book that is widely known and read?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object \"To Kill a Mockingbird\" by Harper Lee?*\n\n*Me: No*\n\n*ChatGPT: I'm sorry, I'm running out of ideas. Can you give me a hint or tell me the answer?*\n\nSeems like we hit a wall here with twenty questions, but ChatGPT is very close, so I decided to give a hint.\n\n*Me: You are on the right track. It is by Walt Whitman*\n\n*ChatGPT: Is the object \"Leaves of Grass\" by Walt Whitman?*\n\n*Me: Yes! Congratulations!*\n\n*ChatGPT: Thank you! I'm glad I was able to guess the object you were thinking of. It was fun playing \"Twenty Questions\" with you. Let me know if you want to play again sometime.*\n\n---\n\nI’ve been keeping an eye on how other people are using ChatGPT, and [prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering) is one of the more fascinating aspects around how people are communicating with the AI. Prompt engineering plays a key role in communicating with models like ChatGPT. Carefully crafting prompts can help maximize the quality of the reponse. However, it is important to keep in mind that, like any AI model, ChatGPT has its own set of limitations.\n\nSo I was curious when I read that “[ChatGPT can’t write sentences that end in a specific letter](https://www.reddit.com/r/ChatGPT/comments/101e454/chatgpt_cant_write_sentences_that_end_with_a/)”. Is this a real limitation of ChatGPT, or maybe this was just a poor prompt.\n\nSo let’s start with a very simple question to ChatGPT:\n\n*Me: Can you write a sentence that ends with the letter \"a\"?*\n\n*ChatGPT: The cat sat on the mat.*\n\n*Me: That sentence does not end in the letter \"a\". Can you write a sentence that ends in the letter \"a\"?*\n\n*ChatGPT: I can't think of anything right now, but the word \"America\" ends with letter \"a\".*\n\n*Me: Great, write a sentence that ends in that word. That will then satisfy the original question.*\n\n*ChatGPT: The land of the free, and the home of the brave, America.*\n\nOkay, that does technically end in the letter a, but the sentence seems very strange.\n\n*Me: That isn't a very coherent sentence. Can you write a sentence that ends in the letter \"a\"?*\n\n*ChatGPT: I am sorry for the confusion, here is a sentence that ends with the letter \"a\" - \"He saw the drama unfold on the stage, it was quite the spectacle, a.”*\n\nLooks like we are going off the rails here. Let’s try a different approach:\n\n*Me: Write a sentence that ends in a word that ends with the letter \"a\".*\n\n*ChatGPT: The sun was setting over the horizon, painting the sky with shades of orange and red, a spectacle to behold and end the day with.*\n\nI’m going to ask ChatGPT to tell me a prompt to feed back to itself. I’ve found this useful for resetting context when having long conversations. Or if ChatGPT gets into weird states like the above response.\n\n*Me: Can you tell me how to write a prompt for you that would actually get you to write a sentence that ends in the letter \"a\".*\n\n*ChatGPT: Sure, to get me to write a sentence that ends in the letter \"a\" you could provide a prompt like: \"Write a sentence that ends with a word that ends with the letter 'a'\" or \"Can you write a sentence with a word ending in 'a' at the end of the sentence?\" . This makes it clear that the sentence should end in a word ending with the letter 'a'.*\n\n*Me: Can you write a sentence with a word ending in 'a' at the end of the sentence?*\n\n*ChatGPT: The sky was clear and blue, not a cloud in sight, perfect for a day out at the parka.*\n\n---\n\nWhile ChatGPT is great at forming sentences and even code, it seems like it has no understanding and hasn’t been trained on letters, syllables, or the concept of sentences. I've seen others get ChatGPT to create poems, but it has no concept of why words would rhyme. It can give great answers to questions, but doesn’t understand how to count how many words are in its response.\n\nOne Redditor in the link above mentions that ChatGPT fails at ASCII art. I’ve tried getting the AI to print ASCII art before, and I’ll leave you with part of a conversation I’ve had with it. This appears to be the best ASCII art I could get it to print, even after having a long conversation where I provided different ASCII art examples:\n\n*Me: Can you make ASCII art? Show me a picture of a cat.*\n\n*ChatGPT: Sure! Here is a picture of a cat using ASCII art:*\n\n```\n /\\_/\\\n( o.o )\n >^<\n\n```\n\n*I hope you like it! Is there anything else I can help with?*\n\n*Me: Can you make it more detailed*\n\n*ChatGPT: Certainly! Here is a more detailed version of an ASCII art cat:*\n\n```\n /\\_/\\\n( o.o )\n  >^<\n  | |\n  || ||\n  \\\\ //\n  // \\\\\n  \\\\_//\n  /   \\\n /     \\\n\n```\n\nWith new language models coming out, it's important to recognize what the limitations\nof the AI are. Poor responses can be a result of poorly written prompts, but there\nare times, like with letters in words with ChatGPT, where the AI just doesn't have\nthe capability to understand the question.\n","contentHTML":"<p>Looks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether <a href=\"https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff\">ChatGPT can play 20 questions</a>. The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.</p>\n<p>I attempted to do 20 questions with ChatGPT using a different prompt:</p>\n<p><em>Me: I would like to play a game. It&#x27;s called twenty questions. You will ask me one question at a time and I will answer it. The goal is for you guess the thing I am thinking about.</em></p>\n<p><em>ChatGPT: Sure, I&#x27;d be happy to play &quot;Twenty Questions&quot; with you. Please go ahead and think of something, and I will start asking my first question.</em></p>\n<p><em>Me: I am ready</em></p>\n<p><em>ChatGPT: Great, here is my first question: Is the thing you are thinking of an object?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object something that you can hold in your hand?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object something that you would typically find in a kitchen?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object something that you would use for transportation?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object something that you would use for entertainment or leisure?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object a musical instrument?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object a type of game or puzzle?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object a piece of technology such as a phone or computer?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object a book or magazine?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object a novel or a collection of short stories?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object a specific book that is widely known and read?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object &quot;To Kill a Mockingbird&quot; by Harper Lee?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: I&#x27;m sorry, I&#x27;m running out of ideas. Can you give me a hint or tell me the answer?</em></p>\n<p>Seems like we hit a wall here with twenty questions, but ChatGPT is very close, so I decided to give a hint.</p>\n<p><em>Me: You are on the right track. It is by Walt Whitman</em></p>\n<p><em>ChatGPT: Is the object &quot;Leaves of Grass&quot; by Walt Whitman?</em></p>\n<p><em>Me: Yes! Congratulations!</em></p>\n<p><em>ChatGPT: Thank you! I&#x27;m glad I was able to guess the object you were thinking of. It was fun playing &quot;Twenty Questions&quot; with you. Let me know if you want to play again sometime.</em></p>\n<hr/>\n<p>I’ve been keeping an eye on how other people are using ChatGPT, and <a href=\"https://en.wikipedia.org/wiki/Prompt_engineering\">prompt engineering</a> is one of the more fascinating aspects around how people are communicating with the AI. Prompt engineering plays a key role in communicating with models like ChatGPT. Carefully crafting prompts can help maximize the quality of the reponse. However, it is important to keep in mind that, like any AI model, ChatGPT has its own set of limitations.</p>\n<p>So I was curious when I read that “<a href=\"https://www.reddit.com/r/ChatGPT/comments/101e454/chatgpt_cant_write_sentences_that_end_with_a/\">ChatGPT can’t write sentences that end in a specific letter</a>”. Is this a real limitation of ChatGPT, or maybe this was just a poor prompt.</p>\n<p>So let’s start with a very simple question to ChatGPT:</p>\n<p><em>Me: Can you write a sentence that ends with the letter &quot;a&quot;?</em></p>\n<p><em>ChatGPT: The cat sat on the mat.</em></p>\n<p><em>Me: That sentence does not end in the letter &quot;a&quot;. Can you write a sentence that ends in the letter &quot;a&quot;?</em></p>\n<p><em>ChatGPT: I can&#x27;t think of anything right now, but the word &quot;America&quot; ends with letter &quot;a&quot;.</em></p>\n<p><em>Me: Great, write a sentence that ends in that word. That will then satisfy the original question.</em></p>\n<p><em>ChatGPT: The land of the free, and the home of the brave, America.</em></p>\n<p>Okay, that does technically end in the letter a, but the sentence seems very strange.</p>\n<p><em>Me: That isn&#x27;t a very coherent sentence. Can you write a sentence that ends in the letter &quot;a&quot;?</em></p>\n<p><em>ChatGPT: I am sorry for the confusion, here is a sentence that ends with the letter &quot;a&quot; - &quot;He saw the drama unfold on the stage, it was quite the spectacle, a.”</em></p>\n<p>Looks like we are going off the rails here. Let’s try a different approach:</p>\n<p><em>Me: Write a sentence that ends in a word that ends with the letter &quot;a&quot;.</em></p>\n<p><em>ChatGPT: The sun was setting over the horizon, painting the sky with shades of orange and red, a spectacle to behold and end the day with.</em></p>\n<p>I’m going to ask ChatGPT to tell me a prompt to feed back to itself. I’ve found this useful for resetting context when having long conversations. Or if ChatGPT gets into weird states like the above response.</p>\n<p><em>Me: Can you tell me how to write a prompt for you that would actually get you to write a sentence that ends in the letter &quot;a&quot;.</em></p>\n<p><em>ChatGPT: Sure, to get me to write a sentence that ends in the letter &quot;a&quot; you could provide a prompt like: &quot;Write a sentence that ends with a word that ends with the letter &#x27;a&#x27;&quot; or &quot;Can you write a sentence with a word ending in &#x27;a&#x27; at the end of the sentence?&quot; . This makes it clear that the sentence should end in a word ending with the letter &#x27;a&#x27;.</em></p>\n<p><em>Me: Can you write a sentence with a word ending in &#x27;a&#x27; at the end of the sentence?</em></p>\n<p><em>ChatGPT: The sky was clear and blue, not a cloud in sight, perfect for a day out at the parka.</em></p>\n<hr/>\n<p>While ChatGPT is great at forming sentences and even code, it seems like it has no understanding and hasn’t been trained on letters, syllables, or the concept of sentences. I&#x27;ve seen others get ChatGPT to create poems, but it has no concept of why words would rhyme. It can give great answers to questions, but doesn’t understand how to count how many words are in its response.</p>\n<p>One Redditor in the link above mentions that ChatGPT fails at ASCII art. I’ve tried getting the AI to print ASCII art before, and I’ll leave you with part of a conversation I’ve had with it. This appears to be the best ASCII art I could get it to print, even after having a long conversation where I provided different ASCII art examples:</p>\n<p><em>Me: Can you make ASCII art? Show me a picture of a cat.</em></p>\n<p><em>ChatGPT: Sure! Here is a picture of a cat using ASCII art:</em></p>\n<div class=\"overflow-auto rounded bg-gray-200 p-4 font-mono text-sm dark:bg-gray-800 dark:text-gray-100\"><pre><code> /\\_/\\\n( o.o )\n &gt;^&lt;\n\n</code></pre></div>\n<p><em>I hope you like it! Is there anything else I can help with?</em></p>\n<p><em>Me: Can you make it more detailed</em></p>\n<p><em>ChatGPT: Certainly! Here is a more detailed version of an ASCII art cat:</em></p>\n<div class=\"overflow-auto rounded bg-gray-200 p-4 font-mono text-sm dark:bg-gray-800 dark:text-gray-100\"><pre><code> /\\_/\\\n( o.o )\n  &gt;^&lt;\n  | |\n  || ||\n  \\\\ //\n  // \\\\\n  \\\\_//\n  /   \\\n /     \\\n\n</code></pre></div>\n<p>With new language models coming out, it&#x27;s important to recognize what the limitations\nof the AI are. Poor responses can be a result of poorly written prompts, but there\nare times, like with letters in words with ChatGPT, where the AI just doesn&#x27;t have\nthe capability to understand the question.</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    code: \"code\",\n    em: \"em\",\n    hr: \"hr\",\n    p: \"p\",\n    pre: \"pre\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"Looks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether \", _jsx(_components.a, {\n        href: \"https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff\",\n        children: \"ChatGPT can play 20 questions\"\n      }), \". The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I attempted to do 20 questions with ChatGPT using a different prompt:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: I would like to play a game. It's called twenty questions. You will ask me one question at a time and I will answer it. The goal is for you guess the thing I am thinking about.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Sure, I'd be happy to play \\\"Twenty Questions\\\" with you. Please go ahead and think of something, and I will start asking my first question.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: I am ready\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Great, here is my first question: Is the thing you are thinking of an object?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object something that you can hold in your hand?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object something that you would typically find in a kitchen?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object something that you would use for transportation?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object something that you would use for entertainment or leisure?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a musical instrument?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a type of game or puzzle?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a piece of technology such as a phone or computer?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a book or magazine?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a novel or a collection of short stories?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a specific book that is widely known and read?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object \\\"To Kill a Mockingbird\\\" by Harper Lee?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: I'm sorry, I'm running out of ideas. Can you give me a hint or tell me the answer?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Seems like we hit a wall here with twenty questions, but ChatGPT is very close, so I decided to give a hint.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: You are on the right track. It is by Walt Whitman\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object \\\"Leaves of Grass\\\" by Walt Whitman?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes! Congratulations!\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Thank you! I'm glad I was able to guess the object you were thinking of. It was fun playing \\\"Twenty Questions\\\" with you. Let me know if you want to play again sometime.\"\n      })\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsxs(_components.p, {\n      children: [\"I’ve been keeping an eye on how other people are using ChatGPT, and \", _jsx(_components.a, {\n        href: \"https://en.wikipedia.org/wiki/Prompt_engineering\",\n        children: \"prompt engineering\"\n      }), \" is one of the more fascinating aspects around how people are communicating with the AI. Prompt engineering plays a key role in communicating with models like ChatGPT. Carefully crafting prompts can help maximize the quality of the reponse. However, it is important to keep in mind that, like any AI model, ChatGPT has its own set of limitations.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"So I was curious when I read that “\", _jsx(_components.a, {\n        href: \"https://www.reddit.com/r/ChatGPT/comments/101e454/chatgpt_cant_write_sentences_that_end_with_a/\",\n        children: \"ChatGPT can’t write sentences that end in a specific letter\"\n      }), \"”. Is this a real limitation of ChatGPT, or maybe this was just a poor prompt.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So let’s start with a very simple question to ChatGPT:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you write a sentence that ends with the letter \\\"a\\\"?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: The cat sat on the mat.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: That sentence does not end in the letter \\\"a\\\". Can you write a sentence that ends in the letter \\\"a\\\"?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: I can't think of anything right now, but the word \\\"America\\\" ends with letter \\\"a\\\".\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Great, write a sentence that ends in that word. That will then satisfy the original question.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: The land of the free, and the home of the brave, America.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Okay, that does technically end in the letter a, but the sentence seems very strange.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: That isn't a very coherent sentence. Can you write a sentence that ends in the letter \\\"a\\\"?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: I am sorry for the confusion, here is a sentence that ends with the letter \\\"a\\\" - \\\"He saw the drama unfold on the stage, it was quite the spectacle, a.”\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Looks like we are going off the rails here. Let’s try a different approach:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Write a sentence that ends in a word that ends with the letter \\\"a\\\".\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: The sun was setting over the horizon, painting the sky with shades of orange and red, a spectacle to behold and end the day with.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I’m going to ask ChatGPT to tell me a prompt to feed back to itself. I’ve found this useful for resetting context when having long conversations. Or if ChatGPT gets into weird states like the above response.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you tell me how to write a prompt for you that would actually get you to write a sentence that ends in the letter \\\"a\\\".\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Sure, to get me to write a sentence that ends in the letter \\\"a\\\" you could provide a prompt like: \\\"Write a sentence that ends with a word that ends with the letter 'a'\\\" or \\\"Can you write a sentence with a word ending in 'a' at the end of the sentence?\\\" . This makes it clear that the sentence should end in a word ending with the letter 'a'.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you write a sentence with a word ending in 'a' at the end of the sentence?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: The sky was clear and blue, not a cloud in sight, perfect for a day out at the parka.\"\n      })\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsx(_components.p, {\n      children: \"While ChatGPT is great at forming sentences and even code, it seems like it has no understanding and hasn’t been trained on letters, syllables, or the concept of sentences. I've seen others get ChatGPT to create poems, but it has no concept of why words would rhyme. It can give great answers to questions, but doesn’t understand how to count how many words are in its response.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"One Redditor in the link above mentions that ChatGPT fails at ASCII art. I’ve tried getting the AI to print ASCII art before, and I’ll leave you with part of a conversation I’ve had with it. This appears to be the best ASCII art I could get it to print, even after having a long conversation where I provided different ASCII art examples:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you make ASCII art? Show me a picture of a cat.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Sure! Here is a picture of a cat using ASCII art:\"\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \" /\\\\_/\\\\\\n( o.o )\\n >^<\\n\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"I hope you like it! Is there anything else I can help with?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you make it more detailed\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Certainly! Here is a more detailed version of an ASCII art cat:\"\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \" /\\\\_/\\\\\\n( o.o )\\n  >^<\\n  | |\\n  || ||\\n  \\\\\\\\ //\\n  // \\\\\\\\\\n  \\\\\\\\_//\\n  /   \\\\\\n /     \\\\\\n\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With new language models coming out, it's important to recognize what the limitations\\nof the AI are. Poor responses can be a result of poorly written prompts, but there\\nare times, like with letters in words with ChatGPT, where the AI just doesn't have\\nthe capability to understand the question.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nLooks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether [ChatGPT can play 20 questions](https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff). The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.","excerptHTML":"<p>Looks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether <a href=\"https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff\">ChatGPT can play 20 questions</a>. The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.</p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsxs(_components.p, {\n    children: [\"Looks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether \", _jsx(_components.a, {\n      href: \"https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff\",\n      children: \"ChatGPT can play 20 questions\"\n    }), \". The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.\"]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["openai","chatgpt"]}]},"__N_SSG":true}