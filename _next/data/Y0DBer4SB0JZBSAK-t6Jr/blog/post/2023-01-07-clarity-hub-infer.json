{"pageProps":{"headTitle":"Clarity Hub Infer API - idmontie's Portfolio","headKeywords":"nlp, machine learning","post":{"slug":"2023-01-07-clarity-hub-infer","date":"2023-01-07","title":"Clarity Hub Infer API","frontmatter":{"title":"Clarity Hub Infer API","tags":["nlp","machine learning"]},"contentRaw":"\n![Screen Shot 2023-01-07 at 3.57.30 PM.png](/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png)\n\nWhile working on Clarity Hub, we created a Clarity Hub Infer API along with a developer portal that would let anyone create infer models.\n\nThe Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\n\nAt the most basic level, the Infer API would let users send utterances via an API and get toxicity analysis, sentiment scores, and simple NLP data like nouns and topics from the utterances.\n\nThe power of the Infer API is that consumers can supply a set of pre-labelled utterances to the API, and the API will create a model from this, even if there are only a few utterances used for training. Then the consumer can send a new utterance get a label using that model.\n\nThe NLP APIs at Clarity Hub were a set of APIs:\n\n```mermaid\ngraph RL\n  NLP(Clarity Hub NLP API) --> API(Clarity Hub Infer API) --> Consumer\n```\n\nThe Consumer would user the Infer API which provided APIs for training and labeling datasets and getting toxicity and sentiment analyses. the Clarity Hub NLP API contained trained Tensorflow datasets for creating embeddings via the Universal Sentence Encoder (USE).\n\nAn **embedding** a vector that represents an utterance - a sentence, sentence fragment, or paragraph of text.\n\nTraining would involve a consumer sending a payload of utterances with labels to the Infer API, which would call the NLP API internally to create embeddings. We then clustered these embeddings to and re-labelled the clusters using the given labels. If no label was found for an utterance cluster, we attempted to pull a topic out of the utterances to re-label it.\n\nThe clusters with labels were then stored into S3.\n\n```mermaid\ngraph TD\n  Train -->|Utterances with labels| USE\n  USE -->|Embeddings with labels| Clustering\n  Clustering -->|Embedding Clusters| Labeller\n  Labeller -->|Clusters with Labels| S3\n```\n\nTo classify a new utterance, we created an embedding from it, loaded the existing dataset in, then ran cosine similarity to find the most probabilistic matches:\n\n```mermaid\ngraph TD\n  Classify --> |Utterance| USE\n  USE --> |Embedding| Classifier(Classifier)\n  Classifier --> |Embedding + Clusters from S3| Similarity(Cosine Similarity)\n  Similarity --> |Labels with Probability| Response\n```\n\n### What it looked like\n\n![Screen Shot 2023-01-07 at 3.57.56 PM.png](/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.56_PM.png)\n\n![Screen Shot 2023-01-07 at 3.58.08 PM.png](/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.08_PM.png)\n\n![Screen Shot 2023-01-07 at 3.58.28 PM.png](/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.28_PM.png)\n\n### Conclusion\n\nWith ChatGPT and other NLP models coming out lately, this seems fairly basic, but the following processes are still very useful to understand:\n\n- Convert language to a representation that is easier to work with, like a vector.\n- Clustering vectors is a great way to find representative vectors, reducing the size of the number of vectors you need to work with.\n- Cosine Similarity can be used to find how similar vectors are. If a vector is labelled with metadata, it also tells you how similar the metadata between the vectors are as well.\n\nYou can see [my project page](/projects/2020-05-18-clarity-hub-infer) for more details and links to the Github repos.\n","contentHTML":"<p><img alt=\"Screen Shot 2023-01-07 at 3.57.30 PM.png\" src=\"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p>While working on Clarity Hub, we created a Clarity Hub Infer API along with a developer portal that would let anyone create infer models.</p>\n<p>The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.</p>\n<p>At the most basic level, the Infer API would let users send utterances via an API and get toxicity analysis, sentiment scores, and simple NLP data like nouns and topics from the utterances.</p>\n<p>The power of the Infer API is that consumers can supply a set of pre-labelled utterances to the API, and the API will create a model from this, even if there are only a few utterances used for training. Then the consumer can send a new utterance get a label using that model.</p>\n<p>The NLP APIs at Clarity Hub were a set of APIs:</p>\n<mermaid chart=\"graph RL\n  NLP(Clarity Hub NLP API) --&gt; API(Clarity Hub Infer API) --&gt; Consumer\"></mermaid>\n<p>The Consumer would user the Infer API which provided APIs for training and labeling datasets and getting toxicity and sentiment analyses. the Clarity Hub NLP API contained trained Tensorflow datasets for creating embeddings via the Universal Sentence Encoder (USE).</p>\n<p>An <strong>embedding</strong> a vector that represents an utterance - a sentence, sentence fragment, or paragraph of text.</p>\n<p>Training would involve a consumer sending a payload of utterances with labels to the Infer API, which would call the NLP API internally to create embeddings. We then clustered these embeddings to and re-labelled the clusters using the given labels. If no label was found for an utterance cluster, we attempted to pull a topic out of the utterances to re-label it.</p>\n<p>The clusters with labels were then stored into S3.</p>\n<mermaid chart=\"graph TD\n  Train --&gt;|Utterances with labels| USE\n  USE --&gt;|Embeddings with labels| Clustering\n  Clustering --&gt;|Embedding Clusters| Labeller\n  Labeller --&gt;|Clusters with Labels| S3\"></mermaid>\n<p>To classify a new utterance, we created an embedding from it, loaded the existing dataset in, then ran cosine similarity to find the most probabilistic matches:</p>\n<mermaid chart=\"graph TD\n  Classify --&gt; |Utterance| USE\n  USE --&gt; |Embedding| Classifier(Classifier)\n  Classifier --&gt; |Embedding + Clusters from S3| Similarity(Cosine Similarity)\n  Similarity --&gt; |Labels with Probability| Response\"></mermaid>\n<h3>What it looked like</h3>\n<p><img alt=\"Screen Shot 2023-01-07 at 3.57.56 PM.png\" src=\"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.56_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p><img alt=\"Screen Shot 2023-01-07 at 3.58.08 PM.png\" src=\"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.08_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p><img alt=\"Screen Shot 2023-01-07 at 3.58.28 PM.png\" src=\"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.28_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<h3>Conclusion</h3>\n<p>With ChatGPT and other NLP models coming out lately, this seems fairly basic, but the following processes are still very useful to understand:</p>\n<ul>\n<li>Convert language to a representation that is easier to work with, like a vector.</li>\n<li>Clustering vectors is a great way to find representative vectors, reducing the size of the number of vectors you need to work with.</li>\n<li>Cosine Similarity can be used to find how similar vectors are. If a vector is labelled with metadata, it also tells you how similar the metadata between the vectors are as well.</li>\n</ul>\n<p>You can see <a href=\"/projects/2020-05-18-clarity-hub-infer\">my project page</a> for more details and links to the Github repos.</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    h3: \"h3\",\n    img: \"img\",\n    li: \"li\",\n    mermaid: \"mermaid\",\n    p: \"p\",\n    strong: \"strong\",\n    ul: \"ul\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png\",\n        alt: \"Screen Shot 2023-01-07 at 3.57.30 PM.png\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"While working on Clarity Hub, we created a Clarity Hub Infer API along with a developer portal that would let anyone create infer models.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"At the most basic level, the Infer API would let users send utterances via an API and get toxicity analysis, sentiment scores, and simple NLP data like nouns and topics from the utterances.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The power of the Infer API is that consumers can supply a set of pre-labelled utterances to the API, and the API will create a model from this, even if there are only a few utterances used for training. Then the consumer can send a new utterance get a label using that model.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The NLP APIs at Clarity Hub were a set of APIs:\"\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph RL\\n  NLP(Clarity Hub NLP API) --> API(Clarity Hub Infer API) --> Consumer\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The Consumer would user the Infer API which provided APIs for training and labeling datasets and getting toxicity and sentiment analyses. the Clarity Hub NLP API contained trained Tensorflow datasets for creating embeddings via the Universal Sentence Encoder (USE).\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"An \", _jsx(_components.strong, {\n        children: \"embedding\"\n      }), \" a vector that represents an utterance - a sentence, sentence fragment, or paragraph of text.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Training would involve a consumer sending a payload of utterances with labels to the Infer API, which would call the NLP API internally to create embeddings. We then clustered these embeddings to and re-labelled the clusters using the given labels. If no label was found for an utterance cluster, we attempted to pull a topic out of the utterances to re-label it.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The clusters with labels were then stored into S3.\"\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph TD\\n  Train -->|Utterances with labels| USE\\n  USE -->|Embeddings with labels| Clustering\\n  Clustering -->|Embedding Clusters| Labeller\\n  Labeller -->|Clusters with Labels| S3\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To classify a new utterance, we created an embedding from it, loaded the existing dataset in, then ran cosine similarity to find the most probabilistic matches:\"\n    }), \"\\n\", _jsx(_components.mermaid, {\n      chart: \"graph TD\\n  Classify --> |Utterance| USE\\n  USE --> |Embedding| Classifier(Classifier)\\n  Classifier --> |Embedding + Clusters from S3| Similarity(Cosine Similarity)\\n  Similarity --> |Labels with Probability| Response\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"What it looked like\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.56_PM.png\",\n        alt: \"Screen Shot 2023-01-07 at 3.57.56 PM.png\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.08_PM.png\",\n        alt: \"Screen Shot 2023-01-07 at 3.58.08 PM.png\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.28_PM.png\",\n        alt: \"Screen Shot 2023-01-07 at 3.58.28 PM.png\"\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Conclusion\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With ChatGPT and other NLP models coming out lately, this seems fairly basic, but the following processes are still very useful to understand:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Convert language to a representation that is easier to work with, like a vector.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Clustering vectors is a great way to find representative vectors, reducing the size of the number of vectors you need to work with.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Cosine Similarity can be used to find how similar vectors are. If a vector is labelled with metadata, it also tells you how similar the metadata between the vectors are as well.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"You can see \", _jsx(_components.a, {\n        href: \"/projects/2020-05-18-clarity-hub-infer\",\n        children: \"my project page\"\n      }), \" for more details and links to the Github repos.\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\n![Screen Shot 2023-01-07 at 3.57.30 PM.png](/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png)","excerptHTML":"<p><img alt=\"Screen Shot 2023-01-07 at 3.57.30 PM.png\" src=\"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    img: \"img\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsx(_components.p, {\n    children: _jsx(_components.img, {\n      src: \"/media/2023-01-07-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png\",\n      alt: \"Screen Shot 2023-01-07 at 3.57.30 PM.png\"\n    })\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["nlp","machine learning"]},"previous":{"slug":"2023-01-15-hierarchy-of-webapp-needs","title":"The Hierarchy of Webapp Needs"},"next":{"slug":"2023-01-01-nx-nextjs-starter","title":"NX NextJS Starter"}},"__N_SSG":true}