{"pageProps":{"headTitle":"ChatGPT Doesn't Understand - idmontie's Portfolio","headKeywords":"openai, chatgpt","post":{"slug":"2023-01-24-chat-gpt-doesnt-understand","date":"2023-01-24","title":"ChatGPT Doesn't Understand","frontmatter":{"title":"ChatGPT Doesn't Understand","tags":["openai","chatgpt"]},"contentRaw":"\nLooks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether [ChatGPT can play 20 questions](https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff). The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.\n\nI attempted to do 20 questions with ChatGPT using a different prompt:\n\n*Me: I would like to play a game. It's called twenty questions. You will ask me one question at a time and I will answer it. The goal is for you guess the thing I am thinking about.*\n\n*ChatGPT: Sure, I'd be happy to play \"Twenty Questions\" with you. Please go ahead and think of something, and I will start asking my first question.*\n\n*Me: I am ready*\n\n*ChatGPT: Great, here is my first question: Is the thing you are thinking of an object?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object something that you can hold in your hand?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object something that you would typically find in a kitchen?*\n\n*Me: No*\n\n*ChatGPT: Is the object something that you would use for transportation?*\n\n*Me: No*\n\n*ChatGPT: Is the object something that you would use for entertainment or leisure?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object a musical instrument?*\n\n*Me: No*\n\n*ChatGPT: Is the object a type of game or puzzle?*\n\n*Me: No*\n\n*ChatGPT: Is the object a piece of technology such as a phone or computer?*\n\n*Me: No*\n\n*ChatGPT: Is the object a book or magazine?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object a novel or a collection of short stories?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object a specific book that is widely known and read?*\n\n*Me: Yes*\n\n*ChatGPT: Is the object \"To Kill a Mockingbird\" by Harper Lee?*\n\n*Me: No*\n\n*ChatGPT: I'm sorry, I'm running out of ideas. Can you give me a hint or tell me the answer?*\n\nSeems like we hit a wall here with twenty questions, but ChatGPT is very close, so I decided to give a hint.\n\n*Me: You are on the right track. It is by Walt Whitman*\n\n*ChatGPT: Is the object \"Leaves of Grass\" by Walt Whitman?*\n\n*Me: Yes! Congratulations!*\n\n*ChatGPT: Thank you! I'm glad I was able to guess the object you were thinking of. It was fun playing \"Twenty Questions\" with you. Let me know if you want to play again sometime.*\n\n---\n\nI’ve been keeping an eye on how other people are using ChatGPT, and [prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering) is one of the more fascinating aspects around how people are communicating with the AI. Prompt engineering plays a key role in communicating with models like ChatGPT. Carefully crafting prompts can help maximize the quality of the reponse. However, it is important to keep in mind that, like any AI model, ChatGPT has its own set of limitations.\n\nSo I was curious when I read that “[ChatGPT can’t write sentences that end in a specific letter](https://www.reddit.com/r/ChatGPT/comments/101e454/chatgpt_cant_write_sentences_that_end_with_a/)”. Is this a real limitation of ChatGPT, or maybe this was just a poor prompt.\n\nSo let’s start with a very simple question to ChatGPT:\n\n*Me: Can you write a sentence that ends with the letter \"a\"?*\n\n*ChatGPT: The cat sat on the mat.*\n\n*Me: That sentence does not end in the letter \"a\". Can you write a sentence that ends in the letter \"a\"?*\n\n*ChatGPT: I can't think of anything right now, but the word \"America\" ends with letter \"a\".*\n\n*Me: Great, write a sentence that ends in that word. That will then satisfy the original question.*\n\n*ChatGPT: The land of the free, and the home of the brave, America.*\n\nOkay, that does technically end in the letter a, but the sentence seems very strange.\n\n*Me: That isn't a very coherent sentence. Can you write a sentence that ends in the letter \"a\"?*\n\n*ChatGPT: I am sorry for the confusion, here is a sentence that ends with the letter \"a\" - \"He saw the drama unfold on the stage, it was quite the spectacle, a.”*\n\nLooks like we are going off the rails here. Let’s try a different approach:\n\n*Me: Write a sentence that ends in a word that ends with the letter \"a\".*\n\n*ChatGPT: The sun was setting over the horizon, painting the sky with shades of orange and red, a spectacle to behold and end the day with.*\n\nI’m going to ask ChatGPT to tell me a prompt to feed back to itself. I’ve found this useful for resetting context when having long conversations. Or if ChatGPT gets into weird states like the above response.\n\n*Me: Can you tell me how to write a prompt for you that would actually get you to write a sentence that ends in the letter \"a\".*\n\n*ChatGPT: Sure, to get me to write a sentence that ends in the letter \"a\" you could provide a prompt like: \"Write a sentence that ends with a word that ends with the letter 'a'\" or \"Can you write a sentence with a word ending in 'a' at the end of the sentence?\" . This makes it clear that the sentence should end in a word ending with the letter 'a'.*\n\n*Me: Can you write a sentence with a word ending in 'a' at the end of the sentence?*\n\n*ChatGPT: The sky was clear and blue, not a cloud in sight, perfect for a day out at the parka.*\n\n---\n\nWhile ChatGPT is great at forming sentences and even code, it seems like it has no understanding and hasn’t been trained on letters, syllables, or the concept of sentences. I've seen others get ChatGPT to create poems, but it has no concept of why words would rhyme. It can give great answers to questions, but doesn’t understand how to count how many words are in its response.\n\nOne Redditor in the link above mentions that ChatGPT fails at ASCII art. I’ve tried getting the AI to print ASCII art before, and I’ll leave you with part of a conversation I’ve had with it. This appears to be the best ASCII art I could get it to print, even after having a long conversation where I provided different ASCII art examples:\n\n*Me: Can you make ASCII art? Show me a picture of a cat.*\n\n*ChatGPT: Sure! Here is a picture of a cat using ASCII art:*\n\n```\n /\\_/\\\n( o.o )\n >^<\n\n```\n\n*I hope you like it! Is there anything else I can help with?*\n\n*Me: Can you make it more detailed*\n\n*ChatGPT: Certainly! Here is a more detailed version of an ASCII art cat:*\n\n```\n /\\_/\\\n( o.o )\n  >^<\n  | |\n  || ||\n  \\\\ //\n  // \\\\\n  \\\\_//\n  /   \\\n /     \\\n\n```\n\nWith new language models coming out, it's important to recognize what the limitations\nof the AI are. Poor responses can be a result of poorly written prompts, but there\nare times, like with letters in words with ChatGPT, where the AI just doesn't have\nthe capability to understand the question.\n","contentHTML":"<p>Looks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether <a href=\"https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff\">ChatGPT can play 20 questions</a>. The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.</p>\n<p>I attempted to do 20 questions with ChatGPT using a different prompt:</p>\n<p><em>Me: I would like to play a game. It&#x27;s called twenty questions. You will ask me one question at a time and I will answer it. The goal is for you guess the thing I am thinking about.</em></p>\n<p><em>ChatGPT: Sure, I&#x27;d be happy to play &quot;Twenty Questions&quot; with you. Please go ahead and think of something, and I will start asking my first question.</em></p>\n<p><em>Me: I am ready</em></p>\n<p><em>ChatGPT: Great, here is my first question: Is the thing you are thinking of an object?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object something that you can hold in your hand?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object something that you would typically find in a kitchen?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object something that you would use for transportation?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object something that you would use for entertainment or leisure?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object a musical instrument?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object a type of game or puzzle?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object a piece of technology such as a phone or computer?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: Is the object a book or magazine?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object a novel or a collection of short stories?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object a specific book that is widely known and read?</em></p>\n<p><em>Me: Yes</em></p>\n<p><em>ChatGPT: Is the object &quot;To Kill a Mockingbird&quot; by Harper Lee?</em></p>\n<p><em>Me: No</em></p>\n<p><em>ChatGPT: I&#x27;m sorry, I&#x27;m running out of ideas. Can you give me a hint or tell me the answer?</em></p>\n<p>Seems like we hit a wall here with twenty questions, but ChatGPT is very close, so I decided to give a hint.</p>\n<p><em>Me: You are on the right track. It is by Walt Whitman</em></p>\n<p><em>ChatGPT: Is the object &quot;Leaves of Grass&quot; by Walt Whitman?</em></p>\n<p><em>Me: Yes! Congratulations!</em></p>\n<p><em>ChatGPT: Thank you! I&#x27;m glad I was able to guess the object you were thinking of. It was fun playing &quot;Twenty Questions&quot; with you. Let me know if you want to play again sometime.</em></p>\n<hr/>\n<p>I’ve been keeping an eye on how other people are using ChatGPT, and <a href=\"https://en.wikipedia.org/wiki/Prompt_engineering\">prompt engineering</a> is one of the more fascinating aspects around how people are communicating with the AI. Prompt engineering plays a key role in communicating with models like ChatGPT. Carefully crafting prompts can help maximize the quality of the reponse. However, it is important to keep in mind that, like any AI model, ChatGPT has its own set of limitations.</p>\n<p>So I was curious when I read that “<a href=\"https://www.reddit.com/r/ChatGPT/comments/101e454/chatgpt_cant_write_sentences_that_end_with_a/\">ChatGPT can’t write sentences that end in a specific letter</a>”. Is this a real limitation of ChatGPT, or maybe this was just a poor prompt.</p>\n<p>So let’s start with a very simple question to ChatGPT:</p>\n<p><em>Me: Can you write a sentence that ends with the letter &quot;a&quot;?</em></p>\n<p><em>ChatGPT: The cat sat on the mat.</em></p>\n<p><em>Me: That sentence does not end in the letter &quot;a&quot;. Can you write a sentence that ends in the letter &quot;a&quot;?</em></p>\n<p><em>ChatGPT: I can&#x27;t think of anything right now, but the word &quot;America&quot; ends with letter &quot;a&quot;.</em></p>\n<p><em>Me: Great, write a sentence that ends in that word. That will then satisfy the original question.</em></p>\n<p><em>ChatGPT: The land of the free, and the home of the brave, America.</em></p>\n<p>Okay, that does technically end in the letter a, but the sentence seems very strange.</p>\n<p><em>Me: That isn&#x27;t a very coherent sentence. Can you write a sentence that ends in the letter &quot;a&quot;?</em></p>\n<p><em>ChatGPT: I am sorry for the confusion, here is a sentence that ends with the letter &quot;a&quot; - &quot;He saw the drama unfold on the stage, it was quite the spectacle, a.”</em></p>\n<p>Looks like we are going off the rails here. Let’s try a different approach:</p>\n<p><em>Me: Write a sentence that ends in a word that ends with the letter &quot;a&quot;.</em></p>\n<p><em>ChatGPT: The sun was setting over the horizon, painting the sky with shades of orange and red, a spectacle to behold and end the day with.</em></p>\n<p>I’m going to ask ChatGPT to tell me a prompt to feed back to itself. I’ve found this useful for resetting context when having long conversations. Or if ChatGPT gets into weird states like the above response.</p>\n<p><em>Me: Can you tell me how to write a prompt for you that would actually get you to write a sentence that ends in the letter &quot;a&quot;.</em></p>\n<p><em>ChatGPT: Sure, to get me to write a sentence that ends in the letter &quot;a&quot; you could provide a prompt like: &quot;Write a sentence that ends with a word that ends with the letter &#x27;a&#x27;&quot; or &quot;Can you write a sentence with a word ending in &#x27;a&#x27; at the end of the sentence?&quot; . This makes it clear that the sentence should end in a word ending with the letter &#x27;a&#x27;.</em></p>\n<p><em>Me: Can you write a sentence with a word ending in &#x27;a&#x27; at the end of the sentence?</em></p>\n<p><em>ChatGPT: The sky was clear and blue, not a cloud in sight, perfect for a day out at the parka.</em></p>\n<hr/>\n<p>While ChatGPT is great at forming sentences and even code, it seems like it has no understanding and hasn’t been trained on letters, syllables, or the concept of sentences. I&#x27;ve seen others get ChatGPT to create poems, but it has no concept of why words would rhyme. It can give great answers to questions, but doesn’t understand how to count how many words are in its response.</p>\n<p>One Redditor in the link above mentions that ChatGPT fails at ASCII art. I’ve tried getting the AI to print ASCII art before, and I’ll leave you with part of a conversation I’ve had with it. This appears to be the best ASCII art I could get it to print, even after having a long conversation where I provided different ASCII art examples:</p>\n<p><em>Me: Can you make ASCII art? Show me a picture of a cat.</em></p>\n<p><em>ChatGPT: Sure! Here is a picture of a cat using ASCII art:</em></p>\n<div class=\"overflow-auto rounded bg-gray-200 p-4 font-mono text-sm dark:bg-gray-800 dark:text-gray-100\"><pre><code> /\\_/\\\n( o.o )\n &gt;^&lt;\n\n</code></pre></div>\n<p><em>I hope you like it! Is there anything else I can help with?</em></p>\n<p><em>Me: Can you make it more detailed</em></p>\n<p><em>ChatGPT: Certainly! Here is a more detailed version of an ASCII art cat:</em></p>\n<div class=\"overflow-auto rounded bg-gray-200 p-4 font-mono text-sm dark:bg-gray-800 dark:text-gray-100\"><pre><code> /\\_/\\\n( o.o )\n  &gt;^&lt;\n  | |\n  || ||\n  \\\\ //\n  // \\\\\n  \\\\_//\n  /   \\\n /     \\\n\n</code></pre></div>\n<p>With new language models coming out, it&#x27;s important to recognize what the limitations\nof the AI are. Poor responses can be a result of poorly written prompts, but there\nare times, like with letters in words with ChatGPT, where the AI just doesn&#x27;t have\nthe capability to understand the question.</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    code: \"code\",\n    em: \"em\",\n    hr: \"hr\",\n    p: \"p\",\n    pre: \"pre\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"Looks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether \", _jsx(_components.a, {\n        href: \"https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff\",\n        children: \"ChatGPT can play 20 questions\"\n      }), \". The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I attempted to do 20 questions with ChatGPT using a different prompt:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: I would like to play a game. It's called twenty questions. You will ask me one question at a time and I will answer it. The goal is for you guess the thing I am thinking about.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Sure, I'd be happy to play \\\"Twenty Questions\\\" with you. Please go ahead and think of something, and I will start asking my first question.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: I am ready\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Great, here is my first question: Is the thing you are thinking of an object?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object something that you can hold in your hand?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object something that you would typically find in a kitchen?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object something that you would use for transportation?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object something that you would use for entertainment or leisure?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a musical instrument?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a type of game or puzzle?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a piece of technology such as a phone or computer?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a book or magazine?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a novel or a collection of short stories?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object a specific book that is widely known and read?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object \\\"To Kill a Mockingbird\\\" by Harper Lee?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: No\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: I'm sorry, I'm running out of ideas. Can you give me a hint or tell me the answer?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Seems like we hit a wall here with twenty questions, but ChatGPT is very close, so I decided to give a hint.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: You are on the right track. It is by Walt Whitman\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Is the object \\\"Leaves of Grass\\\" by Walt Whitman?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Yes! Congratulations!\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Thank you! I'm glad I was able to guess the object you were thinking of. It was fun playing \\\"Twenty Questions\\\" with you. Let me know if you want to play again sometime.\"\n      })\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsxs(_components.p, {\n      children: [\"I’ve been keeping an eye on how other people are using ChatGPT, and \", _jsx(_components.a, {\n        href: \"https://en.wikipedia.org/wiki/Prompt_engineering\",\n        children: \"prompt engineering\"\n      }), \" is one of the more fascinating aspects around how people are communicating with the AI. Prompt engineering plays a key role in communicating with models like ChatGPT. Carefully crafting prompts can help maximize the quality of the reponse. However, it is important to keep in mind that, like any AI model, ChatGPT has its own set of limitations.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"So I was curious when I read that “\", _jsx(_components.a, {\n        href: \"https://www.reddit.com/r/ChatGPT/comments/101e454/chatgpt_cant_write_sentences_that_end_with_a/\",\n        children: \"ChatGPT can’t write sentences that end in a specific letter\"\n      }), \"”. Is this a real limitation of ChatGPT, or maybe this was just a poor prompt.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So let’s start with a very simple question to ChatGPT:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you write a sentence that ends with the letter \\\"a\\\"?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: The cat sat on the mat.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: That sentence does not end in the letter \\\"a\\\". Can you write a sentence that ends in the letter \\\"a\\\"?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: I can't think of anything right now, but the word \\\"America\\\" ends with letter \\\"a\\\".\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Great, write a sentence that ends in that word. That will then satisfy the original question.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: The land of the free, and the home of the brave, America.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Okay, that does technically end in the letter a, but the sentence seems very strange.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: That isn't a very coherent sentence. Can you write a sentence that ends in the letter \\\"a\\\"?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: I am sorry for the confusion, here is a sentence that ends with the letter \\\"a\\\" - \\\"He saw the drama unfold on the stage, it was quite the spectacle, a.”\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Looks like we are going off the rails here. Let’s try a different approach:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Write a sentence that ends in a word that ends with the letter \\\"a\\\".\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: The sun was setting over the horizon, painting the sky with shades of orange and red, a spectacle to behold and end the day with.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I’m going to ask ChatGPT to tell me a prompt to feed back to itself. I’ve found this useful for resetting context when having long conversations. Or if ChatGPT gets into weird states like the above response.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you tell me how to write a prompt for you that would actually get you to write a sentence that ends in the letter \\\"a\\\".\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Sure, to get me to write a sentence that ends in the letter \\\"a\\\" you could provide a prompt like: \\\"Write a sentence that ends with a word that ends with the letter 'a'\\\" or \\\"Can you write a sentence with a word ending in 'a' at the end of the sentence?\\\" . This makes it clear that the sentence should end in a word ending with the letter 'a'.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you write a sentence with a word ending in 'a' at the end of the sentence?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: The sky was clear and blue, not a cloud in sight, perfect for a day out at the parka.\"\n      })\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsx(_components.p, {\n      children: \"While ChatGPT is great at forming sentences and even code, it seems like it has no understanding and hasn’t been trained on letters, syllables, or the concept of sentences. I've seen others get ChatGPT to create poems, but it has no concept of why words would rhyme. It can give great answers to questions, but doesn’t understand how to count how many words are in its response.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"One Redditor in the link above mentions that ChatGPT fails at ASCII art. I’ve tried getting the AI to print ASCII art before, and I’ll leave you with part of a conversation I’ve had with it. This appears to be the best ASCII art I could get it to print, even after having a long conversation where I provided different ASCII art examples:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you make ASCII art? Show me a picture of a cat.\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Sure! Here is a picture of a cat using ASCII art:\"\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \" /\\\\_/\\\\\\n( o.o )\\n >^<\\n\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"I hope you like it! Is there anything else I can help with?\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Me: Can you make it more detailed\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"ChatGPT: Certainly! Here is a more detailed version of an ASCII art cat:\"\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \" /\\\\_/\\\\\\n( o.o )\\n  >^<\\n  | |\\n  || ||\\n  \\\\\\\\ //\\n  // \\\\\\\\\\n  \\\\\\\\_//\\n  /   \\\\\\n /     \\\\\\n\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With new language models coming out, it's important to recognize what the limitations\\nof the AI are. Poor responses can be a result of poorly written prompts, but there\\nare times, like with letters in words with ChatGPT, where the AI just doesn't have\\nthe capability to understand the question.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nLooks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether [ChatGPT can play 20 questions](https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff). The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.","excerptHTML":"<p>Looks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether <a href=\"https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff\">ChatGPT can play 20 questions</a>. The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.</p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsxs(_components.p, {\n    children: [\"Looks like everyone is trying to discover ChatGPT’s limitations. In one article I read, the author asked whether \", _jsx(_components.a, {\n      href: \"https://medium.com/@theworldaccordingtocgpt/chatgpt-can-play-20-questions-7911405f7aff\",\n      children: \"ChatGPT can play 20 questions\"\n    }), \". The human in this scenario tried to play 20 questions with ChatGPT, and found that they needed to guide the AI to ask questions. From my perspective, it looked more like a failure to engineer the initial prompt correctly.\"]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["openai","chatgpt"]},"previous":{"slug":"2023-04-02-dark-emblem-rewrite","title":"Dark Emblem Rewrite"},"next":{"slug":"2023-01-15-hierarchy-of-webapp-needs","title":"The Hierarchy of Webapp Needs"}},"__N_SSG":true}