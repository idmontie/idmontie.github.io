{"pageProps":{"headTitle":"Looking back on Clarity Hub - idmontie's Portfolio","headKeywords":"clarityhub, startups","post":{"slug":"2023-11-19-reboot-clarityhub","date":"2023-11-19","title":"Looking back on Clarity Hub","frontmatter":{"title":"Looking back on Clarity Hub","tags":["clarityhub","startups"]},"contentRaw":"\nIn my projects list on this blog is a set of projects related to Clarity Hub. This was a startup I did with a group of friends where we aimed to create software to enable software product teams to gather customer feedback, and then action on it.\n\nI've been thinking about rebooting Clarity Hub for some time. When I was devoting my time to the Clarity Hub startup, the offering was split into two parts: 1. Interviewing software for product teams, and 2. an AI and NLP set of APIs for inference and predictions.\n\nWe ended up open sourcing as much of our Clarity Hub code as we could: [Clarity Hub on Github](https://github.com/Clarityhub). This included all of our original code pivots as well. While interviewing with a few startups, a couple asked me for details on Clarity Hub and how we approached the problem domain, architectural decisions, and software design. All these notes ended up as part of the README: [Architecture notes on Github](https://github.com/clarityhub/clarityhub-server-core).\n\nLooking at all these diagrams, seeing all the incredible work I did with my small team on Clarity Hub, I can see that a lot has changed since we tackled this problem.\n\nThe first major change is that Notion has become a common name in note-taking. I consider myself an early adopter of Notion and have referred many friends over to it. Clarity Hub as a Notion for Product Teams seems very useless now, especially with the second change in consideration.\n\nThe second major change being how far AI and NLP came within just a few years. Focusing on this as our differentiator is now irrelevant. Notion has released their API, new AI tools, and a plethora of other features. And while Notion doesn't provide an easy way to record, video call, automatically transcribe meetings, and pull topics from conversations, this seems pretty trivial to add as a Notion extension. I think Dovetail will be in the same boat. As OpenAI continues to provide more powerful models, and makes them easy to use, well-positioned apps like Notion will be able to continue to get better.\n\nBut not is all lost, part of failing as a start-up is at least learning a lot.\n\n## Microservices, but not really\n\nLooking back on our startup adventure, one thing I'd recommend for a new business just trying to start out is to think about microservices, but not fully committing to the complexity of microservices. We approached this by making the entire application in Serverless, using lambdas for each main endpoint that was needed as lambdas to handle asynchronous services. This let us share code, but move quickly.\n\n## Billing\n\nBilling is one of those items that can easily become a time-sink – and it did. Looking back, I feel like we wasted so much time, effort, and thought on billing. If I had to do Clarity Hub over again, I'd ignore billing for just Free Trial and Contact Sales for custom billing.\n\nWithout customers, there's no point in building a billing system, especially when you don't know what type of customers you will have.\n\nWe definitely learned a lot about Stripe and how to build in eventing into our systems to help support billing cycles, upgrading, and more.\n\nWe also spent very little time looking into alternative billing providers, since we were part of Stripe Atlas. One that has always interested me was Lago, since it is available as Open Source and a hosted solution.\n\n## Conflict-free replicated data types\n\nWe originally used Slate for our editor, and as is usual in programming, they went through a major version bump right after we finished our original implementation. I wish we had investigated Conflict-free replicated data types for this more and built-in real-time multi-user editing for notes early in the development stage.\n\nImplementing a basic solution for this would have been well worth it from a learning perspective, and from a code-reusability perspective. As is, a lot of the editor code is obsolete and tightly coupled with the specific version of slate that we used.\n\n## Conclusion\n\nIf I could do Clarity Hub all over again, I would. It was a great learning and growing experience for me, and I've often looked back on what we did and thought about rebooting Clarity Hub. But when I look around the current technology landscape, I think the scope of the product and its main differentiators would have to change dramatically.\n","contentHTML":"<p>In my projects list on this blog is a set of projects related to Clarity Hub. This was a startup I did with a group of friends where we aimed to create software to enable software product teams to gather customer feedback, and then action on it.</p>\n<p>I&#x27;ve been thinking about rebooting Clarity Hub for some time. When I was devoting my time to the Clarity Hub startup, the offering was split into two parts: 1. Interviewing software for product teams, and 2. an AI and NLP set of APIs for inference and predictions.</p>\n<p>We ended up open sourcing as much of our Clarity Hub code as we could: <a href=\"https://github.com/Clarityhub\">Clarity Hub on Github</a>. This included all of our original code pivots as well. While interviewing with a few startups, a couple asked me for details on Clarity Hub and how we approached the problem domain, architectural decisions, and software design. All these notes ended up as part of the README: <a href=\"https://github.com/clarityhub/clarityhub-server-core\">Architecture notes on Github</a>.</p>\n<p>Looking at all these diagrams, seeing all the incredible work I did with my small team on Clarity Hub, I can see that a lot has changed since we tackled this problem.</p>\n<p>The first major change is that Notion has become a common name in note-taking. I consider myself an early adopter of Notion and have referred many friends over to it. Clarity Hub as a Notion for Product Teams seems very useless now, especially with the second change in consideration.</p>\n<p>The second major change being how far AI and NLP came within just a few years. Focusing on this as our differentiator is now irrelevant. Notion has released their API, new AI tools, and a plethora of other features. And while Notion doesn&#x27;t provide an easy way to record, video call, automatically transcribe meetings, and pull topics from conversations, this seems pretty trivial to add as a Notion extension. I think Dovetail will be in the same boat. As OpenAI continues to provide more powerful models, and makes them easy to use, well-positioned apps like Notion will be able to continue to get better.</p>\n<p>But not is all lost, part of failing as a start-up is at least learning a lot.</p>\n<h2>Microservices, but not really</h2>\n<p>Looking back on our startup adventure, one thing I&#x27;d recommend for a new business just trying to start out is to think about microservices, but not fully committing to the complexity of microservices. We approached this by making the entire application in Serverless, using lambdas for each main endpoint that was needed as lambdas to handle asynchronous services. This let us share code, but move quickly.</p>\n<h2>Billing</h2>\n<p>Billing is one of those items that can easily become a time-sink – and it did. Looking back, I feel like we wasted so much time, effort, and thought on billing. If I had to do Clarity Hub over again, I&#x27;d ignore billing for just Free Trial and Contact Sales for custom billing.</p>\n<p>Without customers, there&#x27;s no point in building a billing system, especially when you don&#x27;t know what type of customers you will have.</p>\n<p>We definitely learned a lot about Stripe and how to build in eventing into our systems to help support billing cycles, upgrading, and more.</p>\n<p>We also spent very little time looking into alternative billing providers, since we were part of Stripe Atlas. One that has always interested me was Lago, since it is available as Open Source and a hosted solution.</p>\n<h2>Conflict-free replicated data types</h2>\n<p>We originally used Slate for our editor, and as is usual in programming, they went through a major version bump right after we finished our original implementation. I wish we had investigated Conflict-free replicated data types for this more and built-in real-time multi-user editing for notes early in the development stage.</p>\n<p>Implementing a basic solution for this would have been well worth it from a learning perspective, and from a code-reusability perspective. As is, a lot of the editor code is obsolete and tightly coupled with the specific version of slate that we used.</p>\n<h2>Conclusion</h2>\n<p>If I could do Clarity Hub all over again, I would. It was a great learning and growing experience for me, and I&#x27;ve often looked back on what we did and thought about rebooting Clarity Hub. But when I look around the current technology landscape, I think the scope of the product and its main differentiators would have to change dramatically.</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    h2: \"h2\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"In my projects list on this blog is a set of projects related to Clarity Hub. This was a startup I did with a group of friends where we aimed to create software to enable software product teams to gather customer feedback, and then action on it.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I've been thinking about rebooting Clarity Hub for some time. When I was devoting my time to the Clarity Hub startup, the offering was split into two parts: 1. Interviewing software for product teams, and 2. an AI and NLP set of APIs for inference and predictions.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We ended up open sourcing as much of our Clarity Hub code as we could: \", _jsx(_components.a, {\n        href: \"https://github.com/Clarityhub\",\n        children: \"Clarity Hub on Github\"\n      }), \". This included all of our original code pivots as well. While interviewing with a few startups, a couple asked me for details on Clarity Hub and how we approached the problem domain, architectural decisions, and software design. All these notes ended up as part of the README: \", _jsx(_components.a, {\n        href: \"https://github.com/clarityhub/clarityhub-server-core\",\n        children: \"Architecture notes on Github\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Looking at all these diagrams, seeing all the incredible work I did with my small team on Clarity Hub, I can see that a lot has changed since we tackled this problem.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The first major change is that Notion has become a common name in note-taking. I consider myself an early adopter of Notion and have referred many friends over to it. Clarity Hub as a Notion for Product Teams seems very useless now, especially with the second change in consideration.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The second major change being how far AI and NLP came within just a few years. Focusing on this as our differentiator is now irrelevant. Notion has released their API, new AI tools, and a plethora of other features. And while Notion doesn't provide an easy way to record, video call, automatically transcribe meetings, and pull topics from conversations, this seems pretty trivial to add as a Notion extension. I think Dovetail will be in the same boat. As OpenAI continues to provide more powerful models, and makes them easy to use, well-positioned apps like Notion will be able to continue to get better.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But not is all lost, part of failing as a start-up is at least learning a lot.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Microservices, but not really\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Looking back on our startup adventure, one thing I'd recommend for a new business just trying to start out is to think about microservices, but not fully committing to the complexity of microservices. We approached this by making the entire application in Serverless, using lambdas for each main endpoint that was needed as lambdas to handle asynchronous services. This let us share code, but move quickly.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Billing\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Billing is one of those items that can easily become a time-sink – and it did. Looking back, I feel like we wasted so much time, effort, and thought on billing. If I had to do Clarity Hub over again, I'd ignore billing for just Free Trial and Contact Sales for custom billing.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Without customers, there's no point in building a billing system, especially when you don't know what type of customers you will have.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We definitely learned a lot about Stripe and how to build in eventing into our systems to help support billing cycles, upgrading, and more.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We also spent very little time looking into alternative billing providers, since we were part of Stripe Atlas. One that has always interested me was Lago, since it is available as Open Source and a hosted solution.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Conflict-free replicated data types\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We originally used Slate for our editor, and as is usual in programming, they went through a major version bump right after we finished our original implementation. I wish we had investigated Conflict-free replicated data types for this more and built-in real-time multi-user editing for notes early in the development stage.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Implementing a basic solution for this would have been well worth it from a learning perspective, and from a code-reusability perspective. As is, a lot of the editor code is obsolete and tightly coupled with the specific version of slate that we used.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Conclusion\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If I could do Clarity Hub all over again, I would. It was a great learning and growing experience for me, and I've often looked back on what we did and thought about rebooting Clarity Hub. But when I look around the current technology landscape, I think the scope of the product and its main differentiators would have to change dramatically.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nIn my projects list on this blog is a set of projects related to Clarity Hub. This was a startup I did with a group of friends where we aimed to create software to enable software product teams to gather customer feedback, and then action on it.","excerptHTML":"<p>In my projects list on this blog is a set of projects related to Clarity Hub. This was a startup I did with a group of friends where we aimed to create software to enable software product teams to gather customer feedback, and then action on it.</p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    p: \"p\",\n    ...props.components\n  };\n  return _jsx(_components.p, {\n    children: \"In my projects list on this blog is a set of projects related to Clarity Hub. This was a startup I did with a group of friends where we aimed to create software to enable software product teams to gather customer feedback, and then action on it.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["clarityhub","startups"]},"previous":{"slug":"2023-12-08-the-breaking-point","date":"2023-12-08","title":"The Breaking Point - Understanding the performance of your systems","frontmatter":{"title":"The Breaking Point - Understanding the performance of your systems","tags":["architecture","scaling"]},"contentRaw":"\nEvery system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn't magically infinite. It's a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.\n\n![The Breaking Point](/media/2023-12-08-the-breaking-point/splash.png)\n\n## The Myth of Scaling\n\nSoftware engineering often has an optimistic mindset that scaling a service is easy: we just let the more instances of the service be deployed, and voilà, perfect scaling! But the reality is a bit more complex. Instances don't always fire up instantly, services can fail unexpectedly, and not every component can scale indefinitely.\n\nThat's why it's important to understand the limitations of our services. Knowing where the system might buckle under pressure allows us to devise strategies to prevent these breaking points from turning into disasters.\n\nFor example, we may have a public API service with set auto-scaling rules. When the service is hit with many requests, the service spawns additional instances to handle the workload. This ends up working well in most cases, but in the real-world, the service ends up getting hit with huge bursts of requests from downstream users, rather than a steady increase of traffic. When this happens, we scale the service instances up, but now the database gets hit with too many writes and fails over, since the database was originally designed as a read heavy use-case. Of course this is a contrived example, but similar edge-cases commonly appear in complex architectures.\n\nWithout understanding the full system and the constraints of each part, it can be difficult to successfully scale.\n\n## Understanding Server Limitations\n\nA good starting point for finding your system's breaking point is to see how it fares on a single machine. Profile the memory usage when under load, and use load testing to determine how many simultaneous requests the service can handle before performance degrades. To make sense of it all, set some benchmarks:\n\n1. Determine what it means for performance to degrade. In some systems, you may have SLAs for some percentage of requests to complete within a given response time. Other systems may have more leniency.\n2. Use readily available tools to bombard your service with requests and observe the results. For web API services, there are plenty of open source tools that can sustain issuing millions of requests a second and reporting results.\n3. Run the tests multiple times and throw out any outliers in the results. From the rest, understand the peak memory usage, peak disk usage, and peak CPU usage of the service.\n\nOnce you have the information from these types of load tests, it becomes easy to identify indicators that a service will begin to degrade. For some services it is CPU usage that will increase more than the other resources. For some services, memory can get exhausted first.\n\nThe load testing will also be a good indicator of how many requests a single instance of your service can handle before falling over.\n\n## Scaling Strategies\n\nWhen dealing with monolithic services or hefty microservices, you may find from load testing that just vertically scaling the service by adding more hardware is more cost efficient than replicating the instance.\n\nFor smaller service that use less memory and CPU footprint, it may make more sense to horizontally scale the service with many additional smaller servers being deployed.\n\nCloud services like AWS, Azure, and GCP help enable either decision. With AWS, there are many different instance types to get the right size for your specific service deployment. With the right size picked out, auto-scaling becomes a more budget-friendly option, as you're only spinning up instances that meet your specific resource requirements.\n\nCloud providers additionally have ways to detect when to auto-scale an instance based on resource usage, making load testing very informative to tune these values.\n\n## Conclusion\n\nScaling isn't a one-size-fits-all solution. It's about understanding the unique limitations and potential of your system. Through careful analysis, load testing, and a bit of strategic thinking, you can develop a scaling strategy that not only meets your performance needs but also keeps an eye on the cost of your system. Whether it's beefing up your hardware or multiplying smaller instances, the key lies in making informed, tailored decisions for your system's specific demands and quirks.\n","contentHTML":"<p>Every system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn&#x27;t magically infinite. It&#x27;s a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.</p>\n<p><img alt=\"The Breaking Point\" src=\"/media/2023-12-08-the-breaking-point/splash.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<h2>The Myth of Scaling</h2>\n<p>Software engineering often has an optimistic mindset that scaling a service is easy: we just let the more instances of the service be deployed, and voilà, perfect scaling! But the reality is a bit more complex. Instances don&#x27;t always fire up instantly, services can fail unexpectedly, and not every component can scale indefinitely.</p>\n<p>That&#x27;s why it&#x27;s important to understand the limitations of our services. Knowing where the system might buckle under pressure allows us to devise strategies to prevent these breaking points from turning into disasters.</p>\n<p>For example, we may have a public API service with set auto-scaling rules. When the service is hit with many requests, the service spawns additional instances to handle the workload. This ends up working well in most cases, but in the real-world, the service ends up getting hit with huge bursts of requests from downstream users, rather than a steady increase of traffic. When this happens, we scale the service instances up, but now the database gets hit with too many writes and fails over, since the database was originally designed as a read heavy use-case. Of course this is a contrived example, but similar edge-cases commonly appear in complex architectures.</p>\n<p>Without understanding the full system and the constraints of each part, it can be difficult to successfully scale.</p>\n<h2>Understanding Server Limitations</h2>\n<p>A good starting point for finding your system&#x27;s breaking point is to see how it fares on a single machine. Profile the memory usage when under load, and use load testing to determine how many simultaneous requests the service can handle before performance degrades. To make sense of it all, set some benchmarks:</p>\n<ol>\n<li>Determine what it means for performance to degrade. In some systems, you may have SLAs for some percentage of requests to complete within a given response time. Other systems may have more leniency.</li>\n<li>Use readily available tools to bombard your service with requests and observe the results. For web API services, there are plenty of open source tools that can sustain issuing millions of requests a second and reporting results.</li>\n<li>Run the tests multiple times and throw out any outliers in the results. From the rest, understand the peak memory usage, peak disk usage, and peak CPU usage of the service.</li>\n</ol>\n<p>Once you have the information from these types of load tests, it becomes easy to identify indicators that a service will begin to degrade. For some services it is CPU usage that will increase more than the other resources. For some services, memory can get exhausted first.</p>\n<p>The load testing will also be a good indicator of how many requests a single instance of your service can handle before falling over.</p>\n<h2>Scaling Strategies</h2>\n<p>When dealing with monolithic services or hefty microservices, you may find from load testing that just vertically scaling the service by adding more hardware is more cost efficient than replicating the instance.</p>\n<p>For smaller service that use less memory and CPU footprint, it may make more sense to horizontally scale the service with many additional smaller servers being deployed.</p>\n<p>Cloud services like AWS, Azure, and GCP help enable either decision. With AWS, there are many different instance types to get the right size for your specific service deployment. With the right size picked out, auto-scaling becomes a more budget-friendly option, as you&#x27;re only spinning up instances that meet your specific resource requirements.</p>\n<p>Cloud providers additionally have ways to detect when to auto-scale an instance based on resource usage, making load testing very informative to tune these values.</p>\n<h2>Conclusion</h2>\n<p>Scaling isn&#x27;t a one-size-fits-all solution. It&#x27;s about understanding the unique limitations and potential of your system. Through careful analysis, load testing, and a bit of strategic thinking, you can develop a scaling strategy that not only meets your performance needs but also keeps an eye on the cost of your system. Whether it&#x27;s beefing up your hardware or multiplying smaller instances, the key lies in making informed, tailored decisions for your system&#x27;s specific demands and quirks.</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    h2: \"h2\",\n    img: \"img\",\n    li: \"li\",\n    ol: \"ol\",\n    p: \"p\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Every system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn't magically infinite. It's a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-12-08-the-breaking-point/splash.png\",\n        alt: \"The Breaking Point\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"The Myth of Scaling\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Software engineering often has an optimistic mindset that scaling a service is easy: we just let the more instances of the service be deployed, and voilà, perfect scaling! But the reality is a bit more complex. Instances don't always fire up instantly, services can fail unexpectedly, and not every component can scale indefinitely.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That's why it's important to understand the limitations of our services. Knowing where the system might buckle under pressure allows us to devise strategies to prevent these breaking points from turning into disasters.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For example, we may have a public API service with set auto-scaling rules. When the service is hit with many requests, the service spawns additional instances to handle the workload. This ends up working well in most cases, but in the real-world, the service ends up getting hit with huge bursts of requests from downstream users, rather than a steady increase of traffic. When this happens, we scale the service instances up, but now the database gets hit with too many writes and fails over, since the database was originally designed as a read heavy use-case. Of course this is a contrived example, but similar edge-cases commonly appear in complex architectures.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Without understanding the full system and the constraints of each part, it can be difficult to successfully scale.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Understanding Server Limitations\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A good starting point for finding your system's breaking point is to see how it fares on a single machine. Profile the memory usage when under load, and use load testing to determine how many simultaneous requests the service can handle before performance degrades. To make sense of it all, set some benchmarks:\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Determine what it means for performance to degrade. In some systems, you may have SLAs for some percentage of requests to complete within a given response time. Other systems may have more leniency.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Use readily available tools to bombard your service with requests and observe the results. For web API services, there are plenty of open source tools that can sustain issuing millions of requests a second and reporting results.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Run the tests multiple times and throw out any outliers in the results. From the rest, understand the peak memory usage, peak disk usage, and peak CPU usage of the service.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Once you have the information from these types of load tests, it becomes easy to identify indicators that a service will begin to degrade. For some services it is CPU usage that will increase more than the other resources. For some services, memory can get exhausted first.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The load testing will also be a good indicator of how many requests a single instance of your service can handle before falling over.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Scaling Strategies\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When dealing with monolithic services or hefty microservices, you may find from load testing that just vertically scaling the service by adding more hardware is more cost efficient than replicating the instance.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For smaller service that use less memory and CPU footprint, it may make more sense to horizontally scale the service with many additional smaller servers being deployed.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Cloud services like AWS, Azure, and GCP help enable either decision. With AWS, there are many different instance types to get the right size for your specific service deployment. With the right size picked out, auto-scaling becomes a more budget-friendly option, as you're only spinning up instances that meet your specific resource requirements.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Cloud providers additionally have ways to detect when to auto-scale an instance based on resource usage, making load testing very informative to tune these values.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Conclusion\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Scaling isn't a one-size-fits-all solution. It's about understanding the unique limitations and potential of your system. Through careful analysis, load testing, and a bit of strategic thinking, you can develop a scaling strategy that not only meets your performance needs but also keeps an eye on the cost of your system. Whether it's beefing up your hardware or multiplying smaller instances, the key lies in making informed, tailored decisions for your system's specific demands and quirks.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nEvery system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn't magically infinite. It's a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.","excerptHTML":"<p>Every system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn&#x27;t magically infinite. It&#x27;s a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.</p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    p: \"p\",\n    ...props.components\n  };\n  return _jsx(_components.p, {\n    children: \"Every system has its limits. When designing and architecting systems, sometimes we as engineers like to assume things can scale infinitely. Maybe we can use larger machines, or maybe we can deploy more instances of a service. But even trying to scale systems isn't magically infinite. It's a smart move to understand the limitations of what we are building upfront so we can make better technology choices, and squeeze the performance out of our existing systems.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["architecture","scaling"]},"next":{"slug":"2023-09-24-impostor-syndrome","date":"2023-09-24","title":"In Good Company, Impostor Syndrome","frontmatter":{"title":"In Good Company, Impostor Syndrome","tags":["career"]},"contentRaw":"\nWe've all felt it at some point in our careers: that dreaded feeling of impostor syndrome kicking in as we find ourselves in over our heads. Questions like, \"Am I truly qualified for this?\" and \"Are my peers facing the same challenges?\" often plague our minds.\n\nImpostor syndrome is such a universal experience that countless articles, conference talks, and books have been dedicated to the topic.\n\nBut is this just a human emotion? I think impostor syndrome also applies to startups and companies as well. While a lot less universal, some of us in the tech world have had the misfortune of working at such impostor syndrome companies. And that anxiety manifests itself into doubt in the employees, bringing everyone down.\n\n> For example, many startups use Jira because large companies use Jira.\n>\n> - https://blog.johnqian.com/startup-spark\n\nWhether or not you like JIRA, the startup impostor syndrome manifests itself in similar ways: pick safe tech that larger companies use. It must be good because the larger company we think is successful uses it. Emulate success and surely we will be successful.\n\nOr it may show up in processes. A manager comes into a startup from a large successful company and blindly imposes large corporate processes to the small company. Everything slows down, dampening the enthusiasm of the team. Emulate the processes of a large company and surely we will be successful.\n\nThis mindset isn't new. The old adage \"[No one has ever been fired for buying IBM](https://www.origina.com/blog/nobody-ever-got-fired-for-buying-ibm)\" highlights the tendency to play it safe in the face of doubt. When we have doubt, even as a company, we like to play it safe; but, innovation and large payoffs don't happen from playing it safe. They come from risk and opportunity.\n\nWhen we play it too safe, too cautiously, we are giving into that impostor syndrome and settling for good enough. In our personal lives and in business, emulating success is usually just a facade for fear of risk. It's difficult to go out there and create new processes when you are so used to an old process you learned at a larger company. It's difficult to go out there and pick a technology that no one is using compared to one that a large company is using. And it's difficult to go out there and solve problems you think are over your head.\n\nThat feeling of impostor syndrome is good. It means you are pushing your limits and getting out of your comfort zone. You are tackling problems you haven't experienced before. And if you don't just try to emulate others, you might make mistakes, but they are your learning opportunities for growth. Then you can look back and see how far you've come, not by playing it safe and fearing impostor syndrome, but by embracing it.\n","contentHTML":"<p>We&#x27;ve all felt it at some point in our careers: that dreaded feeling of impostor syndrome kicking in as we find ourselves in over our heads. Questions like, &quot;Am I truly qualified for this?&quot; and &quot;Are my peers facing the same challenges?&quot; often plague our minds.</p>\n<p>Impostor syndrome is such a universal experience that countless articles, conference talks, and books have been dedicated to the topic.</p>\n<p>But is this just a human emotion? I think impostor syndrome also applies to startups and companies as well. While a lot less universal, some of us in the tech world have had the misfortune of working at such impostor syndrome companies. And that anxiety manifests itself into doubt in the employees, bringing everyone down.</p>\n<blockquote class=\"border-l-4 border-gray-300 pl-4\">\n<p>For example, many startups use Jira because large companies use Jira.</p>\n<ul>\n<li><a href=\"https://blog.johnqian.com/startup-spark\">https://blog.johnqian.com/startup-spark</a></li>\n</ul>\n</blockquote>\n<p>Whether or not you like JIRA, the startup impostor syndrome manifests itself in similar ways: pick safe tech that larger companies use. It must be good because the larger company we think is successful uses it. Emulate success and surely we will be successful.</p>\n<p>Or it may show up in processes. A manager comes into a startup from a large successful company and blindly imposes large corporate processes to the small company. Everything slows down, dampening the enthusiasm of the team. Emulate the processes of a large company and surely we will be successful.</p>\n<p>This mindset isn&#x27;t new. The old adage &quot;<a href=\"https://www.origina.com/blog/nobody-ever-got-fired-for-buying-ibm\">No one has ever been fired for buying IBM</a>&quot; highlights the tendency to play it safe in the face of doubt. When we have doubt, even as a company, we like to play it safe; but, innovation and large payoffs don&#x27;t happen from playing it safe. They come from risk and opportunity.</p>\n<p>When we play it too safe, too cautiously, we are giving into that impostor syndrome and settling for good enough. In our personal lives and in business, emulating success is usually just a facade for fear of risk. It&#x27;s difficult to go out there and create new processes when you are so used to an old process you learned at a larger company. It&#x27;s difficult to go out there and pick a technology that no one is using compared to one that a large company is using. And it&#x27;s difficult to go out there and solve problems you think are over your head.</p>\n<p>That feeling of impostor syndrome is good. It means you are pushing your limits and getting out of your comfort zone. You are tackling problems you haven&#x27;t experienced before. And if you don&#x27;t just try to emulate others, you might make mistakes, but they are your learning opportunities for growth. Then you can look back and see how far you&#x27;ve come, not by playing it safe and fearing impostor syndrome, but by embracing it.</p>","contentCode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    blockquote: \"blockquote\",\n    li: \"li\",\n    p: \"p\",\n    ul: \"ul\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"We've all felt it at some point in our careers: that dreaded feeling of impostor syndrome kicking in as we find ourselves in over our heads. Questions like, \\\"Am I truly qualified for this?\\\" and \\\"Are my peers facing the same challenges?\\\" often plague our minds.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Impostor syndrome is such a universal experience that countless articles, conference talks, and books have been dedicated to the topic.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But is this just a human emotion? I think impostor syndrome also applies to startups and companies as well. While a lot less universal, some of us in the tech world have had the misfortune of working at such impostor syndrome companies. And that anxiety manifests itself into doubt in the employees, bringing everyone down.\"\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"For example, many startups use Jira because large companies use Jira.\"\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: _jsx(_components.a, {\n            href: \"https://blog.johnqian.com/startup-spark\",\n            children: \"https://blog.johnqian.com/startup-spark\"\n          })\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Whether or not you like JIRA, the startup impostor syndrome manifests itself in similar ways: pick safe tech that larger companies use. It must be good because the larger company we think is successful uses it. Emulate success and surely we will be successful.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Or it may show up in processes. A manager comes into a startup from a large successful company and blindly imposes large corporate processes to the small company. Everything slows down, dampening the enthusiasm of the team. Emulate the processes of a large company and surely we will be successful.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This mindset isn't new. The old adage \\\"\", _jsx(_components.a, {\n        href: \"https://www.origina.com/blog/nobody-ever-got-fired-for-buying-ibm\",\n        children: \"No one has ever been fired for buying IBM\"\n      }), \"\\\" highlights the tendency to play it safe in the face of doubt. When we have doubt, even as a company, we like to play it safe; but, innovation and large payoffs don't happen from playing it safe. They come from risk and opportunity.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When we play it too safe, too cautiously, we are giving into that impostor syndrome and settling for good enough. In our personal lives and in business, emulating success is usually just a facade for fear of risk. It's difficult to go out there and create new processes when you are so used to an old process you learned at a larger company. It's difficult to go out there and pick a technology that no one is using compared to one that a large company is using. And it's difficult to go out there and solve problems you think are over your head.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That feeling of impostor syndrome is good. It means you are pushing your limits and getting out of your comfort zone. You are tackling problems you haven't experienced before. And if you don't just try to emulate others, you might make mistakes, but they are your learning opportunities for growth. Then you can look back and see how far you've come, not by playing it safe and fearing impostor syndrome, but by embracing it.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nWe've all felt it at some point in our careers: that dreaded feeling of impostor syndrome kicking in as we find ourselves in over our heads. Questions like, \"Am I truly qualified for this?\" and \"Are my peers facing the same challenges?\" often plague our minds.","excerptHTML":"<p>We&#x27;ve all felt it at some point in our careers: that dreaded feeling of impostor syndrome kicking in as we find ourselves in over our heads. Questions like, &quot;Am I truly qualified for this?&quot; and &quot;Are my peers facing the same challenges?&quot; often plague our minds.</p>","excerptCode":"\"use strict\";\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    p: \"p\",\n    ...props.components\n  };\n  return _jsx(_components.p, {\n    children: \"We've all felt it at some point in our careers: that dreaded feeling of impostor syndrome kicking in as we find ourselves in over our heads. Questions like, \\\"Am I truly qualified for this?\\\" and \\\"Are my peers facing the same challenges?\\\" often plague our minds.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["career"]}},"__N_SSG":true}