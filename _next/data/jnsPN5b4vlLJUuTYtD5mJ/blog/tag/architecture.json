{"pageProps":{"headTitle":"architecture posts - idmontie's Portfolio","headKeywords":"architecture","tag":"architecture","posts":[{"slug":"2023-08-06-data-on-the-wire","date":"2023-08-06","title":"Data on the Wire","frontmatter":{"title":"Data on the Wire","tags":["architecture"]},"contentRaw":"\nBack when [Meteor](https://www.meteor.com/) was in vogue, they popularized the concept of “Data on the wire”. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.\n\n> Data on the wire refers mostly to the way that Meteor forms a websocket connection to the server on page load and then transfers the data needed over that connection.\n>\n> The websocket is a live connection and as the data changes, the updates are automatically pushed over the wire and the client updates in real time. (Similar to how many people can edit the same document simultaneously in Google Docs and see each others changes in real time)\n>\n\n- [coagmano on Stackoverflow](https://stackoverflow.com/questions/48512242/in-meteor-what-does-data-on-the-wire-mean)\n\nThis idea was pretty interesting: a UI could always be considered up to date even if another client created a new row in the database. This is because Meteor would listen to the changelog of the MongoDB it was connected to, and then if a client was subscribed to the dataset that change belonged it, Meteor would push that change over the connected websocket.\n\nData on the wire enabled clients to stay up-to-date with any changes and create an amazing experience for users who would see changes instantly. For developers, this was also a huge win for prototyping applications.\n\nBut the problem with data on the wire is that the client can subscribe to a dataset with additional MongoDB filters, but the server now needs to keep track of what clients are subscribed to what subset of data.\n\nIf we start with a dataset `A`, and a user creates a new item `i`, then we know that if a user is subscribed to dataset `A`, we can just send the changes for `i` via a websocket.\n\n```mermaid\nsequenceDiagram\n    Client->>Server: Subscribe to dataset A\n    MongoDB-->>Server: New item i was inserted into A\n    Server-->>Client: Push new item i via websocket\n```\n\nBut if we want to start scaling our servers up, then we must broadcast any change to dataset `A` to every service, and then each service must check if any websocket is subscribed to `A`:\n\n```mermaid\ngraph LR\n  MongoDB --> Server1\n  Client --> Server2\n  MongoDB --> Server2\n  MongoDB --> Server3 \n```\n\n(Technically, each server would either read from the MongoDB change stream, or have a service push an event to them that is listening to the change stream)\n\nNow, each Service needs to additionally check if the item `i` meets any additional filter criteria that each subscriber may have for dataset `A`.\n\nAs datasets grow and filters become more computationally expensive, this can cause a lot of processing and memory burden for each Server.\n\nThis is such a problem that it is even called out in the Meteor documentation: **Scaling Updates**.\n\n> As previously mentioned, Meteor uses MongoDB’s Oplog to identify which changes to apply to which publication. Each change to the database is processed by every Meteor server, so frequent changes can result in high CPU usage across the board. At the same time, your database will come under higher load as all your servers keep fetching data from the oplog.\n>\n\nI’ve just thought about this recently since I had a conversation about keeping UI’s up-to-date with realtime data based on subscribing to that dataset via a websocket and it sounded eerily familiar to problems I have seen in the past.\n\nIn fact, similarly, I’ve seen trouble with GraphQL Subscriptions having similar issues, since each server node now needs to identify when to push data back to a subscriber:\n\n> GraphQL Subscriptions (GQLS) are a mechanism which allow clients to subscribe to changes in a piece of data from the server, and get notified whenever that data changes.\n>\n\n[The relay spec](https://relay.dev/docs/v13.0.0/guided-tour/updating-data/graphql-subscriptions/) makes no mention of how a server might do this though. There is a handy tutorial by LogRocket on implementing a NodeJS server to handle subscriptions though: [GraphQL Subscriptions with NodeJS and Express](https://blog.logrocket.com/graphql-subscriptions-nodejs-express/).\n\nBut if you look at the diagrams, they seem awfully familiar…\n","contentHTML":"<p>Back when <a href=\"https://www.meteor.com/\">Meteor</a> was in vogue, they popularized the concept of “Data on the wire”. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.</p>\n<blockquote class=\"border-l-4 border-gray-300 pl-4\">\n<p>Data on the wire refers mostly to the way that Meteor forms a websocket connection to the server on page load and then transfers the data needed over that connection.</p>\n<p>The websocket is a live connection and as the data changes, the updates are automatically pushed over the wire and the client updates in real time. (Similar to how many people can edit the same document simultaneously in Google Docs and see each others changes in real time)</p>\n</blockquote>\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/48512242/in-meteor-what-does-data-on-the-wire-mean\">coagmano on Stackoverflow</a></li>\n</ul>\n<p>This idea was pretty interesting: a UI could always be considered up to date even if another client created a new row in the database. This is because Meteor would listen to the changelog of the MongoDB it was connected to, and then if a client was subscribed to the dataset that change belonged it, Meteor would push that change over the connected websocket.</p>\n<p>Data on the wire enabled clients to stay up-to-date with any changes and create an amazing experience for users who would see changes instantly. For developers, this was also a huge win for prototyping applications.</p>\n<p>But the problem with data on the wire is that the client can subscribe to a dataset with additional MongoDB filters, but the server now needs to keep track of what clients are subscribed to what subset of data.</p>\n<p>If we start with a dataset <code>A</code>, and a user creates a new item <code>i</code>, then we know that if a user is subscribed to dataset <code>A</code>, we can just send the changes for <code>i</code> via a websocket.</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"sequenceDiagram\n    Client-&gt;&gt;Server: Subscribe to dataset A\n    MongoDB--&gt;&gt;Server: New item i was inserted into A\n    Server--&gt;&gt;Client: Push new item i via websocket\">sequenceDiagram\n    Client-&gt;&gt;Server: Subscribe to dataset A\n    MongoDB--&gt;&gt;Server: New item i was inserted into A\n    Server--&gt;&gt;Client: Push new item i via websocket</div></div>\n<p>But if we want to start scaling our servers up, then we must broadcast any change to dataset <code>A</code> to every service, and then each service must check if any websocket is subscribed to <code>A</code>:</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph LR\n  MongoDB --&gt; Server1\n  Client --&gt; Server2\n  MongoDB --&gt; Server2\n  MongoDB --&gt; Server3 \">graph LR\n  MongoDB --&gt; Server1\n  Client --&gt; Server2\n  MongoDB --&gt; Server2\n  MongoDB --&gt; Server3 </div></div>\n<p>(Technically, each server would either read from the MongoDB change stream, or have a service push an event to them that is listening to the change stream)</p>\n<p>Now, each Service needs to additionally check if the item <code>i</code> meets any additional filter criteria that each subscriber may have for dataset <code>A</code>.</p>\n<p>As datasets grow and filters become more computationally expensive, this can cause a lot of processing and memory burden for each Server.</p>\n<p>This is such a problem that it is even called out in the Meteor documentation: <strong>Scaling Updates</strong>.</p>\n<blockquote class=\"border-l-4 border-gray-300 pl-4\">\n<p>As previously mentioned, Meteor uses MongoDB’s Oplog to identify which changes to apply to which publication. Each change to the database is processed by every Meteor server, so frequent changes can result in high CPU usage across the board. At the same time, your database will come under higher load as all your servers keep fetching data from the oplog.</p>\n</blockquote>\n<p>I’ve just thought about this recently since I had a conversation about keeping UI’s up-to-date with realtime data based on subscribing to that dataset via a websocket and it sounded eerily familiar to problems I have seen in the past.</p>\n<p>In fact, similarly, I’ve seen trouble with GraphQL Subscriptions having similar issues, since each server node now needs to identify when to push data back to a subscriber:</p>\n<blockquote class=\"border-l-4 border-gray-300 pl-4\">\n<p>GraphQL Subscriptions (GQLS) are a mechanism which allow clients to subscribe to changes in a piece of data from the server, and get notified whenever that data changes.</p>\n</blockquote>\n<p><a href=\"https://relay.dev/docs/v13.0.0/guided-tour/updating-data/graphql-subscriptions/\">The relay spec</a> makes no mention of how a server might do this though. There is a handy tutorial by LogRocket on implementing a NodeJS server to handle subscriptions though: <a href=\"https://blog.logrocket.com/graphql-subscriptions-nodejs-express/\">GraphQL Subscriptions with NodeJS and Express</a>.</p>\n<p>But if you look at the diagrams, they seem awfully familiar…</p>","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    blockquote: \"blockquote\",\n    ul: \"ul\",\n    li: \"li\",\n    code: \"code\",\n    strong: \"strong\"\n  }, props.components), {Mermaid} = _components;\n  if (!Mermaid) _missingMdxReference(\"Mermaid\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"Back when \", _jsx(_components.a, {\n        href: \"https://www.meteor.com/\",\n        children: \"Meteor\"\n      }), \" was in vogue, they popularized the concept of “Data on the wire”. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.\"]\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"Data on the wire refers mostly to the way that Meteor forms a websocket connection to the server on page load and then transfers the data needed over that connection.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The websocket is a live connection and as the data changes, the updates are automatically pushed over the wire and the client updates in real time. (Similar to how many people can edit the same document simultaneously in Google Docs and see each others changes in real time)\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://stackoverflow.com/questions/48512242/in-meteor-what-does-data-on-the-wire-mean\",\n          children: \"coagmano on Stackoverflow\"\n        })\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This idea was pretty interesting: a UI could always be considered up to date even if another client created a new row in the database. This is because Meteor would listen to the changelog of the MongoDB it was connected to, and then if a client was subscribed to the dataset that change belonged it, Meteor would push that change over the connected websocket.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Data on the wire enabled clients to stay up-to-date with any changes and create an amazing experience for users who would see changes instantly. For developers, this was also a huge win for prototyping applications.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But the problem with data on the wire is that the client can subscribe to a dataset with additional MongoDB filters, but the server now needs to keep track of what clients are subscribed to what subset of data.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"If we start with a dataset \", _jsx(_components.code, {\n        children: \"A\"\n      }), \", and a user creates a new item \", _jsx(_components.code, {\n        children: \"i\"\n      }), \", then we know that if a user is subscribed to dataset \", _jsx(_components.code, {\n        children: \"A\"\n      }), \", we can just send the changes for \", _jsx(_components.code, {\n        children: \"i\"\n      }), \" via a websocket.\"]\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"sequenceDiagram\\n    Client->>Server: Subscribe to dataset A\\n    MongoDB-->>Server: New item i was inserted into A\\n    Server-->>Client: Push new item i via websocket\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"But if we want to start scaling our servers up, then we must broadcast any change to dataset \", _jsx(_components.code, {\n        children: \"A\"\n      }), \" to every service, and then each service must check if any websocket is subscribed to \", _jsx(_components.code, {\n        children: \"A\"\n      }), \":\"]\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph LR\\n  MongoDB --> Server1\\n  Client --> Server2\\n  MongoDB --> Server2\\n  MongoDB --> Server3 \"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"(Technically, each server would either read from the MongoDB change stream, or have a service push an event to them that is listening to the change stream)\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now, each Service needs to additionally check if the item \", _jsx(_components.code, {\n        children: \"i\"\n      }), \" meets any additional filter criteria that each subscriber may have for dataset \", _jsx(_components.code, {\n        children: \"A\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"As datasets grow and filters become more computationally expensive, this can cause a lot of processing and memory burden for each Server.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This is such a problem that it is even called out in the Meteor documentation: \", _jsx(_components.strong, {\n        children: \"Scaling Updates\"\n      }), \".\"]\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"As previously mentioned, Meteor uses MongoDB’s Oplog to identify which changes to apply to which publication. Each change to the database is processed by every Meteor server, so frequent changes can result in high CPU usage across the board. At the same time, your database will come under higher load as all your servers keep fetching data from the oplog.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I’ve just thought about this recently since I had a conversation about keeping UI’s up-to-date with realtime data based on subscribing to that dataset via a websocket and it sounded eerily familiar to problems I have seen in the past.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In fact, similarly, I’ve seen trouble with GraphQL Subscriptions having similar issues, since each server node now needs to identify when to push data back to a subscriber:\"\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"GraphQL Subscriptions (GQLS) are a mechanism which allow clients to subscribe to changes in a piece of data from the server, and get notified whenever that data changes.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://relay.dev/docs/v13.0.0/guided-tour/updating-data/graphql-subscriptions/\",\n        children: \"The relay spec\"\n      }), \" makes no mention of how a server might do this though. There is a handy tutorial by LogRocket on implementing a NodeJS server to handle subscriptions though: \", _jsx(_components.a, {\n        href: \"https://blog.logrocket.com/graphql-subscriptions-nodejs-express/\",\n        children: \"GraphQL Subscriptions with NodeJS and Express\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But if you look at the diagrams, they seem awfully familiar…\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","excerptRaw":"\nBack when [Meteor](https://www.meteor.com/) was in vogue, they popularized the concept of “Data on the wire”. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.","excerptHTML":"<p>Back when <a href=\"https://www.meteor.com/\">Meteor</a> was in vogue, they popularized the concept of “Data on the wire”. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.</p>","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\"\n  }, props.components);\n  return _jsxs(_components.p, {\n    children: [\"Back when \", _jsx(_components.a, {\n      href: \"https://www.meteor.com/\",\n      children: \"Meteor\"\n    }), \" was in vogue, they popularized the concept of “Data on the wire”. This was the idea that the UI would be updated with changes from the dataset it is subscribed to.\"]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["architecture"]},{"slug":"2023-07-21-backend-frontend","date":"2023-07-21","title":"Backend for Frontend","frontmatter":{"title":"Backend for Frontend","tags":["backend","frontend","architecture"]},"contentRaw":"\nThe Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:\n\n```mermaid\ngraph LR\n  SPA --> Backend\n```\n\nSPAs also became popular because the codebase could be built into static assets that could be services.\n\nHowever, as complexity arises with the above architecture and the SPA starts to rely on more services, a thin proxy is typically introduced, like NGINX:\n\n```mermaid\ngraph LR\n  SPA --> NGINX\n  NGINX --> Service1\n  NGINX --> Service2\n  NGINX --> Service3\n```\n\nWhile proxies like NGINX can continue to be useful, using it as a proxy ends up putting a lot of routing and additional API handling logic on the client. The client now ends up also having to support, understand, and embed how to interact with the data rom all the downstream services. To simplify and create consistent contracts with the UI, we can create a proxy service: a Backend for the Frontend:\n\n```mermaid\ngraph LR\n  SPA --> BEFFE\n  BEFFE --> Service1\n  BEFFE --> Service2\n  BEFFE --> Service3\n```\n\nThe Backend for the Frontend ends up serving two purposes:\n\n- It acts as a proxy for all UI requests\n- It manages and massages the APIs of downstream services to be a consistent API for the UI.\n\nWhen building a UI, only a single service that acts like an API Gateway is required to understand and encode within the application.\n\nThe Backend for the Frontend model also allows engineers working on services to separate logic for the UI with the logic from an internal service. An internal service can rely on the Backend for the Frontend to handle things like Authentication, Authorization, Caching, and Rate-limits. These mechanisms may also be implemented as independent services, but the Backend for the Frontend can make multiple API calls per any API request from the UI.\n\n## Moving away from SPAs\n\nA newer development in the UI space is server side render the application. If we are already introducing additional complexity by having a Backend for the Frontend, then why not combine the UI code with the backend service and generate hydrated and cacheable pages via the server instead of using a SPA?\n\n```mermaid\ngraph LR\n  UIServer[\"UI Server\"] --> Service1\n  UIServer --> Service2\n UIServer --> Service3\n```\n\nWith this design, we increase the complexity - the backend not has to be able to render the UI code. It must now render, hydrate, make requests to downstream APIs, and send those server-side rendered pages to the browser.\n\nBut this additional complexity enabled us to:\n\n- create truly authenticated and authorized routes – the code for those routes isn’t even streamed to the browser, unlike a SPA.\n- near instant page loads – reducing the bundle size by just sending the JavaScript needed to run the page makes this possible. And since API calls are happening within the same network, this saves the user from additional loading spinners after the initial bundle has been loaded.\n\nThe general trend of having a Backend for the Frontend comes with additional complexity. It stems from the want to enhance the experience of the user, and probably from a subconscious desire to return to a simpler time:\n\n```mermaid\ngraph TD\n  Server\n```\n","contentHTML":"<p>The Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph LR\n  SPA --&gt; Backend\">graph LR\n  SPA --&gt; Backend</div></div>\n<p>SPAs also became popular because the codebase could be built into static assets that could be services.</p>\n<p>However, as complexity arises with the above architecture and the SPA starts to rely on more services, a thin proxy is typically introduced, like NGINX:</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph LR\n  SPA --&gt; NGINX\n  NGINX --&gt; Service1\n  NGINX --&gt; Service2\n  NGINX --&gt; Service3\">graph LR\n  SPA --&gt; NGINX\n  NGINX --&gt; Service1\n  NGINX --&gt; Service2\n  NGINX --&gt; Service3</div></div>\n<p>While proxies like NGINX can continue to be useful, using it as a proxy ends up putting a lot of routing and additional API handling logic on the client. The client now ends up also having to support, understand, and embed how to interact with the data rom all the downstream services. To simplify and create consistent contracts with the UI, we can create a proxy service: a Backend for the Frontend:</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph LR\n  SPA --&gt; BEFFE\n  BEFFE --&gt; Service1\n  BEFFE --&gt; Service2\n  BEFFE --&gt; Service3\">graph LR\n  SPA --&gt; BEFFE\n  BEFFE --&gt; Service1\n  BEFFE --&gt; Service2\n  BEFFE --&gt; Service3</div></div>\n<p>The Backend for the Frontend ends up serving two purposes:</p>\n<ul>\n<li>It acts as a proxy for all UI requests</li>\n<li>It manages and massages the APIs of downstream services to be a consistent API for the UI.</li>\n</ul>\n<p>When building a UI, only a single service that acts like an API Gateway is required to understand and encode within the application.</p>\n<p>The Backend for the Frontend model also allows engineers working on services to separate logic for the UI with the logic from an internal service. An internal service can rely on the Backend for the Frontend to handle things like Authentication, Authorization, Caching, and Rate-limits. These mechanisms may also be implemented as independent services, but the Backend for the Frontend can make multiple API calls per any API request from the UI.</p>\n<h2>Moving away from SPAs</h2>\n<p>A newer development in the UI space is server side render the application. If we are already introducing additional complexity by having a Backend for the Frontend, then why not combine the UI code with the backend service and generate hydrated and cacheable pages via the server instead of using a SPA?</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph LR\n  UIServer[&quot;UI Server&quot;] --&gt; Service1\n  UIServer --&gt; Service2\n UIServer --&gt; Service3\">graph LR\n  UIServer[&quot;UI Server&quot;] --&gt; Service1\n  UIServer --&gt; Service2\n UIServer --&gt; Service3</div></div>\n<p>With this design, we increase the complexity - the backend not has to be able to render the UI code. It must now render, hydrate, make requests to downstream APIs, and send those server-side rendered pages to the browser.</p>\n<p>But this additional complexity enabled us to:</p>\n<ul>\n<li>create truly authenticated and authorized routes – the code for those routes isn’t even streamed to the browser, unlike a SPA.</li>\n<li>near instant page loads – reducing the bundle size by just sending the JavaScript needed to run the page makes this possible. And since API calls are happening within the same network, this saves the user from additional loading spinners after the initial bundle has been loaded.</li>\n</ul>\n<p>The general trend of having a Backend for the Frontend comes with additional complexity. It stems from the want to enhance the experience of the user, and probably from a subconscious desire to return to a simpler time:</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph TD\n  Server\">graph TD\n  Server</div></div>","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    ul: \"ul\",\n    li: \"li\",\n    h2: \"h2\"\n  }, props.components), {Mermaid} = _components;\n  if (!Mermaid) _missingMdxReference(\"Mermaid\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"The Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:\"\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph LR\\n  SPA --> Backend\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"SPAs also became popular because the codebase could be built into static assets that could be services.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"However, as complexity arises with the above architecture and the SPA starts to rely on more services, a thin proxy is typically introduced, like NGINX:\"\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph LR\\n  SPA --> NGINX\\n  NGINX --> Service1\\n  NGINX --> Service2\\n  NGINX --> Service3\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"While proxies like NGINX can continue to be useful, using it as a proxy ends up putting a lot of routing and additional API handling logic on the client. The client now ends up also having to support, understand, and embed how to interact with the data rom all the downstream services. To simplify and create consistent contracts with the UI, we can create a proxy service: a Backend for the Frontend:\"\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph LR\\n  SPA --> BEFFE\\n  BEFFE --> Service1\\n  BEFFE --> Service2\\n  BEFFE --> Service3\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The Backend for the Frontend ends up serving two purposes:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"It acts as a proxy for all UI requests\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"It manages and massages the APIs of downstream services to be a consistent API for the UI.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When building a UI, only a single service that acts like an API Gateway is required to understand and encode within the application.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The Backend for the Frontend model also allows engineers working on services to separate logic for the UI with the logic from an internal service. An internal service can rely on the Backend for the Frontend to handle things like Authentication, Authorization, Caching, and Rate-limits. These mechanisms may also be implemented as independent services, but the Backend for the Frontend can make multiple API calls per any API request from the UI.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Moving away from SPAs\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A newer development in the UI space is server side render the application. If we are already introducing additional complexity by having a Backend for the Frontend, then why not combine the UI code with the backend service and generate hydrated and cacheable pages via the server instead of using a SPA?\"\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph LR\\n  UIServer[\\\"UI Server\\\"] --> Service1\\n  UIServer --> Service2\\n UIServer --> Service3\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With this design, we increase the complexity - the backend not has to be able to render the UI code. It must now render, hydrate, make requests to downstream APIs, and send those server-side rendered pages to the browser.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But this additional complexity enabled us to:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"create truly authenticated and authorized routes – the code for those routes isn’t even streamed to the browser, unlike a SPA.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"near instant page loads – reducing the bundle size by just sending the JavaScript needed to run the page makes this possible. And since API calls are happening within the same network, this saves the user from additional loading spinners after the initial bundle has been loaded.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The general trend of having a Backend for the Frontend comes with additional complexity. It stems from the want to enhance the experience of the user, and probably from a subconscious desire to return to a simpler time:\"\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph TD\\n  Server\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","excerptRaw":"\nThe Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:","excerptHTML":"<p>The Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:</p>","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: \"The Backend for the Frontend (BEFFE) is typically stateless and acts as a proxy for other services, including authentication, authorization, and core services. The recent divorce of browser code being rendered by backend services was created by SPAs - Single Page Applications. In simpler architectures, a SPA and service could be as simple as:\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","tags":["backend","frontend","architecture"]}]},"__N_SSG":true}