{"pageProps":{"posts":[{"slug":"2023-01-7-clarity-hub-infer","date":"2023-01-7","title":"Clarity Hub Infer API","frontmatter":{"title":"Clarity Hub Infer API"},"contentRaw":"\n![Screen Shot 2023-01-07 at 3.57.30 PM.png](/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png)\n\nWhile working on Clarity Hub, we created a Clarity Hub Infer API along with a developer portal that would let anyone create infer models.\n\nThe Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\n\nAt the most basic level, the Infer API would let users send utterances via an API and get toxicity analysis, sentiment scores, and simple NLP data like nouns and topics from the utterances.\n\nThe power of the Infer API is that consumers can supply a set of pre-labelled utterances to the API, and the API will create a model from this, even if there are only a few utterances used for training. Then the consumer can send a new utterance get a label using that model.\n\nThe NLP APIs at Clarity Hub were a set of APIs:\n\n```mermaid\ngraph RL\n  NLP(Clarity Hub NLP API) --> API(Clarity Hub Infer API) --> Consumer\n```\n\nThe Consumer would user the Infer API which provided APIs for training and labeling datasets and getting toxicity and sentiment analyses. the Clarity Hub NLP API contained trained Tensorflow datasets for creating embeddings via the Universal Sentence Encoder (USE).\n\nAn **embedding** a vector that represents an utterance - a sentence, sentence fragment, or paragraph of text.\n\nTraining would involve a consumer sending a payload of utterances with labels to the Infer API, which would call the NLP API internally to create embeddings. We then clustered these embeddings to and re-labelled the clusters using the given labels. If no label was found for an utterance cluster, we attempted to pull a topic out of the utterances to re-label it.\n\nThe clusters with labels were then stored into S3.\n\n```mermaid\ngraph TD\n  Train -->|Utterances with labels| USE\n  USE -->|Embeddings with labels| Clustering\n  Clustering -->|Embedding Clusters| Labeller\n  Labeller -->|Clusters with Labels| S3\n```\n\nTo classify a new utterance, we created an embedding from it, loaded the existing dataset in, then ran cosine similarity to find the most probabilistic matches:\n\n```mermaid\ngraph TD\n  Classify --> |Utterance| USE\n  USE --> |Embedding| Classifier(Classifier)\n  Classifier --> |Embedding + Clusters from S3| Similarity(Cosine Similarity)\n  Similarity --> |Labels with Probability| Response\n```\n\n### What it looked like\n\n![Screen Shot 2023-01-07 at 3.57.56 PM.png](/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.56_PM.png)\n\n![Screen Shot 2023-01-07 at 3.58.08 PM.png](/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.08_PM.png)\n\n![Screen Shot 2023-01-07 at 3.58.28 PM.png](/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.28_PM.png)\n\n### Conclusion\n\nWith ChatGPT and other NLP models coming out lately, this seems fairly basic, but the following processes are still very useful to understand:\n\n- Convert language to a representation that is easier to work with, like a vector.\n- Clustering vectors is a great way to find representative vectors, reducing the size of the number of vectors you need to work with.\n- Cosine Similarity can be used to find how similar vectors are. If a vector is labelled with metadata, it also tells you how similar the metadata between the vectors are as well.\n\nYou can see [my project page](/projects/2020-05-18-clarity-hub-infer) for more details and links to the Github repos.\n","contentHTML":"<p><img alt=\"Screen Shot 2023-01-07 at 3.57.30 PM.png\" src=\"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p>While working on Clarity Hub, we created a Clarity Hub Infer API along with a developer portal that would let anyone create infer models.</p>\n<p>The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.</p>\n<p>At the most basic level, the Infer API would let users send utterances via an API and get toxicity analysis, sentiment scores, and simple NLP data like nouns and topics from the utterances.</p>\n<p>The power of the Infer API is that consumers can supply a set of pre-labelled utterances to the API, and the API will create a model from this, even if there are only a few utterances used for training. Then the consumer can send a new utterance get a label using that model.</p>\n<p>The NLP APIs at Clarity Hub were a set of APIs:</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph RL\n  NLP(Clarity Hub NLP API) --&gt; API(Clarity Hub Infer API) --&gt; Consumer\">graph RL\n  NLP(Clarity Hub NLP API) --&gt; API(Clarity Hub Infer API) --&gt; Consumer</div></div>\n<p>The Consumer would user the Infer API which provided APIs for training and labeling datasets and getting toxicity and sentiment analyses. the Clarity Hub NLP API contained trained Tensorflow datasets for creating embeddings via the Universal Sentence Encoder (USE).</p>\n<p>An <strong>embedding</strong> a vector that represents an utterance - a sentence, sentence fragment, or paragraph of text.</p>\n<p>Training would involve a consumer sending a payload of utterances with labels to the Infer API, which would call the NLP API internally to create embeddings. We then clustered these embeddings to and re-labelled the clusters using the given labels. If no label was found for an utterance cluster, we attempted to pull a topic out of the utterances to re-label it.</p>\n<p>The clusters with labels were then stored into S3.</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph TD\n  Train --&gt;|Utterances with labels| USE\n  USE --&gt;|Embeddings with labels| Clustering\n  Clustering --&gt;|Embedding Clusters| Labeller\n  Labeller --&gt;|Clusters with Labels| S3\">graph TD\n  Train --&gt;|Utterances with labels| USE\n  USE --&gt;|Embeddings with labels| Clustering\n  Clustering --&gt;|Embedding Clusters| Labeller\n  Labeller --&gt;|Clusters with Labels| S3</div></div>\n<p>To classify a new utterance, we created an embedding from it, loaded the existing dataset in, then ran cosine similarity to find the most probabilistic matches:</p>\n<div class=\"py-8 [&amp;_svg]:m-auto\"><div class=\"mermaid\" data-mermaid-src=\"graph TD\n  Classify --&gt; |Utterance| USE\n  USE --&gt; |Embedding| Classifier(Classifier)\n  Classifier --&gt; |Embedding + Clusters from S3| Similarity(Cosine Similarity)\n  Similarity --&gt; |Labels with Probability| Response\">graph TD\n  Classify --&gt; |Utterance| USE\n  USE --&gt; |Embedding| Classifier(Classifier)\n  Classifier --&gt; |Embedding + Clusters from S3| Similarity(Cosine Similarity)\n  Similarity --&gt; |Labels with Probability| Response</div></div>\n<h3>What it looked like</h3>\n<p><img alt=\"Screen Shot 2023-01-07 at 3.57.56 PM.png\" src=\"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.56_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p><img alt=\"Screen Shot 2023-01-07 at 3.58.08 PM.png\" src=\"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.08_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<p><img alt=\"Screen Shot 2023-01-07 at 3.58.28 PM.png\" src=\"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.28_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>\n<h3>Conclusion</h3>\n<p>With ChatGPT and other NLP models coming out lately, this seems fairly basic, but the following processes are still very useful to understand:</p>\n<ul>\n<li>Convert language to a representation that is easier to work with, like a vector.</li>\n<li>Clustering vectors is a great way to find representative vectors, reducing the size of the number of vectors you need to work with.</li>\n<li>Cosine Similarity can be used to find how similar vectors are. If a vector is labelled with metadata, it also tells you how similar the metadata between the vectors are as well.</li>\n</ul>\n<p>You can see <a href=\"/projects/2020-05-18-clarity-hub-infer\">my project page</a> for more details and links to the Github repos.</p>","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\",\n    strong: \"strong\",\n    h3: \"h3\",\n    ul: \"ul\",\n    li: \"li\",\n    a: \"a\"\n  }, props.components), {Mermaid} = _components;\n  if (!Mermaid) _missingMdxReference(\"Mermaid\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png\",\n        alt: \"Screen Shot 2023-01-07 at 3.57.30 PM.png\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"While working on Clarity Hub, we created a Clarity Hub Infer API along with a developer portal that would let anyone create infer models.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"At the most basic level, the Infer API would let users send utterances via an API and get toxicity analysis, sentiment scores, and simple NLP data like nouns and topics from the utterances.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The power of the Infer API is that consumers can supply a set of pre-labelled utterances to the API, and the API will create a model from this, even if there are only a few utterances used for training. Then the consumer can send a new utterance get a label using that model.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The NLP APIs at Clarity Hub were a set of APIs:\"\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph RL\\n  NLP(Clarity Hub NLP API) --> API(Clarity Hub Infer API) --> Consumer\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The Consumer would user the Infer API which provided APIs for training and labeling datasets and getting toxicity and sentiment analyses. the Clarity Hub NLP API contained trained Tensorflow datasets for creating embeddings via the Universal Sentence Encoder (USE).\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"An \", _jsx(_components.strong, {\n        children: \"embedding\"\n      }), \" a vector that represents an utterance - a sentence, sentence fragment, or paragraph of text.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Training would involve a consumer sending a payload of utterances with labels to the Infer API, which would call the NLP API internally to create embeddings. We then clustered these embeddings to and re-labelled the clusters using the given labels. If no label was found for an utterance cluster, we attempted to pull a topic out of the utterances to re-label it.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The clusters with labels were then stored into S3.\"\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph TD\\n  Train -->|Utterances with labels| USE\\n  USE -->|Embeddings with labels| Clustering\\n  Clustering -->|Embedding Clusters| Labeller\\n  Labeller -->|Clusters with Labels| S3\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To classify a new utterance, we created an embedding from it, loaded the existing dataset in, then ran cosine similarity to find the most probabilistic matches:\"\n    }), \"\\n\", _jsx(Mermaid, {\n      chart: \"graph TD\\n  Classify --> |Utterance| USE\\n  USE --> |Embedding| Classifier(Classifier)\\n  Classifier --> |Embedding + Clusters from S3| Similarity(Cosine Similarity)\\n  Similarity --> |Labels with Probability| Response\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"What it looked like\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.56_PM.png\",\n        alt: \"Screen Shot 2023-01-07 at 3.57.56 PM.png\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.08_PM.png\",\n        alt: \"Screen Shot 2023-01-07 at 3.58.08 PM.png\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.58.28_PM.png\",\n        alt: \"Screen Shot 2023-01-07 at 3.58.28 PM.png\"\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Conclusion\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With ChatGPT and other NLP models coming out lately, this seems fairly basic, but the following processes are still very useful to understand:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Convert language to a representation that is easier to work with, like a vector.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Clustering vectors is a great way to find representative vectors, reducing the size of the number of vectors you need to work with.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Cosine Similarity can be used to find how similar vectors are. If a vector is labelled with metadata, it also tells you how similar the metadata between the vectors are as well.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"You can see \", _jsx(_components.a, {\n        href: \"/projects/2020-05-18-clarity-hub-infer\",\n        children: \"my project page\"\n      }), \" for more details and links to the Github repos.\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","excerptRaw":"\n![Screen Shot 2023-01-07 at 3.57.30 PM.png](/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png)","excerptHTML":"<p><img alt=\"Screen Shot 2023-01-07 at 3.57.30 PM.png\" src=\"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png\" style=\"max-height:500px;margin:auto;text-align:center\"/></p>","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: _jsx(_components.img, {\n      src: \"/media/2023-01-7-clarity-hub-infer/Screen_Shot_2023-01-07_at_3.57.30_PM.png\",\n      alt: \"Screen Shot 2023-01-07 at 3.57.30 PM.png\"\n    })\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n"},{"slug":"2023-01-01-nx-nextjs-starter","date":"2023-01-01","title":"NX NextJS Starter","frontmatter":{"title":"NX NextJS Starter"},"contentRaw":"\nTo kickstart the year, I created a repo that contains a simple starter kit for using NextJS with NX. You can see the repo here:\n\n[Github](https://github.com/idmontie/nx-nextjs-starter)\n\nThis personal Github page is built using this starter kit. I wanted to create a starter kit that was simple and easy to use and also has a lot of eslint and Typescript configuration setup. I've also been working on revamping the website for Dark Emblem - my NFT side-project. The starter kit is based on the linting rules and Typescript set up that I've been using for that project.\n\n## Nx\n\nI've traditionally used Lerna for my monorepo projects, but now that Nx has taken over maintenance of Lerna, I decided to give Nx a try directly.\n\nNx has been enjoyable to use. Managing many different React projects with internal libraries has been very easy to set up, use and deploy.\n\n## NextJS\n\nMy last few projects have been Single Page Apps (SPAs) or statically generated sites using Gatsby or Docusaurus. All three of those tools are great, but I wanted to try out NextJS for a few reasons:\n\n* In my Dark Emblem project, I was having difficulty getting share links to Discord and Twitter to work properly. This was mainly caused by those sites not running JavaScript, so page links would just render the default SPA title and description. I knew that NextJS had a solution for this, so I wanted to try it out.\n* I wanted more control of my documentation and blog websites, so I needed to be able to use custom server-side code.\n\n## Starter Kit\n\nOverall the starter kit is a pretty simple example. It just containers preconfigured Nx, husky, lint-staged, eslint, prettier, Typescript, and NextJS. It does not contain any UI components or anything like that. It's just a simple starter kit to get you up and running with a monorepo NextJS project.\n\nFeel free to check it out at [Github](https://github.com/idmontie/nx-nextjs-starter).","contentHTML":"<p>To kickstart the year, I created a repo that contains a simple starter kit for using NextJS with NX. You can see the repo here:</p>\n<p><a href=\"https://github.com/idmontie/nx-nextjs-starter\">Github</a></p>\n<p>This personal Github page is built using this starter kit. I wanted to create a starter kit that was simple and easy to use and also has a lot of eslint and Typescript configuration setup. I&#x27;ve also been working on revamping the website for Dark Emblem - my NFT side-project. The starter kit is based on the linting rules and Typescript set up that I&#x27;ve been using for that project.</p>\n<h2>Nx</h2>\n<p>I&#x27;ve traditionally used Lerna for my monorepo projects, but now that Nx has taken over maintenance of Lerna, I decided to give Nx a try directly.</p>\n<p>Nx has been enjoyable to use. Managing many different React projects with internal libraries has been very easy to set up, use and deploy.</p>\n<h2>NextJS</h2>\n<p>My last few projects have been Single Page Apps (SPAs) or statically generated sites using Gatsby or Docusaurus. All three of those tools are great, but I wanted to try out NextJS for a few reasons:</p>\n<ul>\n<li>In my Dark Emblem project, I was having difficulty getting share links to Discord and Twitter to work properly. This was mainly caused by those sites not running JavaScript, so page links would just render the default SPA title and description. I knew that NextJS had a solution for this, so I wanted to try it out.</li>\n<li>I wanted more control of my documentation and blog websites, so I needed to be able to use custom server-side code.</li>\n</ul>\n<h2>Starter Kit</h2>\n<p>Overall the starter kit is a pretty simple example. It just containers preconfigured Nx, husky, lint-staged, eslint, prettier, Typescript, and NextJS. It does not contain any UI components or anything like that. It&#x27;s just a simple starter kit to get you up and running with a monorepo NextJS project.</p>\n<p>Feel free to check it out at <a href=\"https://github.com/idmontie/nx-nextjs-starter\">Github</a>.</p>","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    h2: \"h2\",\n    ul: \"ul\",\n    li: \"li\"\n  }, props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"To kickstart the year, I created a repo that contains a simple starter kit for using NextJS with NX. You can see the repo here:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.a, {\n        href: \"https://github.com/idmontie/nx-nextjs-starter\",\n        children: \"Github\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This personal Github page is built using this starter kit. I wanted to create a starter kit that was simple and easy to use and also has a lot of eslint and Typescript configuration setup. I've also been working on revamping the website for Dark Emblem - my NFT side-project. The starter kit is based on the linting rules and Typescript set up that I've been using for that project.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Nx\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I've traditionally used Lerna for my monorepo projects, but now that Nx has taken over maintenance of Lerna, I decided to give Nx a try directly.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Nx has been enjoyable to use. Managing many different React projects with internal libraries has been very easy to set up, use and deploy.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"NextJS\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"My last few projects have been Single Page Apps (SPAs) or statically generated sites using Gatsby or Docusaurus. All three of those tools are great, but I wanted to try out NextJS for a few reasons:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"In my Dark Emblem project, I was having difficulty getting share links to Discord and Twitter to work properly. This was mainly caused by those sites not running JavaScript, so page links would just render the default SPA title and description. I knew that NextJS had a solution for this, so I wanted to try it out.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"I wanted more control of my documentation and blog websites, so I needed to be able to use custom server-side code.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Starter Kit\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Overall the starter kit is a pretty simple example. It just containers preconfigured Nx, husky, lint-staged, eslint, prettier, Typescript, and NextJS. It does not contain any UI components or anything like that. It's just a simple starter kit to get you up and running with a monorepo NextJS project.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Feel free to check it out at \", _jsx(_components.a, {\n        href: \"https://github.com/idmontie/nx-nextjs-starter\",\n        children: \"Github\"\n      }), \".\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nTo kickstart the year, I created a repo that contains a simple starter kit for using NextJS with NX. You can see the repo here:","excerptHTML":"<p>To kickstart the year, I created a repo that contains a simple starter kit for using NextJS with NX. You can see the repo here:</p>","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: \"To kickstart the year, I created a repo that contains a simple starter kit for using NextJS with NX. You can see the repo here:\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n"}],"projects":[{"slug":"2020-05-18-clarity-hub-infer","date":"2020-05-18","title":"Clarity Hub Infer API","frontmatter":{"title":"Clarity Hub Infer API","image":"/images/clarityhub-infer-splash.png","description":"NLP infer API to create and label utterances.\n","language_tags":["node"],"framework_tags":["Universal Sentence Encoder","serverless","swagger"],"github_link":"https://github.com/clarityhub/chapi-api-infer"},"contentRaw":"\nThe Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\n\nThis API used the Universal Sentence Encoder (USE) to create embeddings from utterances, then used cosine similarity to find the most similar utterances to a given utterance.\n","contentHTML":"<p>The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.</p>\n<p>This API used the Universal Sentence Encoder (USE) to create embeddings from utterances, then used cosine similarity to find the most similar utterances to a given utterance.</p>","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This API used the Universal Sentence Encoder (USE) to create embeddings from utterances, then used cosine similarity to find the most similar utterances to a given utterance.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nThe Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.","excerptHTML":"<p>The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.</p>","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: \"The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n"},{"slug":"2018-03-05-clairvoyance.md","date":"2018-03-05","title":"Clairvoyance","frontmatter":{"title":"Clairvoyance","description":"Clairvoyance (renamed to Clarity Hub) finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\n","image":"/images/project-clarity-hub.png","view_link":"https://clarityhub.io","github_link":"https://github.com/clarityhub","language_tags":["javascript","es2015+","css"],"framework_tags":["aws","react","serverless","redux"]},"contentRaw":"\nClairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\n\nClairvoyance was built on AWS using S3, SNS, SQS, RDS, PostgreSQL, MongoDB, Elasticsearch, and React. We created a webapp, extensions, and a microservice backend to bring real time suggestions to customer success agents using Intercom.\n","contentHTML":"<p>Clairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.</p>\n<p>Clairvoyance was built on AWS using S3, SNS, SQS, RDS, PostgreSQL, MongoDB, Elasticsearch, and React. We created a webapp, extensions, and a microservice backend to bring real time suggestions to customer success agents using Intercom.</p>","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Clairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Clairvoyance was built on AWS using S3, SNS, SQS, RDS, PostgreSQL, MongoDB, Elasticsearch, and React. We created a webapp, extensions, and a microservice backend to bring real time suggestions to customer success agents using Intercom.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nClairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.","excerptHTML":"<p>Clairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.</p>","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: \"Clairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n"}]},"__N_SSG":true}