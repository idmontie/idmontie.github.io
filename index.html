<!DOCTYPE html><html lang="en"><head><meta name="viewport" content="width=device-width"/><meta charSet="utf8"/><title>Welcome - idmontie&#x27;s Portfolio</title><meta name="description" content="Latest projects"/><meta name="next-head-count" content="4"/><script>
                        try {
                            const storage = window && window.localStorage;
                            if (
                                storage.getItem("color-theme") === "dark" ||
                                (!("color-theme" in storage) &&
                                    window.matchMedia("(prefers-color-scheme: dark)").matches)
                            ) {
                                document.documentElement.classList.add("dark");
                            } else {
                                document.documentElement.classList.remove("dark");
                            }
                        } catch (e) {
                            console.error(e);
                        }
                        </script><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/078a38357c71905e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/078a38357c71905e.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-f5a48affa2e5582e.js" defer=""></script><script src="/_next/static/chunks/framework-dfd14d7ce6600b03.js" defer=""></script><script src="/_next/static/chunks/main-3412f4325dfb32ac.js" defer=""></script><script src="/_next/static/chunks/pages/_app-5585f6cc20ef0661.js" defer=""></script><script src="/_next/static/chunks/2e6ef0e3-e0509ad90a52e50d.js" defer=""></script><script src="/_next/static/chunks/956-14a634a4f6c953dc.js" defer=""></script><script src="/_next/static/chunks/pages/index-7db2606001d3590f.js" defer=""></script><script src="/_next/static/F7BNWm69u0aEm2ItOMAzh/_buildManifest.js" defer=""></script><script src="/_next/static/F7BNWm69u0aEm2ItOMAzh/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700&family=Open+Sans:wght@300;400;700&display=swap">@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRpXA.woff) format('woff')}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5OeA.woff) format('woff')}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNpXA.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsiH0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjZ0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsg-1y4k.woff) format('woff')}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZVcf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZXMf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZV8f6hPvhPUWH.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZVsf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Merriweather';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l521wRZWMf6hPvhPQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-cSZMdeX3rsHo.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-eCZMdeX3rsHo.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-cyZMdeX3rsHo.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-ciZMdeX3rsHo.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Merriweather';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-440qyriQwlOrhSvowK_l5-fCZMdeX3rg.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZVcf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZXMf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZV8f6hPvhPUWH.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZVsf6hPvhPUWH.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Merriweather';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/merriweather/v30/u-4n0qyriQwlOrhSvowK_l52xwNZWMf6hPvhPQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v35/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body class="leading-base bg-white text-lg antialiased dark:bg-gray-900 dark:text-white"><div id="__next"><nav class="flex items-center p-3"><div class="flex-1 space-x-4"><a class="font-bold" href="/">Home</a><a class="" href="/blog">Blog</a><a class="" href="/portfolio">Portfolio</a></div><div class="flex flex-1 justify-end"><label for="toggle" class="relative flex w-fit cursor-pointer items-center">🌑<input type="checkbox" id="toggle" class="sr-only"/><div class="
                        relative
                        h-6
                        w-11
                        rounded-full
                        border-2
                    
                        after:absolute
                        after:h-5
                        after:w-5
                        after:rounded-full
                        after:border
                        after:border-gray-300
                        after:bg-white
                        after:shadow-sm
                        after:transition
                     
                            border-gray-200
                            bg-gray-200
                            dark:border-gray-700
                            dark:bg-gray-700
                        "></div>☀️</label></div></nav><div class="relative overflow-hidden pb-4"><div class="mx-auto flex w-full max-w-screen-md flex-col items-center"><main class="app"><div><div class="px-4"><header><h1 class="my-8 text-center text-3xl font-bold dark:text-white md:text-5xl">Welcome</h1></header><section class="my-4"><h3 class="mb-4 text-center text-2xl font-bold">Latest Posts</h3><div class="grid grid-cols-1 gap-4"><div class="overflow-visible rounded-lg bg-white shadow-lg dark:bg-gray-800"><div class="p-4"><a href="/blog/post/2023-07-01-fast-embedding-lookingup"><h2 class="text-2xl font-bold">Fast Similar Embedding Lookup</h2></a><div class="py-2 text-sm"></div><div class="prose dark:prose-dark py-4"><div><div><p>While working on the Clarity Hub NLP API, we had a common use-case where we would create embeddings from text, and use those embedding to determine cosine similarity with other embeddings. Doing this required loading all of the embeddings in-memory and then computing cosine similarity with the entire dataset. As the dataset grew, this operation would get incredibly slow.</p></div></div></div><div class="pt-2"><a href="/blog/post/2023-07-01-fast-embedding-lookingup">Continue reading<span class="ml-2">→</span></a></div></div></div><div class="overflow-visible rounded-lg bg-white shadow-lg dark:bg-gray-800"><div class="p-4"><a href="/blog/post/2023-06-06-sora"><h2 class="text-2xl font-bold">Sora - OpenAI Visual Studio Code Extension</h2></a><div class="py-2 text-sm"></div><div class="prose dark:prose-dark py-4"><div><div><p>Github Copilot and other AI tools are hitting the scene. I decided to create my own Visual Studio Code extension, which is designed to use OpenAI’s APIs to bring some additional ChatGPT functionality into the code editor. The goal with Sora was to enable a developer to thoughtfully write a comment about the code they would like the AI to write, and then commit to it – rather than the real-time typeahead that Github Copilot provides.</p></div></div></div><div class="pt-2"><a href="/blog/post/2023-06-06-sora">Continue reading<span class="ml-2">→</span></a></div></div></div></div><div class="mt-4 text-center"><a class="
                inline-block
                rounded-sm
                bg-blue-600
                px-6
                py-2.5
                text-xs
                font-semibold
                uppercase
                leading-tight
                text-white
                shadow-md
                transition
                duration-150
                ease-in-out
                hover:bg-blue-700
                hover:shadow-lg
                focus:bg-blue-700
                focus:shadow-lg
                focus:outline-none
                focus:ring-0
                active:bg-blue-800
                active:shadow-lg
                " href="/blog">View All</a></div></section><section class="my-4 mt-12"><h3 class="mb-4 text-center text-2xl font-bold">Latest Projects</h3><div class="grid grid-cols-1 gap-4 md:grid-cols-2"><div class="overflow-visible rounded-lg bg-white shadow-lg dark:bg-gray-800"><div class="px-6 py-4"><h4 class="text-xl font-semibold text-gray-800 dark:text-white"><a href="/projects/2020-05-18-clarity-hub-infer">Clarity Hub Infer API</a></h4></div><a href="/projects/2020-05-18-clarity-hub-infer"><div class="ml-[-1%] w-[102%] bg-cover bg-center pb-[20vw] shadow-md" style="background-image:url(&#x27;/images/clarityhub-infer-splash.png&#x27;)"></div></a><div class="px-6 py-4"><p class="text-gray-700 dark:text-gray-300">NLP infer API to create and label utterances.
</p></div></div><div class="overflow-visible rounded-lg bg-white shadow-lg dark:bg-gray-800"><div class="px-6 py-4"><h4 class="text-xl font-semibold text-gray-800 dark:text-white"><a href="/projects/2018-03-05-clairvoyance.md">Clairvoyance</a></h4></div><a href="/projects/2018-03-05-clairvoyance.md"><div class="ml-[-1%] w-[102%] bg-cover bg-center pb-[20vw] shadow-md" style="background-image:url(&#x27;/images/project-clarity-hub.png&#x27;)"></div></a><div class="px-6 py-4"><p class="text-gray-700 dark:text-gray-300">Clairvoyance (renamed to Clarity Hub) finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.
</p></div></div></div><div class="mt-4 text-center"><a class="
                inline-block
                rounded-sm
                bg-blue-600
                px-6
                py-2.5
                text-xs
                font-semibold
                uppercase
                leading-tight
                text-white
                shadow-md
                transition
                duration-150
                ease-in-out
                hover:bg-blue-700
                hover:shadow-lg
                focus:bg-blue-700
                focus:shadow-lg
                focus:outline-none
                focus:ring-0
                active:bg-blue-800
                active:shadow-lg
                " href="/portfolio">View All</a></div></section></div></div></main></div></div><footer class="width-full border-top bg-gray-light my-4 p-4"><div class="flex-justify-between flex px-3 text-gray-700 dark:text-gray-300"><div class="flex-1">Like this blog and portfolio? Check it out on<!-- --> <a href="https://github.com/idmontie/idmontie.github.io" target="_blank" rel="noopener noreferrer">Github</a></div><div class="flex self-end"><button>Back to top</button></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"slug":"2023-07-01-fast-embedding-lookingup","date":"2023-07-01","title":"Fast Similar Embedding Lookup","frontmatter":{"title":"Fast Similar Embedding Lookup"},"contentRaw":"\nWhile working on the Clarity Hub NLP API, we had a common use-case where we would create embeddings from text, and use those embedding to determine cosine similarity with other embeddings. Doing this required loading all of the embeddings in-memory and then computing cosine similarity with the entire dataset. As the dataset grew, this operation would get incredibly slow.\n\nWe worked on a fast way to do these lookups using ranges that can be performed in any database. This approach was never implemented, but we worked on multiple proof-of-concepts to test out our ideas. The goal was to take an input text, compute an embedding, load the entire embedding datasets loaded into an AWS lambda, find the most similar set of vectors, and return the top N similar vectors in one use-case. To tackle that, we came up with the following idea.\n\nGiven a vector A, compute is similar to a unit vector U of the same dimension as A. So:\n\n```cpp\ndim(U) = dim(A)\n```\n\nAnd\n\n```cpp\nS_u = cos(θ) = A · U / ||A|| x ||U||\n```\n\nWhere S_u is the similarity with the unit vector. The unit vector just needs to be the same across all samples.\n\nFor each embedding, store the calculated S_u.\n\nIf we want to find similar vectors for a new vector B, then we compute is similarity to the unit vector.\n\nThen, we can query the database for vectors within an interval of `[S_u - ε, S_u + ε]` . This will give us a subset of the dataset that have similar similarities with the unit vector.\n\nWe can re-query increasing or decreasing ε until the top N results are found.\n\nTo further improve accuracy, we can also re-compute the similarity score using cosine similarity with the subset of vectors, which is still much faster then computing the similarity against the entire dataset.\n\nThis approach begins to break down as the cosine similarity to the unit vector chosen gets very large (`\u003e 0.4`).  We end up with the possibility of matching against vectors that are of opposite directions – the least similar vectors to the original input vector.\n\nOne solution to workaround this could be to pre-compute the similarity of a vector against unit vectors for each dimension of the input vector. But this could be 512 or more cosine similarity calculations for modern embeddings just to precompute the data. Once all unit vector similarities are calculated and stored, the range query against the database would be made against the column for which the input vector’s similarity is closest to 0.\n\nThere are a lot of real solutions to this problem, but this was a fun exercise to think about and work on.","contentHTML":"\u003cp\u003eWhile working on the Clarity Hub NLP API, we had a common use-case where we would create embeddings from text, and use those embedding to determine cosine similarity with other embeddings. Doing this required loading all of the embeddings in-memory and then computing cosine similarity with the entire dataset. As the dataset grew, this operation would get incredibly slow.\u003c/p\u003e\n\u003cp\u003eWe worked on a fast way to do these lookups using ranges that can be performed in any database. This approach was never implemented, but we worked on multiple proof-of-concepts to test out our ideas. The goal was to take an input text, compute an embedding, load the entire embedding datasets loaded into an AWS lambda, find the most similar set of vectors, and return the top N similar vectors in one use-case. To tackle that, we came up with the following idea.\u003c/p\u003e\n\u003cp\u003eGiven a vector A, compute is similar to a unit vector U of the same dimension as A. So:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003edim(U) = dim(A)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003eS_u = cos(θ) = A · U / ||A|| x ||U||\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhere S_u is the similarity with the unit vector. The unit vector just needs to be the same across all samples.\u003c/p\u003e\n\u003cp\u003eFor each embedding, store the calculated S_u.\u003c/p\u003e\n\u003cp\u003eIf we want to find similar vectors for a new vector B, then we compute is similarity to the unit vector.\u003c/p\u003e\n\u003cp\u003eThen, we can query the database for vectors within an interval of \u003ccode\u003e[S_u - ε, S_u + ε]\u003c/code\u003e . This will give us a subset of the dataset that have similar similarities with the unit vector.\u003c/p\u003e\n\u003cp\u003eWe can re-query increasing or decreasing ε until the top N results are found.\u003c/p\u003e\n\u003cp\u003eTo further improve accuracy, we can also re-compute the similarity score using cosine similarity with the subset of vectors, which is still much faster then computing the similarity against the entire dataset.\u003c/p\u003e\n\u003cp\u003eThis approach begins to break down as the cosine similarity to the unit vector chosen gets very large (\u003ccode\u003e\u0026gt; 0.4\u003c/code\u003e).  We end up with the possibility of matching against vectors that are of opposite directions – the least similar vectors to the original input vector.\u003c/p\u003e\n\u003cp\u003eOne solution to workaround this could be to pre-compute the similarity of a vector against unit vectors for each dimension of the input vector. But this could be 512 or more cosine similarity calculations for modern embeddings just to precompute the data. Once all unit vector similarities are calculated and stored, the range query against the database would be made against the column for which the input vector’s similarity is closest to 0.\u003c/p\u003e\n\u003cp\u003eThere are a lot of real solutions to this problem, but this was a fun exercise to think about and work on.\u003c/p\u003e","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    pre: \"pre\",\n    code: \"code\"\n  }, props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"While working on the Clarity Hub NLP API, we had a common use-case where we would create embeddings from text, and use those embedding to determine cosine similarity with other embeddings. Doing this required loading all of the embeddings in-memory and then computing cosine similarity with the entire dataset. As the dataset grew, this operation would get incredibly slow.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We worked on a fast way to do these lookups using ranges that can be performed in any database. This approach was never implemented, but we worked on multiple proof-of-concepts to test out our ideas. The goal was to take an input text, compute an embedding, load the entire embedding datasets loaded into an AWS lambda, find the most similar set of vectors, and return the top N similar vectors in one use-case. To tackle that, we came up with the following idea.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Given a vector A, compute is similar to a unit vector U of the same dimension as A. So:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-cpp\",\n        children: \"dim(U) = dim(A)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-cpp\",\n        children: \"S_u = cos(θ) = A · U / ||A|| x ||U||\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Where S_u is the similarity with the unit vector. The unit vector just needs to be the same across all samples.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For each embedding, store the calculated S_u.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If we want to find similar vectors for a new vector B, then we compute is similarity to the unit vector.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Then, we can query the database for vectors within an interval of \", _jsx(_components.code, {\n        children: \"[S_u - ε, S_u + ε]\"\n      }), \" . This will give us a subset of the dataset that have similar similarities with the unit vector.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We can re-query increasing or decreasing ε until the top N results are found.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To further improve accuracy, we can also re-compute the similarity score using cosine similarity with the subset of vectors, which is still much faster then computing the similarity against the entire dataset.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This approach begins to break down as the cosine similarity to the unit vector chosen gets very large (\", _jsx(_components.code, {\n        children: \"\u003e 0.4\"\n      }), \").  We end up with the possibility of matching against vectors that are of opposite directions – the least similar vectors to the original input vector.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"One solution to workaround this could be to pre-compute the similarity of a vector against unit vectors for each dimension of the input vector. But this could be 512 or more cosine similarity calculations for modern embeddings just to precompute the data. Once all unit vector similarities are calculated and stored, the range query against the database would be made against the column for which the input vector’s similarity is closest to 0.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"There are a lot of real solutions to this problem, but this was a fun exercise to think about and work on.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nWhile working on the Clarity Hub NLP API, we had a common use-case where we would create embeddings from text, and use those embedding to determine cosine similarity with other embeddings. Doing this required loading all of the embeddings in-memory and then computing cosine similarity with the entire dataset. As the dataset grew, this operation would get incredibly slow.","excerptHTML":"\u003cp\u003eWhile working on the Clarity Hub NLP API, we had a common use-case where we would create embeddings from text, and use those embedding to determine cosine similarity with other embeddings. Doing this required loading all of the embeddings in-memory and then computing cosine similarity with the entire dataset. As the dataset grew, this operation would get incredibly slow.\u003c/p\u003e","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: \"While working on the Clarity Hub NLP API, we had a common use-case where we would create embeddings from text, and use those embedding to determine cosine similarity with other embeddings. Doing this required loading all of the embeddings in-memory and then computing cosine similarity with the entire dataset. As the dataset grew, this operation would get incredibly slow.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n"},{"slug":"2023-06-06-sora","date":"2023-06-06","title":"Sora - OpenAI Visual Studio Code Extension","frontmatter":{"title":"Sora - OpenAI Visual Studio Code Extension"},"contentRaw":"Github Copilot and other AI tools are hitting the scene. I decided to create my own Visual Studio Code extension, which is designed to use OpenAI’s APIs to bring some additional ChatGPT functionality into the code editor. The goal with Sora was to enable a developer to thoughtfully write a comment about the code they would like the AI to write, and then commit to it – rather than the real-time typeahead that Github Copilot provides.\n\nWith that goal in mind, Sora provides two ways to activate OpenAI: by typing `@OpenAI` (formally `@ChatGPT`) or clicking “Send to OpenAI” when hovering over a comment. The other improvement is that Sora will read any relative link references to files in your project. A great way to use this is to have OpenAI write code in the style that already exists in your project, for example:\n\n```tsx\n/**\n * Write tests for [my-file](./my-file.ts] using\n * [other-test](../something/other-file.test.ts) as an example\n */\n```\n\nUsing this extension lets users write specifications as comments, and have ChatGPT write the entire file for you.\n\n![Sora Preview](/media/2023-06-06-sora/sora-preview.gif)\n\nThis extension leverages the OpenAI API to send any referenced files and a starting prompt to the `gpt-3.5-turbo` chat completion endpoint. The prompt mainly sets the context for creating working code using a given language and reference files.\n\nOnce the response comes back, the extension parses it and appends it to the original file.\n\n## **Installation and Usage**\n\nYou can install the extension by going to [the VSCode Marketplace](https://marketplace.visualstudio.com/items?itemName=CapsuleCat.sora-by-capsule-cat), or searching for “Sora” in Visual Studio Code extensions.\n\nOnce installed, you will need to enter your own OpenAI API key. You can get your key by following [these instructions](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key). Then just enter `Sora: Set API Key` into the Visual Studio Code command prompt.\n\n![Sora Set API Key](/media/2023-06-06-sora/sora-set-api-key.png)\n\nYou can review the code [on Github](https://github.com/CapsuleCat/sora-by-capsule-cat).\n\n## **Conclusion**\n\nIt was fun building my first extension. Please feel free to reach out on our [Github](https://github.com/CapsuleCat/sora-by-capsule-cat) for feedback or questions.\n","contentHTML":"\u003cp\u003eGithub Copilot and other AI tools are hitting the scene. I decided to create my own Visual Studio Code extension, which is designed to use OpenAI’s APIs to bring some additional ChatGPT functionality into the code editor. The goal with Sora was to enable a developer to thoughtfully write a comment about the code they would like the AI to write, and then commit to it – rather than the real-time typeahead that Github Copilot provides.\u003c/p\u003e\n\u003cp\u003eWith that goal in mind, Sora provides two ways to activate OpenAI: by typing \u003ccode\u003e@OpenAI\u003c/code\u003e (formally \u003ccode\u003e@ChatGPT\u003c/code\u003e) or clicking “Send to OpenAI” when hovering over a comment. The other improvement is that Sora will read any relative link references to files in your project. A great way to use this is to have OpenAI write code in the style that already exists in your project, for example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-tsx\"\u003e/**\n * Write tests for [my-file](./my-file.ts] using\n * [other-test](../something/other-file.test.ts) as an example\n */\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUsing this extension lets users write specifications as comments, and have ChatGPT write the entire file for you.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Sora Preview\" src=\"/media/2023-06-06-sora/sora-preview.gif\" style=\"max-height:500px;margin:auto;text-align:center\"/\u003e\u003c/p\u003e\n\u003cp\u003eThis extension leverages the OpenAI API to send any referenced files and a starting prompt to the \u003ccode\u003egpt-3.5-turbo\u003c/code\u003e chat completion endpoint. The prompt mainly sets the context for creating working code using a given language and reference files.\u003c/p\u003e\n\u003cp\u003eOnce the response comes back, the extension parses it and appends it to the original file.\u003c/p\u003e\n\u003ch2\u003e\u003cstrong\u003eInstallation and Usage\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eYou can install the extension by going to \u003ca href=\"https://marketplace.visualstudio.com/items?itemName=CapsuleCat.sora-by-capsule-cat\"\u003ethe VSCode Marketplace\u003c/a\u003e, or searching for “Sora” in Visual Studio Code extensions.\u003c/p\u003e\n\u003cp\u003eOnce installed, you will need to enter your own OpenAI API key. You can get your key by following \u003ca href=\"https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key\"\u003ethese instructions\u003c/a\u003e. Then just enter \u003ccode\u003eSora: Set API Key\u003c/code\u003e into the Visual Studio Code command prompt.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Sora Set API Key\" src=\"/media/2023-06-06-sora/sora-set-api-key.png\" style=\"max-height:500px;margin:auto;text-align:center\"/\u003e\u003c/p\u003e\n\u003cp\u003eYou can review the code \u003ca href=\"https://github.com/CapsuleCat/sora-by-capsule-cat\"\u003eon Github\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003cstrong\u003eConclusion\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eIt was fun building my first extension. Please feel free to reach out on our \u003ca href=\"https://github.com/CapsuleCat/sora-by-capsule-cat\"\u003eGithub\u003c/a\u003e for feedback or questions.\u003c/p\u003e","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    code: \"code\",\n    pre: \"pre\",\n    img: \"img\",\n    h2: \"h2\",\n    strong: \"strong\",\n    a: \"a\"\n  }, props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Github Copilot and other AI tools are hitting the scene. I decided to create my own Visual Studio Code extension, which is designed to use OpenAI’s APIs to bring some additional ChatGPT functionality into the code editor. The goal with Sora was to enable a developer to thoughtfully write a comment about the code they would like the AI to write, and then commit to it – rather than the real-time typeahead that Github Copilot provides.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"With that goal in mind, Sora provides two ways to activate OpenAI: by typing \", _jsx(_components.code, {\n        children: \"@OpenAI\"\n      }), \" (formally \", _jsx(_components.code, {\n        children: \"@ChatGPT\"\n      }), \") or clicking “Send to OpenAI” when hovering over a comment. The other improvement is that Sora will read any relative link references to files in your project. A great way to use this is to have OpenAI write code in the style that already exists in your project, for example:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-tsx\",\n        children: \"/**\\n * Write tests for [my-file](./my-file.ts] using\\n * [other-test](../something/other-file.test.ts) as an example\\n */\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Using this extension lets users write specifications as comments, and have ChatGPT write the entire file for you.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-06-06-sora/sora-preview.gif\",\n        alt: \"Sora Preview\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This extension leverages the OpenAI API to send any referenced files and a starting prompt to the \", _jsx(_components.code, {\n        children: \"gpt-3.5-turbo\"\n      }), \" chat completion endpoint. The prompt mainly sets the context for creating working code using a given language and reference files.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Once the response comes back, the extension parses it and appends it to the original file.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: _jsx(_components.strong, {\n        children: \"Installation and Usage\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"You can install the extension by going to \", _jsx(_components.a, {\n        href: \"https://marketplace.visualstudio.com/items?itemName=CapsuleCat.sora-by-capsule-cat\",\n        children: \"the VSCode Marketplace\"\n      }), \", or searching for “Sora” in Visual Studio Code extensions.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Once installed, you will need to enter your own OpenAI API key. You can get your key by following \", _jsx(_components.a, {\n        href: \"https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key\",\n        children: \"these instructions\"\n      }), \". Then just enter \", _jsx(_components.code, {\n        children: \"Sora: Set API Key\"\n      }), \" into the Visual Studio Code command prompt.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/media/2023-06-06-sora/sora-set-api-key.png\",\n        alt: \"Sora Set API Key\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"You can review the code \", _jsx(_components.a, {\n        href: \"https://github.com/CapsuleCat/sora-by-capsule-cat\",\n        children: \"on Github\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: _jsx(_components.strong, {\n        children: \"Conclusion\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"It was fun building my first extension. Please feel free to reach out on our \", _jsx(_components.a, {\n        href: \"https://github.com/CapsuleCat/sora-by-capsule-cat\",\n        children: \"Github\"\n      }), \" for feedback or questions.\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"Github Copilot and other AI tools are hitting the scene. I decided to create my own Visual Studio Code extension, which is designed to use OpenAI’s APIs to bring some additional ChatGPT functionality into the code editor. The goal with Sora was to enable a developer to thoughtfully write a comment about the code they would like the AI to write, and then commit to it – rather than the real-time typeahead that Github Copilot provides.\n","excerptHTML":"\u003cp\u003eGithub Copilot and other AI tools are hitting the scene. I decided to create my own Visual Studio Code extension, which is designed to use OpenAI’s APIs to bring some additional ChatGPT functionality into the code editor. The goal with Sora was to enable a developer to thoughtfully write a comment about the code they would like the AI to write, and then commit to it – rather than the real-time typeahead that Github Copilot provides.\u003c/p\u003e","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: \"Github Copilot and other AI tools are hitting the scene. I decided to create my own Visual Studio Code extension, which is designed to use OpenAI’s APIs to bring some additional ChatGPT functionality into the code editor. The goal with Sora was to enable a developer to thoughtfully write a comment about the code they would like the AI to write, and then commit to it – rather than the real-time typeahead that Github Copilot provides.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n"}],"projects":[{"slug":"2020-05-18-clarity-hub-infer","date":"2020-05-18","title":"Clarity Hub Infer API","frontmatter":{"title":"Clarity Hub Infer API","image":"/images/clarityhub-infer-splash.png","description":"NLP infer API to create and label utterances.\n","language_tags":["node"],"framework_tags":["Universal Sentence Encoder","serverless","swagger"],"github_link":"https://github.com/clarityhub/chapi-api-infer"},"contentRaw":"\nThe Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\n\nThis API used the Universal Sentence Encoder (USE) to create embeddings from utterances, then used cosine similarity to find the most similar utterances to a given utterance.\n","contentHTML":"\u003cp\u003eThe Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\u003c/p\u003e\n\u003cp\u003eThis API used the Universal Sentence Encoder (USE) to create embeddings from utterances, then used cosine similarity to find the most similar utterances to a given utterance.\u003c/p\u003e","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This API used the Universal Sentence Encoder (USE) to create embeddings from utterances, then used cosine similarity to find the most similar utterances to a given utterance.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nThe Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.","excerptHTML":"\u003cp\u003eThe Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\u003c/p\u003e","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: \"The Clarity Hub Infer API provides a fast and intuitive way to create, manage, and deploy NLP models based on labelling utterances.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n"},{"slug":"2018-03-05-clairvoyance.md","date":"2018-03-05","title":"Clairvoyance","frontmatter":{"title":"Clairvoyance","description":"Clairvoyance (renamed to Clarity Hub) finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\n","image":"/images/project-clarity-hub.png","view_link":"https://clarityhub.io","github_link":"https://github.com/clarityhub","language_tags":["javascript","es2015+","css"],"framework_tags":["aws","react","serverless","redux"]},"contentRaw":"\nClairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\n\nClairvoyance was built on AWS using S3, SNS, SQS, RDS, PostgreSQL, MongoDB, Elasticsearch, and React. We created a webapp, extensions, and a microservice backend to bring real time suggestions to customer success agents using Intercom.\n","contentHTML":"\u003cp\u003eClairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\u003c/p\u003e\n\u003cp\u003eClairvoyance was built on AWS using S3, SNS, SQS, RDS, PostgreSQL, MongoDB, Elasticsearch, and React. We created a webapp, extensions, and a microservice backend to bring real time suggestions to customer success agents using Intercom.\u003c/p\u003e","contentCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Clairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Clairvoyance was built on AWS using S3, SNS, SQS, RDS, PostgreSQL, MongoDB, Elasticsearch, and React. We created a webapp, extensions, and a microservice backend to bring real time suggestions to customer success agents using Intercom.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerptRaw":"\nClairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.","excerptHTML":"\u003cp\u003eClairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\u003c/p\u003e","excerptCode":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, props.components);\n  return _jsx(_components.p, {\n    children: \"Clairvoyance finds the best answers that have worked in the past and suggests them to teams using Intercom when answering similar questions.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n"}]},"__N_SSG":true},"page":"/","query":{},"buildId":"F7BNWm69u0aEm2ItOMAzh","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>